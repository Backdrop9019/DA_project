{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "décalcomanie.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vCVSE5-UboYl",
        "L88afYXKMSdL",
        "qjM3cl279Lvg",
        "o6y3zhSfMbdC",
        "9s8oXpzdMvol"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46f15de5394a4d7490ec61882fb43ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e1596c4ca15404d8850df3532006cd6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b0426559afb4a32aa2f65d208af97f0",
              "IPY_MODEL_be7121406da2412cbab5fa891282cab1"
            ]
          }
        },
        "5e1596c4ca15404d8850df3532006cd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b0426559afb4a32aa2f65d208af97f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b247b44524c24c079999da4f59117ad0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef670cd512ba4b6195a18a8b12d35c09"
          }
        },
        "be7121406da2412cbab5fa891282cab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3fe902af39f44dc2bfdd16487d0361c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:31&lt;00:00, 5321366.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6bb2b0521b4f430ab881d0a99e13e6e3"
          }
        },
        "b247b44524c24c079999da4f59117ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef670cd512ba4b6195a18a8b12d35c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fe902af39f44dc2bfdd16487d0361c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6bb2b0521b4f430ab881d0a99e13e6e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSFGYaIDG6f0"
      },
      "source": [
        "Cutout Data Augmentation.\n",
        "\n",
        "This code is implmented by following the official code (https://github.com/uoguelph-mlrg/Cutout)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCVSE5-UboYl"
      },
      "source": [
        "##**Import all neceassary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YBMwPsubsbX"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L88afYXKMSdL"
      },
      "source": [
        "##**Model - Define ResNet Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMFSLTnkMQdq"
      },
      "source": [
        "'''ResNet18/34/50/101/152 in Pytorch.'''\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = conv3x3(3,64)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n",
        "\n",
        "def ResNet34(num_classes=10):\n",
        "    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n",
        "\n",
        "def ResNet50(num_classes=10):\n",
        "    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n",
        "\n",
        "def ResNet101(num_classes=10):\n",
        "    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n",
        "\n",
        "def ResNet152(num_classes=10):\n",
        "    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n",
        "\n",
        "def test_resnet():\n",
        "    net = ResNet50()\n",
        "    y = net(Variable(torch.randn(1,3,32,32)))\n",
        "    print(y.size())\n",
        "\n",
        "# test_resnet()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjM3cl279Lvg"
      },
      "source": [
        "##**Utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIvuSgE49Kvu"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    r\"\"\"Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def print(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        # _, pred = output.topk(maxk, 1, True, True)\n",
        "        # pred = pred.t()\n",
        "        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n",
        "        _, idx = output.sort(descending=True)\n",
        "        pred = idx[:,:maxk]\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6y3zhSfMbdC"
      },
      "source": [
        "##**Cutout: Main Code for Applying Cutout data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg5mBMBX_pzn"
      },
      "source": [
        "class Cutout(object):\n",
        "    \"\"\"Randomly mask out one or more patches from an image.\n",
        "\n",
        "    Args:\n",
        "        n_holes (int): Number of patches to cut out of each image.\n",
        "        length (int): The length (in pixels) of each square patch.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_holes, length):\n",
        "        self.n_holes = n_holes\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (Tensor): Tensor image of size (C, H, W).\n",
        "        Returns:\n",
        "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
        "        \"\"\"\n",
        "        h = img.size(1)\n",
        "        w = img.size(2)\n",
        "\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "\n",
        "        for n in range(self.n_holes):\n",
        "            y = np.random.randint(h)\n",
        "            x = np.random.randint(w)\n",
        "\n",
        "            y1 = np.clip(y - self.length // 2, 0, h)\n",
        "            y2 = np.clip(y + self.length // 2, 0, h)\n",
        "            x1 = np.clip(x - self.length // 2, 0, w)\n",
        "            x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "            mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img = img * mask\n",
        "\n",
        "        return img\n",
        "        "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT-ndK6vXavT"
      },
      "source": [
        "## horizon décalcomanie\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcYQbQ-xXdKT"
      },
      "source": [
        "class RandomHorizonDecalcomanie(torch.nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, p=0.8):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, img):\n",
        "\n",
        "        if torch.rand(1) < self.p:\n",
        "\n",
        "            if  torch.rand(1) < self.p:\n",
        "              #vertical\n",
        "              if torch.rand(1) < self.p:\n",
        "                #left Decalcomanie\n",
        "                  return torch.cat((img[:,:16,:32], torch.flip(img,[1])[:,16:,:32]), 1)\n",
        "              else:\n",
        "                #right Decalcomanie\n",
        "                  return torch.cat(( torch.flip(img,[1])[:,:16,:32], img[:,16:,:32]), 1)\n",
        "            else:\n",
        "              #horizon\n",
        "              if torch.rand(1) < self.p:\n",
        "                #left Decalcomanie\n",
        "                  return torch.cat((img[:,:32,:16], torch.flip(img,[2])[:,:32,16:]), 2)\n",
        "              else:\n",
        "                #right Decalcomanie\n",
        "                  return torch.cat(( torch.flip(img,[2])[:,:32,:16], img[:,:32,16:]), 2)\n",
        "\n",
        "        return img\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7QzOKgyhTDP",
        "outputId": "fd276e7d-e676-47b0-cf08-92d4fab1d1f4"
      },
      "source": [
        "x=torch.tensor([1,2,3,])\n",
        "x[:3]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "b6qOjyp7Z00l",
        "outputId": "de7dc30b-850f-4a1d-a9af-c04650a74b65"
      },
      "source": [
        "x1 = train_dataset[15][0]\n",
        "plt.subplot(121)\n",
        "plt.imshow(x1.permute(1,2,0))\n",
        "# x2 = torch.flip(x1,[1])\n",
        "# plt.subplot(122)\n",
        "# plt.imshow(x2.permute(1,2,0))\n",
        "# plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5fd64dbaed0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# x2 = torch.flip(x1,[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plt.subplot(122)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNj89vnHc4U5"
      },
      "source": [
        "x1[:,:15,:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiSzEc_zehFF"
      },
      "source": [
        "len(train_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqXg8xHqcWZl"
      },
      "source": [
        "img = train_dataset[5][0]\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.imshow(img.permute(1,2,0))\n",
        "\n",
        "plt.subplot(132)\n",
        "\n",
        "x =torch.cat((img[:,:16,:32], torch.flip(img,[1])[:,16:,:32]), 1)\n",
        "plt.imshow(x.permute(1,2,0))\n",
        "plt.subplot(133)\n",
        "x =torch.cat(( torch.flip(img,[1])[:,:16,:32], img[:,16:,:32]), 1)\n",
        "plt.imshow(x.permute(1,2,0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2SAUX9yfBU6"
      },
      "source": [
        "print(torch.rand(1))\n",
        "print(torch.rand(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enFd93fQbvJG"
      },
      "source": [
        "x = torch.arange(8).view(2, 2, 2)\n",
        "print(x)\n",
        "print(torch.flip(x,[2]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s8oXpzdMvol"
      },
      "source": [
        "##**Parameter Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjeqawi9cNK6"
      },
      "source": [
        "dataset = 'cifar100' # cifar10 or cifar100\n",
        "model = 'resnet34' # resnet18, resnet50, resnet101\n",
        "batch_size = 128  # Input batch size for training (default: 128)\n",
        "epochs = 150 # Number of epochs to train (default: 200)\n",
        "learning_rate = 0.1 # Learning rate\n",
        "data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n",
        "cutout = False # Apply Cutout?\n",
        "mixup = False # Apply Mixup?\n",
        "Decalcomanie = True # Apply Mixup?\n",
        "n_holes = 1 # Number of holes to cut out from image\n",
        "length = 16 # Length of the holes\n",
        "seed = 0 # Random seed (default: 0)\n",
        "print_freq = 30\n",
        "cuda = torch.cuda.is_available()\n",
        "cudnn.benchmark = True  # Should make training should go faster for large models\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "test_id = dataset + '_' + model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXL_PBj6cVoe"
      },
      "source": [
        "##**Load and preprocess data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "46f15de5394a4d7490ec61882fb43ddf",
            "5e1596c4ca15404d8850df3532006cd6",
            "8b0426559afb4a32aa2f65d208af97f0",
            "be7121406da2412cbab5fa891282cab1",
            "b247b44524c24c079999da4f59117ad0",
            "ef670cd512ba4b6195a18a8b12d35c09",
            "3fe902af39f44dc2bfdd16487d0361c1",
            "6bb2b0521b4f430ab881d0a99e13e6e3"
          ]
        },
        "id": "dvQjH3T9caYs",
        "outputId": "cdf88dff-ac1a-487f-b828-113da5beb193"
      },
      "source": [
        "# Image Preprocessing\n",
        "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "train_transform = transforms.Compose([])\n",
        "if data_augmentation:\n",
        "    train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
        "train_transform.transforms.append(transforms.ToTensor())\n",
        "train_transform.transforms.append(normalize)\n",
        "if Decalcomanie:\n",
        "    train_transform.transforms.append(RandomHorizonDecalcomanie())\n",
        "\n",
        "if cutout:\n",
        "    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "    ])\n",
        "\n",
        "if dataset == 'cifar10':\n",
        "    num_classes = 10\n",
        "    train_dataset = datasets.CIFAR10(root='data/',\n",
        "                                     train=True,\n",
        "                                     transform=train_transform,\n",
        "                                     download=True)\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(root='data/',\n",
        "                                    train=False,\n",
        "                                    transform=test_transform,\n",
        "                                    download=True)\n",
        "elif dataset == 'cifar100':\n",
        "    num_classes = 100\n",
        "    train_dataset = datasets.CIFAR100(root='data/',\n",
        "                                      train=True,\n",
        "                                      transform=train_transform,\n",
        "                                      download=True)\n",
        "\n",
        "    test_dataset = datasets.CIFAR100(root='data/',\n",
        "                                     train=False,\n",
        "                                     transform=test_transform,\n",
        "                                     download=True)\n",
        "\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           pin_memory=True,\n",
        "                                           num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          pin_memory=True,\n",
        "                                          num_workers=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46f15de5394a4d7490ec61882fb43ddf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/cifar-100-python.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyTkXquJIlFC"
      },
      "source": [
        "## print image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tukgHLt_NR8D"
      },
      "source": [
        "input =  list(train_loader)[0]    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ_ce67hOOFJ",
        "outputId": "7ecd5773-3bc4-4d9f-c056-967b01425996"
      },
      "source": [
        "input[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 46, 36, 88,  8, 53, 43, 79,  3, 91, 98, 67, 25, 11, 18, 16, 66, 81,\n",
              "        40, 51, 60, 85, 44, 70, 93, 75, 37, 54, 67, 40, 50, 84, 42, 43,  5, 40,\n",
              "        60, 52, 42, 50, 92, 53, 84, 65, 63, 16, 52,  2, 80,  6, 53, 10, 50, 80,\n",
              "        57, 51, 88, 18, 61, 53, 48, 84, 26, 46,  0,  7, 47, 59, 83,  0, 45, 31,\n",
              "        43, 37, 17, 44, 55, 13, 20, 81, 97, 67, 50,  4, 19, 47,  7, 20, 41, 93,\n",
              "        45, 99, 11, 56, 54, 13, 86, 29, 17, 79, 83, 21, 28, 24, 84, 53, 15, 32,\n",
              "        85, 17, 14, 13, 10, 18, 10, 50, 48, 42, 37, 49, 42, 46, 66, 18, 68, 93,\n",
              "         8, 82])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gITLQIAr9lAZ"
      },
      "source": [
        "##**Main Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0-lYvAp9oHA",
        "outputId": "581c62d1-a8c8-4e9f-90a7-9766a9f3236d"
      },
      "source": [
        "def train(train_loader, epoch, model, optimizer, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(len(train_loader), batch_time, losses,\n",
        "                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        " \n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "        if mixup:\n",
        "          input, targets_a, targets_b, lam = mixup_data(input, target)\n",
        "\n",
        "\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        if mixup:\n",
        "          loss = mixup_criterion(criterion,output, targets_a,targets_b,lam)\n",
        "          \n",
        "        else:\n",
        "          loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss, accuracy \n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(timope.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "def test(test_loader,epoch, model):\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    model.eval()\n",
        "    for i,(input,target) in enumerate(test_loader):\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        output = model(input)\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "model = ResNet34(num_classes=num_classes).cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
        "\n",
        "scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "###########################################################\n",
        "best_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n",
        "        epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "    # train for one epoch\n",
        "    start_time = time.time()\n",
        "    train(train_loader, epoch, model, optimizer, criterion)\n",
        "    test_acc = test(test_loader,epoch,model)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n",
        "    # learning rate scheduling\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Save model for best accuracy\n",
        "    if best_acc < test_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'model_best.pt')\n",
        "\n",
        "torch.save(model.state_dict(),'model_latest.pt')\n",
        "print(f\"Best Top-1 Accuracy: {best_acc}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----- epoch: 0, lr: 0.1 -----\n",
            "Epoch: [0][  0/391]\tTime  1.236 ( 1.236)\tLoss 4.7436e+00 (4.7436e+00)\tAcc@1   1.56 (  1.56)\tAcc@5   7.03 (  7.03)\n",
            "Epoch: [0][ 30/391]\tTime  0.161 ( 0.193)\tLoss 4.5585e+00 (5.1365e+00)\tAcc@1   2.34 (  1.44)\tAcc@5   7.03 (  5.97)\n",
            "Epoch: [0][ 60/391]\tTime  0.161 ( 0.178)\tLoss 4.4929e+00 (4.8683e+00)\tAcc@1   3.12 (  1.61)\tAcc@5   7.03 (  6.66)\n",
            "Epoch: [0][ 90/391]\tTime  0.162 ( 0.172)\tLoss 4.3855e+00 (4.7197e+00)\tAcc@1   3.12 (  2.09)\tAcc@5  12.50 (  8.87)\n",
            "Epoch: [0][120/391]\tTime  0.162 ( 0.170)\tLoss 4.2468e+00 (4.6211e+00)\tAcc@1   7.81 (  2.68)\tAcc@5  21.09 ( 10.43)\n",
            "Epoch: [0][150/391]\tTime  0.164 ( 0.168)\tLoss 4.2811e+00 (4.5478e+00)\tAcc@1   3.12 (  3.10)\tAcc@5  17.97 ( 11.80)\n",
            "Epoch: [0][180/391]\tTime  0.163 ( 0.167)\tLoss 4.2341e+00 (4.4921e+00)\tAcc@1   2.34 (  3.30)\tAcc@5  15.62 ( 12.89)\n",
            "Epoch: [0][210/391]\tTime  0.162 ( 0.167)\tLoss 4.1849e+00 (4.4490e+00)\tAcc@1   7.81 (  3.52)\tAcc@5  25.00 ( 13.81)\n",
            "Epoch: [0][240/391]\tTime  0.163 ( 0.166)\tLoss 4.1929e+00 (4.4108e+00)\tAcc@1   5.47 (  3.81)\tAcc@5  21.09 ( 14.80)\n",
            "Epoch: [0][270/391]\tTime  0.163 ( 0.166)\tLoss 4.1383e+00 (4.3779e+00)\tAcc@1   4.69 (  4.02)\tAcc@5  18.75 ( 15.63)\n",
            "Epoch: [0][300/391]\tTime  0.163 ( 0.165)\tLoss 3.9701e+00 (4.3458e+00)\tAcc@1   9.38 (  4.34)\tAcc@5  27.34 ( 16.48)\n",
            "Epoch: [0][330/391]\tTime  0.162 ( 0.165)\tLoss 4.2725e+00 (4.3197e+00)\tAcc@1   2.34 (  4.54)\tAcc@5  17.19 ( 17.18)\n",
            "Epoch: [0][360/391]\tTime  0.163 ( 0.165)\tLoss 4.0596e+00 (4.2929e+00)\tAcc@1   5.47 (  4.82)\tAcc@5  21.88 ( 18.03)\n",
            "Epoch: [0][390/391]\tTime  0.688 ( 0.166)\tLoss 3.9781e+00 (4.2692e+00)\tAcc@1  10.00 (  5.05)\tAcc@5  31.25 ( 18.80)\n",
            "==> Train Accuracy: Acc@1 5.046 || Acc@5 18.796\n",
            "==> Test Accuracy:  Acc@1 9.900 || Acc@5 32.460\n",
            "==> 69.17 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 1, lr: 0.1 -----\n",
            "Epoch: [1][  0/391]\tTime  0.257 ( 0.257)\tLoss 3.9767e+00 (3.9767e+00)\tAcc@1   5.47 (  5.47)\tAcc@5  27.34 ( 27.34)\n",
            "Epoch: [1][ 30/391]\tTime  0.165 ( 0.167)\tLoss 3.7463e+00 (3.9057e+00)\tAcc@1  10.94 (  8.17)\tAcc@5  30.47 ( 30.09)\n",
            "Epoch: [1][ 60/391]\tTime  0.168 ( 0.166)\tLoss 3.8754e+00 (3.8941e+00)\tAcc@1   9.38 (  9.03)\tAcc@5  29.69 ( 29.74)\n",
            "Epoch: [1][ 90/391]\tTime  0.165 ( 0.166)\tLoss 3.9152e+00 (3.8811e+00)\tAcc@1   7.03 (  9.07)\tAcc@5  31.25 ( 30.08)\n",
            "Epoch: [1][120/391]\tTime  0.166 ( 0.166)\tLoss 3.9027e+00 (3.8761e+00)\tAcc@1  13.28 (  9.18)\tAcc@5  31.25 ( 30.20)\n",
            "Epoch: [1][150/391]\tTime  0.167 ( 0.166)\tLoss 3.6082e+00 (3.8777e+00)\tAcc@1  14.06 (  9.15)\tAcc@5  38.28 ( 30.17)\n",
            "Epoch: [1][180/391]\tTime  0.167 ( 0.166)\tLoss 3.7424e+00 (3.8711e+00)\tAcc@1  11.72 (  9.28)\tAcc@5  33.59 ( 30.43)\n",
            "Epoch: [1][210/391]\tTime  0.165 ( 0.166)\tLoss 3.6187e+00 (3.8571e+00)\tAcc@1  11.72 (  9.47)\tAcc@5  36.72 ( 30.74)\n",
            "Epoch: [1][240/391]\tTime  0.167 ( 0.166)\tLoss 3.5881e+00 (3.8438e+00)\tAcc@1  13.28 (  9.71)\tAcc@5  37.50 ( 31.21)\n",
            "Epoch: [1][270/391]\tTime  0.167 ( 0.166)\tLoss 3.7131e+00 (3.8288e+00)\tAcc@1   8.59 (  9.93)\tAcc@5  36.72 ( 31.71)\n",
            "Epoch: [1][300/391]\tTime  0.169 ( 0.167)\tLoss 3.6391e+00 (3.8148e+00)\tAcc@1  12.50 ( 10.13)\tAcc@5  32.03 ( 32.12)\n",
            "Epoch: [1][330/391]\tTime  0.168 ( 0.167)\tLoss 3.7169e+00 (3.8042e+00)\tAcc@1  10.16 ( 10.38)\tAcc@5  39.06 ( 32.54)\n",
            "Epoch: [1][360/391]\tTime  0.167 ( 0.167)\tLoss 3.6893e+00 (3.7919e+00)\tAcc@1  14.84 ( 10.60)\tAcc@5  37.50 ( 32.94)\n",
            "Epoch: [1][390/391]\tTime  0.150 ( 0.167)\tLoss 3.7090e+00 (3.7781e+00)\tAcc@1  10.00 ( 10.81)\tAcc@5  37.50 ( 33.45)\n",
            "==> Train Accuracy: Acc@1 10.814 || Acc@5 33.448\n",
            "==> Test Accuracy:  Acc@1 16.970 || Acc@5 43.910\n",
            "==> 69.43 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 2, lr: 0.1 -----\n",
            "Epoch: [2][  0/391]\tTime  0.264 ( 0.264)\tLoss 3.4675e+00 (3.4675e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  45.31 ( 45.31)\n",
            "Epoch: [2][ 30/391]\tTime  0.171 ( 0.172)\tLoss 3.6670e+00 (3.5666e+00)\tAcc@1  14.84 ( 14.36)\tAcc@5  39.84 ( 40.93)\n",
            "Epoch: [2][ 60/391]\tTime  0.169 ( 0.170)\tLoss 3.2134e+00 (3.5614e+00)\tAcc@1  21.88 ( 14.61)\tAcc@5  51.56 ( 40.71)\n",
            "Epoch: [2][ 90/391]\tTime  0.169 ( 0.170)\tLoss 3.7189e+00 (3.5495e+00)\tAcc@1  14.84 ( 14.95)\tAcc@5  32.03 ( 41.01)\n",
            "Epoch: [2][120/391]\tTime  0.169 ( 0.170)\tLoss 3.7903e+00 (3.5359e+00)\tAcc@1  12.50 ( 15.25)\tAcc@5  33.59 ( 41.30)\n",
            "Epoch: [2][150/391]\tTime  0.167 ( 0.170)\tLoss 3.4171e+00 (3.5207e+00)\tAcc@1  16.41 ( 15.43)\tAcc@5  48.44 ( 41.73)\n",
            "Epoch: [2][180/391]\tTime  0.169 ( 0.169)\tLoss 3.3379e+00 (3.5129e+00)\tAcc@1  14.06 ( 15.58)\tAcc@5  46.88 ( 41.98)\n",
            "Epoch: [2][210/391]\tTime  0.169 ( 0.169)\tLoss 3.3612e+00 (3.5031e+00)\tAcc@1  18.75 ( 15.76)\tAcc@5  46.88 ( 42.27)\n",
            "Epoch: [2][240/391]\tTime  0.167 ( 0.169)\tLoss 3.4063e+00 (3.4927e+00)\tAcc@1  22.66 ( 16.06)\tAcc@5  41.41 ( 42.44)\n",
            "Epoch: [2][270/391]\tTime  0.170 ( 0.169)\tLoss 3.2791e+00 (3.4790e+00)\tAcc@1  21.09 ( 16.28)\tAcc@5  45.31 ( 42.76)\n",
            "Epoch: [2][300/391]\tTime  0.171 ( 0.169)\tLoss 3.4984e+00 (3.4672e+00)\tAcc@1  17.19 ( 16.49)\tAcc@5  40.62 ( 43.16)\n",
            "Epoch: [2][330/391]\tTime  0.172 ( 0.170)\tLoss 3.2399e+00 (3.4596e+00)\tAcc@1  20.31 ( 16.65)\tAcc@5  52.34 ( 43.40)\n",
            "Epoch: [2][360/391]\tTime  0.172 ( 0.170)\tLoss 3.2031e+00 (3.4501e+00)\tAcc@1  19.53 ( 16.77)\tAcc@5  50.78 ( 43.67)\n",
            "Epoch: [2][390/391]\tTime  0.153 ( 0.170)\tLoss 3.3373e+00 (3.4390e+00)\tAcc@1  15.00 ( 16.93)\tAcc@5  46.25 ( 43.93)\n",
            "==> Train Accuracy: Acc@1 16.928 || Acc@5 43.932\n",
            "==> Test Accuracy:  Acc@1 22.260 || Acc@5 53.700\n",
            "==> 70.57 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 3, lr: 0.1 -----\n",
            "Epoch: [3][  0/391]\tTime  0.261 ( 0.261)\tLoss 2.9912e+00 (2.9912e+00)\tAcc@1  21.88 ( 21.88)\tAcc@5  58.59 ( 58.59)\n",
            "Epoch: [3][ 30/391]\tTime  0.173 ( 0.174)\tLoss 3.0996e+00 (3.2737e+00)\tAcc@1  22.66 ( 18.22)\tAcc@5  54.69 ( 48.34)\n",
            "Epoch: [3][ 60/391]\tTime  0.172 ( 0.173)\tLoss 3.2217e+00 (3.2722e+00)\tAcc@1  17.19 ( 18.90)\tAcc@5  50.78 ( 48.23)\n",
            "Epoch: [3][ 90/391]\tTime  0.173 ( 0.173)\tLoss 3.1916e+00 (3.2600e+00)\tAcc@1  19.53 ( 19.42)\tAcc@5  44.53 ( 48.56)\n",
            "Epoch: [3][120/391]\tTime  0.174 ( 0.173)\tLoss 3.5361e+00 (3.2594e+00)\tAcc@1  14.06 ( 19.58)\tAcc@5  41.41 ( 48.83)\n",
            "Epoch: [3][150/391]\tTime  0.172 ( 0.173)\tLoss 3.2660e+00 (3.2518e+00)\tAcc@1  21.09 ( 19.65)\tAcc@5  48.44 ( 49.08)\n",
            "Epoch: [3][180/391]\tTime  0.173 ( 0.173)\tLoss 3.2435e+00 (3.2458e+00)\tAcc@1  21.88 ( 19.74)\tAcc@5  45.31 ( 49.12)\n",
            "Epoch: [3][210/391]\tTime  0.170 ( 0.173)\tLoss 3.3261e+00 (3.2407e+00)\tAcc@1  20.31 ( 19.95)\tAcc@5  47.66 ( 49.18)\n",
            "Epoch: [3][240/391]\tTime  0.174 ( 0.173)\tLoss 3.4959e+00 (3.2359e+00)\tAcc@1  16.41 ( 20.03)\tAcc@5  45.31 ( 49.28)\n",
            "Epoch: [3][270/391]\tTime  0.174 ( 0.173)\tLoss 3.3565e+00 (3.2249e+00)\tAcc@1  16.41 ( 20.31)\tAcc@5  47.66 ( 49.57)\n",
            "Epoch: [3][300/391]\tTime  0.171 ( 0.173)\tLoss 2.9705e+00 (3.2166e+00)\tAcc@1  21.88 ( 20.44)\tAcc@5  53.91 ( 49.78)\n",
            "Epoch: [3][330/391]\tTime  0.171 ( 0.173)\tLoss 3.0389e+00 (3.2085e+00)\tAcc@1  20.31 ( 20.57)\tAcc@5  57.81 ( 50.00)\n",
            "Epoch: [3][360/391]\tTime  0.175 ( 0.173)\tLoss 3.1275e+00 (3.2035e+00)\tAcc@1  22.66 ( 20.71)\tAcc@5  50.78 ( 50.15)\n",
            "Epoch: [3][390/391]\tTime  0.158 ( 0.173)\tLoss 3.0105e+00 (3.1953e+00)\tAcc@1  28.75 ( 20.85)\tAcc@5  56.25 ( 50.38)\n",
            "==> Train Accuracy: Acc@1 20.850 || Acc@5 50.384\n",
            "==> Test Accuracy:  Acc@1 23.610 || Acc@5 53.920\n",
            "==> 71.89 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 4, lr: 0.1 -----\n",
            "Epoch: [4][  0/391]\tTime  0.269 ( 0.269)\tLoss 2.9649e+00 (2.9649e+00)\tAcc@1  25.78 ( 25.78)\tAcc@5  59.38 ( 59.38)\n",
            "Epoch: [4][ 30/391]\tTime  0.173 ( 0.176)\tLoss 3.1679e+00 (3.0046e+00)\tAcc@1  21.88 ( 24.14)\tAcc@5  47.66 ( 55.92)\n",
            "Epoch: [4][ 60/391]\tTime  0.171 ( 0.174)\tLoss 2.8103e+00 (3.0329e+00)\tAcc@1  31.25 ( 24.19)\tAcc@5  62.50 ( 55.07)\n",
            "Epoch: [4][ 90/391]\tTime  0.171 ( 0.173)\tLoss 2.9464e+00 (3.0276e+00)\tAcc@1  32.81 ( 24.47)\tAcc@5  57.03 ( 55.07)\n",
            "Epoch: [4][120/391]\tTime  0.171 ( 0.173)\tLoss 2.8549e+00 (3.0218e+00)\tAcc@1  28.91 ( 24.57)\tAcc@5  57.81 ( 54.87)\n",
            "Epoch: [4][150/391]\tTime  0.171 ( 0.173)\tLoss 3.0131e+00 (3.0224e+00)\tAcc@1  25.00 ( 24.48)\tAcc@5  57.03 ( 54.88)\n",
            "Epoch: [4][180/391]\tTime  0.165 ( 0.172)\tLoss 3.1580e+00 (3.0191e+00)\tAcc@1  21.88 ( 24.46)\tAcc@5  50.00 ( 54.89)\n",
            "Epoch: [4][210/391]\tTime  0.170 ( 0.172)\tLoss 2.9602e+00 (3.0212e+00)\tAcc@1  28.12 ( 24.38)\tAcc@5  54.69 ( 54.81)\n",
            "Epoch: [4][240/391]\tTime  0.171 ( 0.172)\tLoss 2.9895e+00 (3.0171e+00)\tAcc@1  30.47 ( 24.54)\tAcc@5  57.81 ( 54.98)\n",
            "Epoch: [4][270/391]\tTime  0.169 ( 0.172)\tLoss 2.9885e+00 (3.0094e+00)\tAcc@1  25.78 ( 24.68)\tAcc@5  55.47 ( 55.19)\n",
            "Epoch: [4][300/391]\tTime  0.172 ( 0.171)\tLoss 3.1263e+00 (3.0063e+00)\tAcc@1  23.44 ( 24.74)\tAcc@5  49.22 ( 55.26)\n",
            "Epoch: [4][330/391]\tTime  0.168 ( 0.171)\tLoss 2.7598e+00 (3.0027e+00)\tAcc@1  29.69 ( 24.85)\tAcc@5  62.50 ( 55.33)\n",
            "Epoch: [4][360/391]\tTime  0.170 ( 0.171)\tLoss 3.1251e+00 (2.9979e+00)\tAcc@1  21.09 ( 25.00)\tAcc@5  56.25 ( 55.52)\n",
            "Epoch: [4][390/391]\tTime  0.152 ( 0.171)\tLoss 2.8986e+00 (2.9931e+00)\tAcc@1  31.25 ( 25.07)\tAcc@5  55.00 ( 55.67)\n",
            "==> Train Accuracy: Acc@1 25.068 || Acc@5 55.670\n",
            "==> Test Accuracy:  Acc@1 30.010 || Acc@5 62.220\n",
            "==> 71.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 5, lr: 0.1 -----\n",
            "Epoch: [5][  0/391]\tTime  0.286 ( 0.286)\tLoss 3.0889e+00 (3.0889e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  48.44 ( 48.44)\n",
            "Epoch: [5][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.7067e+00 (2.9134e+00)\tAcc@1  28.91 ( 26.44)\tAcc@5  62.50 ( 57.31)\n",
            "Epoch: [5][ 60/391]\tTime  0.169 ( 0.172)\tLoss 2.7409e+00 (2.9028e+00)\tAcc@1  32.03 ( 27.01)\tAcc@5  64.06 ( 57.98)\n",
            "Epoch: [5][ 90/391]\tTime  0.170 ( 0.171)\tLoss 2.8778e+00 (2.9027e+00)\tAcc@1  27.34 ( 26.88)\tAcc@5  63.28 ( 58.03)\n",
            "Epoch: [5][120/391]\tTime  0.171 ( 0.171)\tLoss 3.1250e+00 (2.8919e+00)\tAcc@1  23.44 ( 27.08)\tAcc@5  53.12 ( 58.34)\n",
            "Epoch: [5][150/391]\tTime  0.172 ( 0.171)\tLoss 2.5534e+00 (2.8839e+00)\tAcc@1  35.94 ( 27.30)\tAcc@5  67.97 ( 58.70)\n",
            "Epoch: [5][180/391]\tTime  0.174 ( 0.171)\tLoss 2.7448e+00 (2.8754e+00)\tAcc@1  25.78 ( 27.54)\tAcc@5  64.84 ( 58.88)\n",
            "Epoch: [5][210/391]\tTime  0.173 ( 0.171)\tLoss 2.8250e+00 (2.8711e+00)\tAcc@1  25.00 ( 27.50)\tAcc@5  53.12 ( 59.05)\n",
            "Epoch: [5][240/391]\tTime  0.173 ( 0.172)\tLoss 2.8852e+00 (2.8655e+00)\tAcc@1  27.34 ( 27.55)\tAcc@5  57.03 ( 59.13)\n",
            "Epoch: [5][270/391]\tTime  0.173 ( 0.172)\tLoss 2.9357e+00 (2.8618e+00)\tAcc@1  29.69 ( 27.72)\tAcc@5  57.03 ( 59.13)\n",
            "Epoch: [5][300/391]\tTime  0.172 ( 0.172)\tLoss 2.8248e+00 (2.8557e+00)\tAcc@1  28.91 ( 27.86)\tAcc@5  62.50 ( 59.25)\n",
            "Epoch: [5][330/391]\tTime  0.171 ( 0.172)\tLoss 2.7423e+00 (2.8465e+00)\tAcc@1  27.34 ( 28.02)\tAcc@5  62.50 ( 59.46)\n",
            "Epoch: [5][360/391]\tTime  0.169 ( 0.172)\tLoss 2.6562e+00 (2.8419e+00)\tAcc@1  32.03 ( 28.06)\tAcc@5  64.06 ( 59.56)\n",
            "Epoch: [5][390/391]\tTime  0.154 ( 0.172)\tLoss 3.1412e+00 (2.8380e+00)\tAcc@1  28.75 ( 28.20)\tAcc@5  52.50 ( 59.68)\n",
            "==> Train Accuracy: Acc@1 28.202 || Acc@5 59.678\n",
            "==> Test Accuracy:  Acc@1 31.050 || Acc@5 63.580\n",
            "==> 71.77 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 6, lr: 0.1 -----\n",
            "Epoch: [6][  0/391]\tTime  0.270 ( 0.270)\tLoss 2.8345e+00 (2.8345e+00)\tAcc@1  21.88 ( 21.88)\tAcc@5  54.69 ( 54.69)\n",
            "Epoch: [6][ 30/391]\tTime  0.171 ( 0.176)\tLoss 2.5850e+00 (2.7365e+00)\tAcc@1  34.38 ( 30.52)\tAcc@5  64.84 ( 61.82)\n",
            "Epoch: [6][ 60/391]\tTime  0.172 ( 0.175)\tLoss 2.7706e+00 (2.7489e+00)\tAcc@1  28.12 ( 30.07)\tAcc@5  61.72 ( 61.48)\n",
            "Epoch: [6][ 90/391]\tTime  0.174 ( 0.174)\tLoss 2.6489e+00 (2.7395e+00)\tAcc@1  29.69 ( 29.96)\tAcc@5  67.97 ( 61.78)\n",
            "Epoch: [6][120/391]\tTime  0.175 ( 0.174)\tLoss 2.6457e+00 (2.7256e+00)\tAcc@1  32.03 ( 30.38)\tAcc@5  63.28 ( 62.06)\n",
            "Epoch: [6][150/391]\tTime  0.174 ( 0.174)\tLoss 2.5292e+00 (2.7165e+00)\tAcc@1  41.41 ( 30.51)\tAcc@5  70.31 ( 62.37)\n",
            "Epoch: [6][180/391]\tTime  0.174 ( 0.174)\tLoss 2.3831e+00 (2.7051e+00)\tAcc@1  39.84 ( 30.76)\tAcc@5  68.75 ( 62.65)\n",
            "Epoch: [6][210/391]\tTime  0.172 ( 0.174)\tLoss 2.6916e+00 (2.7042e+00)\tAcc@1  26.56 ( 30.81)\tAcc@5  64.84 ( 62.66)\n",
            "Epoch: [6][240/391]\tTime  0.175 ( 0.174)\tLoss 2.4624e+00 (2.7041e+00)\tAcc@1  29.69 ( 30.72)\tAcc@5  67.97 ( 62.74)\n",
            "Epoch: [6][270/391]\tTime  0.173 ( 0.174)\tLoss 2.5647e+00 (2.6983e+00)\tAcc@1  38.28 ( 30.85)\tAcc@5  66.41 ( 62.80)\n",
            "Epoch: [6][300/391]\tTime  0.171 ( 0.174)\tLoss 2.6406e+00 (2.6953e+00)\tAcc@1  32.03 ( 30.95)\tAcc@5  60.94 ( 62.86)\n",
            "Epoch: [6][330/391]\tTime  0.171 ( 0.173)\tLoss 2.8878e+00 (2.6950e+00)\tAcc@1  26.56 ( 30.93)\tAcc@5  58.59 ( 62.85)\n",
            "Epoch: [6][360/391]\tTime  0.168 ( 0.173)\tLoss 2.5503e+00 (2.6924e+00)\tAcc@1  33.59 ( 31.04)\tAcc@5  67.19 ( 62.94)\n",
            "Epoch: [6][390/391]\tTime  0.155 ( 0.173)\tLoss 2.9178e+00 (2.6891e+00)\tAcc@1  30.00 ( 31.11)\tAcc@5  58.75 ( 63.00)\n",
            "==> Train Accuracy: Acc@1 31.106 || Acc@5 63.000\n",
            "==> Test Accuracy:  Acc@1 31.890 || Acc@5 63.650\n",
            "==> 71.91 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 7, lr: 0.1 -----\n",
            "Epoch: [7][  0/391]\tTime  0.286 ( 0.286)\tLoss 2.5176e+00 (2.5176e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  71.09 ( 71.09)\n",
            "Epoch: [7][ 30/391]\tTime  0.172 ( 0.174)\tLoss 2.8363e+00 (2.5515e+00)\tAcc@1  28.91 ( 33.90)\tAcc@5  61.72 ( 66.56)\n",
            "Epoch: [7][ 60/391]\tTime  0.169 ( 0.172)\tLoss 2.7837e+00 (2.5497e+00)\tAcc@1  29.69 ( 33.97)\tAcc@5  62.50 ( 66.60)\n",
            "Epoch: [7][ 90/391]\tTime  0.170 ( 0.171)\tLoss 2.4933e+00 (2.5692e+00)\tAcc@1  36.72 ( 33.44)\tAcc@5  66.41 ( 66.04)\n",
            "Epoch: [7][120/391]\tTime  0.171 ( 0.171)\tLoss 2.4730e+00 (2.5711e+00)\tAcc@1  39.06 ( 33.26)\tAcc@5  68.75 ( 65.95)\n",
            "Epoch: [7][150/391]\tTime  0.168 ( 0.171)\tLoss 2.7075e+00 (2.5733e+00)\tAcc@1  29.69 ( 33.24)\tAcc@5  63.28 ( 65.99)\n",
            "Epoch: [7][180/391]\tTime  0.171 ( 0.171)\tLoss 2.5102e+00 (2.5673e+00)\tAcc@1  30.47 ( 33.24)\tAcc@5  67.97 ( 65.98)\n",
            "Epoch: [7][210/391]\tTime  0.171 ( 0.171)\tLoss 2.3963e+00 (2.5665e+00)\tAcc@1  32.81 ( 33.31)\tAcc@5  72.66 ( 66.14)\n",
            "Epoch: [7][240/391]\tTime  0.172 ( 0.171)\tLoss 2.8458e+00 (2.5661e+00)\tAcc@1  24.22 ( 33.32)\tAcc@5  63.28 ( 66.07)\n",
            "Epoch: [7][270/391]\tTime  0.169 ( 0.171)\tLoss 2.5279e+00 (2.5677e+00)\tAcc@1  32.81 ( 33.31)\tAcc@5  66.41 ( 66.03)\n",
            "Epoch: [7][300/391]\tTime  0.169 ( 0.171)\tLoss 2.5470e+00 (2.5699e+00)\tAcc@1  29.69 ( 33.33)\tAcc@5  68.75 ( 66.04)\n",
            "Epoch: [7][330/391]\tTime  0.170 ( 0.171)\tLoss 2.5152e+00 (2.5708e+00)\tAcc@1  39.06 ( 33.35)\tAcc@5  68.75 ( 66.01)\n",
            "Epoch: [7][360/391]\tTime  0.174 ( 0.171)\tLoss 2.5518e+00 (2.5696e+00)\tAcc@1  32.03 ( 33.41)\tAcc@5  69.53 ( 66.03)\n",
            "Epoch: [7][390/391]\tTime  0.156 ( 0.171)\tLoss 2.1643e+00 (2.5659e+00)\tAcc@1  41.25 ( 33.57)\tAcc@5  76.25 ( 66.16)\n",
            "==> Train Accuracy: Acc@1 33.572 || Acc@5 66.164\n",
            "==> Test Accuracy:  Acc@1 41.680 || Acc@5 74.570\n",
            "==> 71.10 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 8, lr: 0.1 -----\n",
            "Epoch: [8][  0/391]\tTime  0.266 ( 0.266)\tLoss 2.5505e+00 (2.5505e+00)\tAcc@1  35.16 ( 35.16)\tAcc@5  67.97 ( 67.97)\n",
            "Epoch: [8][ 30/391]\tTime  0.176 ( 0.178)\tLoss 2.5952e+00 (2.4697e+00)\tAcc@1  27.34 ( 35.33)\tAcc@5  66.41 ( 68.42)\n",
            "Epoch: [8][ 60/391]\tTime  0.181 ( 0.178)\tLoss 2.3576e+00 (2.4691e+00)\tAcc@1  36.72 ( 35.54)\tAcc@5  73.44 ( 67.84)\n",
            "Epoch: [8][ 90/391]\tTime  0.180 ( 0.178)\tLoss 2.2997e+00 (2.4473e+00)\tAcc@1  36.72 ( 35.95)\tAcc@5  72.66 ( 68.38)\n",
            "Epoch: [8][120/391]\tTime  0.177 ( 0.178)\tLoss 2.3089e+00 (2.4472e+00)\tAcc@1  40.62 ( 36.14)\tAcc@5  74.22 ( 68.50)\n",
            "Epoch: [8][150/391]\tTime  0.175 ( 0.177)\tLoss 2.2718e+00 (2.4577e+00)\tAcc@1  41.41 ( 36.05)\tAcc@5  75.78 ( 68.33)\n",
            "Epoch: [8][180/391]\tTime  0.177 ( 0.177)\tLoss 2.3425e+00 (2.4542e+00)\tAcc@1  46.88 ( 36.12)\tAcc@5  67.19 ( 68.30)\n",
            "Epoch: [8][210/391]\tTime  0.175 ( 0.177)\tLoss 2.3274e+00 (2.4557e+00)\tAcc@1  37.50 ( 35.98)\tAcc@5  67.97 ( 68.29)\n",
            "Epoch: [8][240/391]\tTime  0.173 ( 0.176)\tLoss 2.1892e+00 (2.4524e+00)\tAcc@1  42.97 ( 36.14)\tAcc@5  74.22 ( 68.32)\n",
            "Epoch: [8][270/391]\tTime  0.171 ( 0.176)\tLoss 2.4210e+00 (2.4545e+00)\tAcc@1  35.94 ( 36.07)\tAcc@5  66.41 ( 68.30)\n",
            "Epoch: [8][300/391]\tTime  0.174 ( 0.176)\tLoss 2.4338e+00 (2.4496e+00)\tAcc@1  35.94 ( 36.15)\tAcc@5  65.62 ( 68.38)\n",
            "Epoch: [8][330/391]\tTime  0.173 ( 0.176)\tLoss 2.6535e+00 (2.4526e+00)\tAcc@1  28.91 ( 36.06)\tAcc@5  68.75 ( 68.38)\n",
            "Epoch: [8][360/391]\tTime  0.174 ( 0.176)\tLoss 2.6346e+00 (2.4509e+00)\tAcc@1  33.59 ( 36.08)\tAcc@5  60.94 ( 68.44)\n",
            "Epoch: [8][390/391]\tTime  0.159 ( 0.175)\tLoss 2.0991e+00 (2.4479e+00)\tAcc@1  38.75 ( 36.16)\tAcc@5  78.75 ( 68.52)\n",
            "==> Train Accuracy: Acc@1 36.156 || Acc@5 68.524\n",
            "==> Test Accuracy:  Acc@1 39.960 || Acc@5 72.330\n",
            "==> 72.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 9, lr: 0.1 -----\n",
            "Epoch: [9][  0/391]\tTime  0.258 ( 0.258)\tLoss 2.3840e+00 (2.3840e+00)\tAcc@1  34.38 ( 34.38)\tAcc@5  70.31 ( 70.31)\n",
            "Epoch: [9][ 30/391]\tTime  0.176 ( 0.176)\tLoss 2.3188e+00 (2.3529e+00)\tAcc@1  33.59 ( 39.01)\tAcc@5  72.66 ( 71.04)\n",
            "Epoch: [9][ 60/391]\tTime  0.173 ( 0.175)\tLoss 2.4074e+00 (2.3587e+00)\tAcc@1  38.28 ( 38.52)\tAcc@5  68.75 ( 70.68)\n",
            "Epoch: [9][ 90/391]\tTime  0.175 ( 0.175)\tLoss 2.5739e+00 (2.3691e+00)\tAcc@1  35.16 ( 38.14)\tAcc@5  68.75 ( 70.37)\n",
            "Epoch: [9][120/391]\tTime  0.175 ( 0.175)\tLoss 2.4510e+00 (2.3733e+00)\tAcc@1  39.06 ( 38.12)\tAcc@5  68.75 ( 70.49)\n",
            "Epoch: [9][150/391]\tTime  0.175 ( 0.175)\tLoss 2.2903e+00 (2.3691e+00)\tAcc@1  36.72 ( 38.16)\tAcc@5  73.44 ( 70.41)\n",
            "Epoch: [9][180/391]\tTime  0.176 ( 0.175)\tLoss 2.4670e+00 (2.3633e+00)\tAcc@1  35.94 ( 38.33)\tAcc@5  68.75 ( 70.55)\n",
            "Epoch: [9][210/391]\tTime  0.174 ( 0.175)\tLoss 2.4919e+00 (2.3609e+00)\tAcc@1  32.81 ( 38.39)\tAcc@5  67.19 ( 70.52)\n",
            "Epoch: [9][240/391]\tTime  0.174 ( 0.175)\tLoss 2.5185e+00 (2.3636e+00)\tAcc@1  38.28 ( 38.34)\tAcc@5  64.84 ( 70.41)\n",
            "Epoch: [9][270/391]\tTime  0.175 ( 0.175)\tLoss 2.0951e+00 (2.3634e+00)\tAcc@1  45.31 ( 38.38)\tAcc@5  71.88 ( 70.39)\n",
            "Epoch: [9][300/391]\tTime  0.176 ( 0.175)\tLoss 2.1748e+00 (2.3584e+00)\tAcc@1  35.94 ( 38.40)\tAcc@5  71.09 ( 70.51)\n",
            "Epoch: [9][330/391]\tTime  0.175 ( 0.175)\tLoss 2.2867e+00 (2.3581e+00)\tAcc@1  39.06 ( 38.35)\tAcc@5  72.66 ( 70.49)\n",
            "Epoch: [9][360/391]\tTime  0.174 ( 0.175)\tLoss 2.5169e+00 (2.3553e+00)\tAcc@1  32.81 ( 38.42)\tAcc@5  67.97 ( 70.52)\n",
            "Epoch: [9][390/391]\tTime  0.156 ( 0.175)\tLoss 2.6175e+00 (2.3572e+00)\tAcc@1  37.50 ( 38.32)\tAcc@5  61.25 ( 70.46)\n",
            "==> Train Accuracy: Acc@1 38.316 || Acc@5 70.462\n",
            "==> Test Accuracy:  Acc@1 42.880 || Acc@5 75.350\n",
            "==> 72.74 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 10, lr: 0.1 -----\n",
            "Epoch: [10][  0/391]\tTime  0.278 ( 0.278)\tLoss 2.2014e+00 (2.2014e+00)\tAcc@1  40.62 ( 40.62)\tAcc@5  74.22 ( 74.22)\n",
            "Epoch: [10][ 30/391]\tTime  0.174 ( 0.177)\tLoss 2.3033e+00 (2.3048e+00)\tAcc@1  37.50 ( 39.26)\tAcc@5  71.09 ( 71.60)\n",
            "Epoch: [10][ 60/391]\tTime  0.174 ( 0.176)\tLoss 2.1898e+00 (2.2752e+00)\tAcc@1  43.75 ( 40.13)\tAcc@5  73.44 ( 72.44)\n",
            "Epoch: [10][ 90/391]\tTime  0.177 ( 0.176)\tLoss 2.2147e+00 (2.2987e+00)\tAcc@1  42.19 ( 39.83)\tAcc@5  74.22 ( 71.89)\n",
            "Epoch: [10][120/391]\tTime  0.175 ( 0.175)\tLoss 2.2544e+00 (2.3005e+00)\tAcc@1  46.88 ( 39.84)\tAcc@5  71.88 ( 71.78)\n",
            "Epoch: [10][150/391]\tTime  0.174 ( 0.175)\tLoss 2.4596e+00 (2.2976e+00)\tAcc@1  38.28 ( 39.83)\tAcc@5  62.50 ( 71.85)\n",
            "Epoch: [10][180/391]\tTime  0.172 ( 0.175)\tLoss 2.0577e+00 (2.2909e+00)\tAcc@1  42.19 ( 39.80)\tAcc@5  75.78 ( 71.97)\n",
            "Epoch: [10][210/391]\tTime  0.176 ( 0.174)\tLoss 2.1133e+00 (2.2961e+00)\tAcc@1  43.75 ( 39.64)\tAcc@5  74.22 ( 71.76)\n",
            "Epoch: [10][240/391]\tTime  0.174 ( 0.174)\tLoss 2.4060e+00 (2.2924e+00)\tAcc@1  42.19 ( 39.71)\tAcc@5  73.44 ( 71.87)\n",
            "Epoch: [10][270/391]\tTime  0.172 ( 0.174)\tLoss 2.2558e+00 (2.2942e+00)\tAcc@1  42.19 ( 39.60)\tAcc@5  69.53 ( 71.75)\n",
            "Epoch: [10][300/391]\tTime  0.172 ( 0.174)\tLoss 1.9468e+00 (2.2931e+00)\tAcc@1  47.66 ( 39.62)\tAcc@5  80.47 ( 71.77)\n",
            "Epoch: [10][330/391]\tTime  0.170 ( 0.173)\tLoss 2.4320e+00 (2.2933e+00)\tAcc@1  37.50 ( 39.60)\tAcc@5  66.41 ( 71.79)\n",
            "Epoch: [10][360/391]\tTime  0.172 ( 0.173)\tLoss 2.3914e+00 (2.2928e+00)\tAcc@1  41.41 ( 39.60)\tAcc@5  71.09 ( 71.86)\n",
            "Epoch: [10][390/391]\tTime  0.152 ( 0.173)\tLoss 2.4506e+00 (2.2938e+00)\tAcc@1  37.50 ( 39.60)\tAcc@5  63.75 ( 71.79)\n",
            "==> Train Accuracy: Acc@1 39.600 || Acc@5 71.792\n",
            "==> Test Accuracy:  Acc@1 38.560 || Acc@5 71.300\n",
            "==> 71.78 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 11, lr: 0.1 -----\n",
            "Epoch: [11][  0/391]\tTime  0.272 ( 0.272)\tLoss 2.3168e+00 (2.3168e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  72.66 ( 72.66)\n",
            "Epoch: [11][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.2619e+00 (2.2628e+00)\tAcc@1  33.59 ( 40.22)\tAcc@5  75.78 ( 72.23)\n",
            "Epoch: [11][ 60/391]\tTime  0.173 ( 0.172)\tLoss 2.1154e+00 (2.2300e+00)\tAcc@1  45.31 ( 41.11)\tAcc@5  78.91 ( 73.14)\n",
            "Epoch: [11][ 90/391]\tTime  0.171 ( 0.171)\tLoss 2.1267e+00 (2.2245e+00)\tAcc@1  42.19 ( 41.47)\tAcc@5  77.34 ( 73.11)\n",
            "Epoch: [11][120/391]\tTime  0.170 ( 0.171)\tLoss 2.3979e+00 (2.2350e+00)\tAcc@1  39.06 ( 41.21)\tAcc@5  70.31 ( 72.78)\n",
            "Epoch: [11][150/391]\tTime  0.172 ( 0.171)\tLoss 2.2847e+00 (2.2372e+00)\tAcc@1  42.19 ( 40.94)\tAcc@5  75.00 ( 72.70)\n",
            "Epoch: [11][180/391]\tTime  0.174 ( 0.171)\tLoss 2.1797e+00 (2.2332e+00)\tAcc@1  41.41 ( 40.93)\tAcc@5  74.22 ( 72.86)\n",
            "Epoch: [11][210/391]\tTime  0.172 ( 0.171)\tLoss 2.3060e+00 (2.2417e+00)\tAcc@1  39.06 ( 40.75)\tAcc@5  74.22 ( 72.78)\n",
            "Epoch: [11][240/391]\tTime  0.172 ( 0.171)\tLoss 2.3349e+00 (2.2387e+00)\tAcc@1  43.75 ( 41.00)\tAcc@5  69.53 ( 72.88)\n",
            "Epoch: [11][270/391]\tTime  0.172 ( 0.171)\tLoss 2.4721e+00 (2.2397e+00)\tAcc@1  33.59 ( 40.99)\tAcc@5  67.97 ( 72.92)\n",
            "Epoch: [11][300/391]\tTime  0.171 ( 0.171)\tLoss 2.0787e+00 (2.2387e+00)\tAcc@1  44.53 ( 41.03)\tAcc@5  75.78 ( 72.99)\n",
            "Epoch: [11][330/391]\tTime  0.169 ( 0.171)\tLoss 2.2622e+00 (2.2389e+00)\tAcc@1  39.84 ( 40.97)\tAcc@5  76.56 ( 73.07)\n",
            "Epoch: [11][360/391]\tTime  0.172 ( 0.171)\tLoss 2.3988e+00 (2.2414e+00)\tAcc@1  35.94 ( 40.93)\tAcc@5  70.31 ( 73.03)\n",
            "Epoch: [11][390/391]\tTime  0.153 ( 0.171)\tLoss 2.5148e+00 (2.2415e+00)\tAcc@1  33.75 ( 40.90)\tAcc@5  70.00 ( 73.03)\n",
            "==> Train Accuracy: Acc@1 40.904 || Acc@5 73.026\n",
            "==> Test Accuracy:  Acc@1 42.700 || Acc@5 74.520\n",
            "==> 71.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 12, lr: 0.1 -----\n",
            "Epoch: [12][  0/391]\tTime  0.258 ( 0.258)\tLoss 1.9146e+00 (1.9146e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  79.69 ( 79.69)\n",
            "Epoch: [12][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.1471e+00 (2.1734e+00)\tAcc@1  43.75 ( 42.79)\tAcc@5  75.00 ( 73.36)\n",
            "Epoch: [12][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.1807e+00 (2.1685e+00)\tAcc@1  42.19 ( 42.76)\tAcc@5  72.66 ( 74.09)\n",
            "Epoch: [12][ 90/391]\tTime  0.169 ( 0.171)\tLoss 2.0349e+00 (2.1719e+00)\tAcc@1  40.62 ( 42.73)\tAcc@5  79.69 ( 74.02)\n",
            "Epoch: [12][120/391]\tTime  0.171 ( 0.171)\tLoss 2.2960e+00 (2.1782e+00)\tAcc@1  34.38 ( 42.35)\tAcc@5  67.19 ( 73.90)\n",
            "Epoch: [12][150/391]\tTime  0.172 ( 0.171)\tLoss 2.1299e+00 (2.1774e+00)\tAcc@1  42.97 ( 42.30)\tAcc@5  75.00 ( 74.06)\n",
            "Epoch: [12][180/391]\tTime  0.172 ( 0.171)\tLoss 2.0436e+00 (2.1706e+00)\tAcc@1  44.53 ( 42.64)\tAcc@5  78.12 ( 74.13)\n",
            "Epoch: [12][210/391]\tTime  0.169 ( 0.171)\tLoss 2.1636e+00 (2.1742e+00)\tAcc@1  42.97 ( 42.59)\tAcc@5  77.34 ( 74.03)\n",
            "Epoch: [12][240/391]\tTime  0.169 ( 0.170)\tLoss 2.2828e+00 (2.1786e+00)\tAcc@1  39.06 ( 42.36)\tAcc@5  73.44 ( 73.97)\n",
            "Epoch: [12][270/391]\tTime  0.170 ( 0.170)\tLoss 2.2101e+00 (2.1805e+00)\tAcc@1  43.75 ( 42.30)\tAcc@5  72.66 ( 73.93)\n",
            "Epoch: [12][300/391]\tTime  0.169 ( 0.170)\tLoss 2.2642e+00 (2.1757e+00)\tAcc@1  42.97 ( 42.42)\tAcc@5  69.53 ( 74.02)\n",
            "Epoch: [12][330/391]\tTime  0.171 ( 0.170)\tLoss 1.9458e+00 (2.1796e+00)\tAcc@1  49.22 ( 42.31)\tAcc@5  82.03 ( 74.00)\n",
            "Epoch: [12][360/391]\tTime  0.172 ( 0.170)\tLoss 2.3214e+00 (2.1829e+00)\tAcc@1  45.31 ( 42.24)\tAcc@5  67.19 ( 73.93)\n",
            "Epoch: [12][390/391]\tTime  0.155 ( 0.170)\tLoss 2.2900e+00 (2.1822e+00)\tAcc@1  42.50 ( 42.26)\tAcc@5  70.00 ( 73.95)\n",
            "==> Train Accuracy: Acc@1 42.260 || Acc@5 73.952\n",
            "==> Test Accuracy:  Acc@1 45.530 || Acc@5 77.240\n",
            "==> 70.80 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 13, lr: 0.1 -----\n",
            "Epoch: [13][  0/391]\tTime  0.265 ( 0.265)\tLoss 2.3089e+00 (2.3089e+00)\tAcc@1  41.41 ( 41.41)\tAcc@5  70.31 ( 70.31)\n",
            "Epoch: [13][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.2320e+00 (2.1668e+00)\tAcc@1  38.28 ( 43.37)\tAcc@5  75.00 ( 74.07)\n",
            "Epoch: [13][ 60/391]\tTime  0.171 ( 0.171)\tLoss 2.0640e+00 (2.1289e+00)\tAcc@1  45.31 ( 43.05)\tAcc@5  71.88 ( 74.85)\n",
            "Epoch: [13][ 90/391]\tTime  0.171 ( 0.171)\tLoss 2.3243e+00 (2.1143e+00)\tAcc@1  39.06 ( 43.30)\tAcc@5  71.09 ( 75.04)\n",
            "Epoch: [13][120/391]\tTime  0.171 ( 0.171)\tLoss 2.2207e+00 (2.1306e+00)\tAcc@1  44.53 ( 42.99)\tAcc@5  71.09 ( 74.69)\n",
            "Epoch: [13][150/391]\tTime  0.170 ( 0.171)\tLoss 2.0039e+00 (2.1261e+00)\tAcc@1  50.78 ( 42.99)\tAcc@5  77.34 ( 74.93)\n",
            "Epoch: [13][180/391]\tTime  0.169 ( 0.171)\tLoss 2.1619e+00 (2.1215e+00)\tAcc@1  42.97 ( 43.15)\tAcc@5  75.78 ( 75.07)\n",
            "Epoch: [13][210/391]\tTime  0.169 ( 0.171)\tLoss 2.0914e+00 (2.1263e+00)\tAcc@1  43.75 ( 43.09)\tAcc@5  78.91 ( 74.97)\n",
            "Epoch: [13][240/391]\tTime  0.170 ( 0.171)\tLoss 1.9154e+00 (2.1364e+00)\tAcc@1  55.47 ( 42.93)\tAcc@5  81.25 ( 74.73)\n",
            "Epoch: [13][270/391]\tTime  0.171 ( 0.171)\tLoss 2.3339e+00 (2.1331e+00)\tAcc@1  43.75 ( 43.04)\tAcc@5  71.88 ( 74.82)\n",
            "Epoch: [13][300/391]\tTime  0.170 ( 0.171)\tLoss 2.0799e+00 (2.1312e+00)\tAcc@1  45.31 ( 43.08)\tAcc@5  69.53 ( 74.81)\n",
            "Epoch: [13][330/391]\tTime  0.170 ( 0.171)\tLoss 2.2829e+00 (2.1346e+00)\tAcc@1  44.53 ( 43.12)\tAcc@5  76.56 ( 74.79)\n",
            "Epoch: [13][360/391]\tTime  0.172 ( 0.171)\tLoss 2.0698e+00 (2.1362e+00)\tAcc@1  49.22 ( 43.14)\tAcc@5  78.12 ( 74.71)\n",
            "Epoch: [13][390/391]\tTime  0.153 ( 0.171)\tLoss 1.9447e+00 (2.1346e+00)\tAcc@1  43.75 ( 43.18)\tAcc@5  80.00 ( 74.82)\n",
            "==> Train Accuracy: Acc@1 43.182 || Acc@5 74.824\n",
            "==> Test Accuracy:  Acc@1 49.470 || Acc@5 80.110\n",
            "==> 70.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 14, lr: 0.1 -----\n",
            "Epoch: [14][  0/391]\tTime  0.264 ( 0.264)\tLoss 2.2712e+00 (2.2712e+00)\tAcc@1  32.81 ( 32.81)\tAcc@5  72.66 ( 72.66)\n",
            "Epoch: [14][ 30/391]\tTime  0.172 ( 0.174)\tLoss 2.0730e+00 (2.1324e+00)\tAcc@1  39.84 ( 43.12)\tAcc@5  75.00 ( 75.23)\n",
            "Epoch: [14][ 60/391]\tTime  0.173 ( 0.172)\tLoss 1.8418e+00 (2.1137e+00)\tAcc@1  52.34 ( 43.88)\tAcc@5  84.38 ( 75.41)\n",
            "Epoch: [14][ 90/391]\tTime  0.173 ( 0.172)\tLoss 2.2221e+00 (2.0967e+00)\tAcc@1  38.28 ( 44.07)\tAcc@5  75.00 ( 75.52)\n",
            "Epoch: [14][120/391]\tTime  0.175 ( 0.172)\tLoss 2.0047e+00 (2.0991e+00)\tAcc@1  42.97 ( 43.77)\tAcc@5  75.78 ( 75.50)\n",
            "Epoch: [14][150/391]\tTime  0.177 ( 0.172)\tLoss 2.1457e+00 (2.1008e+00)\tAcc@1  46.88 ( 43.92)\tAcc@5  71.88 ( 75.39)\n",
            "Epoch: [14][180/391]\tTime  0.177 ( 0.173)\tLoss 2.0729e+00 (2.1048e+00)\tAcc@1  43.75 ( 43.76)\tAcc@5  71.88 ( 75.32)\n",
            "Epoch: [14][210/391]\tTime  0.175 ( 0.173)\tLoss 2.1120e+00 (2.0989e+00)\tAcc@1  39.84 ( 43.86)\tAcc@5  78.91 ( 75.40)\n",
            "Epoch: [14][240/391]\tTime  0.179 ( 0.173)\tLoss 2.3292e+00 (2.1045e+00)\tAcc@1  37.50 ( 43.72)\tAcc@5  71.88 ( 75.25)\n",
            "Epoch: [14][270/391]\tTime  0.178 ( 0.174)\tLoss 2.1080e+00 (2.1049e+00)\tAcc@1  39.84 ( 43.71)\tAcc@5  75.00 ( 75.28)\n",
            "Epoch: [14][300/391]\tTime  0.176 ( 0.174)\tLoss 2.1832e+00 (2.1053e+00)\tAcc@1  38.28 ( 43.74)\tAcc@5  76.56 ( 75.17)\n",
            "Epoch: [14][330/391]\tTime  0.174 ( 0.174)\tLoss 2.0939e+00 (2.1071e+00)\tAcc@1  41.41 ( 43.74)\tAcc@5  75.78 ( 75.17)\n",
            "Epoch: [14][360/391]\tTime  0.173 ( 0.174)\tLoss 2.3429e+00 (2.1096e+00)\tAcc@1  43.75 ( 43.74)\tAcc@5  68.75 ( 75.16)\n",
            "Epoch: [14][390/391]\tTime  0.155 ( 0.174)\tLoss 2.0449e+00 (2.1091e+00)\tAcc@1  43.75 ( 43.74)\tAcc@5  68.75 ( 75.14)\n",
            "==> Train Accuracy: Acc@1 43.740 || Acc@5 75.140\n",
            "==> Test Accuracy:  Acc@1 48.310 || Acc@5 78.260\n",
            "==> 72.40 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 15, lr: 0.1 -----\n",
            "Epoch: [15][  0/391]\tTime  0.265 ( 0.265)\tLoss 2.1858e+00 (2.1858e+00)\tAcc@1  43.75 ( 43.75)\tAcc@5  72.66 ( 72.66)\n",
            "Epoch: [15][ 30/391]\tTime  0.172 ( 0.176)\tLoss 2.1564e+00 (2.0393e+00)\tAcc@1  38.28 ( 45.49)\tAcc@5  75.00 ( 76.01)\n",
            "Epoch: [15][ 60/391]\tTime  0.173 ( 0.175)\tLoss 2.0888e+00 (2.0409e+00)\tAcc@1  42.19 ( 45.47)\tAcc@5  74.22 ( 76.23)\n",
            "Epoch: [15][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.9739e+00 (2.0558e+00)\tAcc@1  45.31 ( 45.16)\tAcc@5  78.91 ( 76.05)\n",
            "Epoch: [15][120/391]\tTime  0.173 ( 0.174)\tLoss 2.0601e+00 (2.0678e+00)\tAcc@1  46.88 ( 44.71)\tAcc@5  74.22 ( 76.00)\n",
            "Epoch: [15][150/391]\tTime  0.174 ( 0.174)\tLoss 2.1260e+00 (2.0693e+00)\tAcc@1  47.66 ( 44.73)\tAcc@5  71.88 ( 76.05)\n",
            "Epoch: [15][180/391]\tTime  0.172 ( 0.174)\tLoss 2.1668e+00 (2.0618e+00)\tAcc@1  43.75 ( 44.78)\tAcc@5  71.88 ( 76.21)\n",
            "Epoch: [15][210/391]\tTime  0.176 ( 0.174)\tLoss 2.0848e+00 (2.0643e+00)\tAcc@1  40.62 ( 44.76)\tAcc@5  77.34 ( 76.15)\n",
            "Epoch: [15][240/391]\tTime  0.174 ( 0.174)\tLoss 2.0745e+00 (2.0657e+00)\tAcc@1  42.97 ( 44.73)\tAcc@5  76.56 ( 76.11)\n",
            "Epoch: [15][270/391]\tTime  0.174 ( 0.174)\tLoss 2.0299e+00 (2.0667e+00)\tAcc@1  49.22 ( 44.70)\tAcc@5  74.22 ( 76.18)\n",
            "Epoch: [15][300/391]\tTime  0.175 ( 0.174)\tLoss 2.1968e+00 (2.0724e+00)\tAcc@1  38.28 ( 44.52)\tAcc@5  72.66 ( 76.10)\n",
            "Epoch: [15][330/391]\tTime  0.173 ( 0.174)\tLoss 2.4091e+00 (2.0766e+00)\tAcc@1  36.72 ( 44.43)\tAcc@5  67.19 ( 76.02)\n",
            "Epoch: [15][360/391]\tTime  0.173 ( 0.174)\tLoss 2.0685e+00 (2.0733e+00)\tAcc@1  42.19 ( 44.56)\tAcc@5  75.00 ( 76.05)\n",
            "Epoch: [15][390/391]\tTime  0.157 ( 0.174)\tLoss 2.0693e+00 (2.0721e+00)\tAcc@1  42.50 ( 44.53)\tAcc@5  73.75 ( 76.13)\n",
            "==> Train Accuracy: Acc@1 44.532 || Acc@5 76.132\n",
            "==> Test Accuracy:  Acc@1 48.500 || Acc@5 80.650\n",
            "==> 72.30 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 16, lr: 0.1 -----\n",
            "Epoch: [16][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.9839e+00 (1.9839e+00)\tAcc@1  43.75 ( 43.75)\tAcc@5  73.44 ( 73.44)\n",
            "Epoch: [16][ 30/391]\tTime  0.172 ( 0.176)\tLoss 2.0664e+00 (1.9992e+00)\tAcc@1  34.38 ( 45.64)\tAcc@5  78.91 ( 77.75)\n",
            "Epoch: [16][ 60/391]\tTime  0.175 ( 0.175)\tLoss 2.1234e+00 (2.0111e+00)\tAcc@1  42.97 ( 45.74)\tAcc@5  71.09 ( 77.28)\n",
            "Epoch: [16][ 90/391]\tTime  0.174 ( 0.175)\tLoss 2.0286e+00 (2.0167e+00)\tAcc@1  49.22 ( 45.72)\tAcc@5  75.78 ( 77.20)\n",
            "Epoch: [16][120/391]\tTime  0.173 ( 0.174)\tLoss 2.0626e+00 (2.0264e+00)\tAcc@1  42.97 ( 45.70)\tAcc@5  73.44 ( 77.07)\n",
            "Epoch: [16][150/391]\tTime  0.174 ( 0.174)\tLoss 2.0382e+00 (2.0341e+00)\tAcc@1  43.75 ( 45.50)\tAcc@5  75.78 ( 76.90)\n",
            "Epoch: [16][180/391]\tTime  0.176 ( 0.174)\tLoss 1.9867e+00 (2.0318e+00)\tAcc@1  43.75 ( 45.48)\tAcc@5  79.69 ( 77.01)\n",
            "Epoch: [16][210/391]\tTime  0.176 ( 0.174)\tLoss 1.8565e+00 (2.0288e+00)\tAcc@1  50.78 ( 45.45)\tAcc@5  78.91 ( 77.11)\n",
            "Epoch: [16][240/391]\tTime  0.173 ( 0.174)\tLoss 1.9983e+00 (2.0343e+00)\tAcc@1  51.56 ( 45.36)\tAcc@5  78.12 ( 77.06)\n",
            "Epoch: [16][270/391]\tTime  0.173 ( 0.174)\tLoss 2.1262e+00 (2.0356e+00)\tAcc@1  42.97 ( 45.40)\tAcc@5  72.66 ( 76.94)\n",
            "Epoch: [16][300/391]\tTime  0.174 ( 0.174)\tLoss 1.9530e+00 (2.0393e+00)\tAcc@1  49.22 ( 45.35)\tAcc@5  76.56 ( 76.89)\n",
            "Epoch: [16][330/391]\tTime  0.173 ( 0.174)\tLoss 1.9291e+00 (2.0432e+00)\tAcc@1  47.66 ( 45.26)\tAcc@5  78.91 ( 76.78)\n",
            "Epoch: [16][360/391]\tTime  0.170 ( 0.174)\tLoss 1.9373e+00 (2.0438e+00)\tAcc@1  47.66 ( 45.24)\tAcc@5  78.12 ( 76.81)\n",
            "Epoch: [16][390/391]\tTime  0.156 ( 0.174)\tLoss 1.8110e+00 (2.0440e+00)\tAcc@1  45.00 ( 45.23)\tAcc@5  82.50 ( 76.75)\n",
            "==> Train Accuracy: Acc@1 45.226 || Acc@5 76.754\n",
            "==> Test Accuracy:  Acc@1 44.150 || Acc@5 75.970\n",
            "==> 72.46 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 17, lr: 0.1 -----\n",
            "Epoch: [17][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.9404e+00 (1.9404e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  75.78 ( 75.78)\n",
            "Epoch: [17][ 30/391]\tTime  0.175 ( 0.177)\tLoss 2.1029e+00 (1.9679e+00)\tAcc@1  44.53 ( 46.24)\tAcc@5  73.44 ( 77.42)\n",
            "Epoch: [17][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.9191e+00 (1.9841e+00)\tAcc@1  44.53 ( 46.50)\tAcc@5  82.81 ( 77.42)\n",
            "Epoch: [17][ 90/391]\tTime  0.175 ( 0.175)\tLoss 2.0622e+00 (2.0058e+00)\tAcc@1  41.41 ( 46.21)\tAcc@5  78.12 ( 77.08)\n",
            "Epoch: [17][120/391]\tTime  0.174 ( 0.175)\tLoss 1.9987e+00 (2.0031e+00)\tAcc@1  44.53 ( 46.19)\tAcc@5  82.03 ( 77.12)\n",
            "Epoch: [17][150/391]\tTime  0.174 ( 0.175)\tLoss 2.0096e+00 (2.0016e+00)\tAcc@1  42.97 ( 46.17)\tAcc@5  77.34 ( 77.24)\n",
            "Epoch: [17][180/391]\tTime  0.171 ( 0.175)\tLoss 2.1552e+00 (2.0145e+00)\tAcc@1  40.62 ( 45.90)\tAcc@5  74.22 ( 77.02)\n",
            "Epoch: [17][210/391]\tTime  0.174 ( 0.174)\tLoss 1.8024e+00 (2.0102e+00)\tAcc@1  46.88 ( 46.06)\tAcc@5  82.03 ( 77.14)\n",
            "Epoch: [17][240/391]\tTime  0.171 ( 0.174)\tLoss 2.1657e+00 (2.0113e+00)\tAcc@1  42.19 ( 46.17)\tAcc@5  72.66 ( 77.13)\n",
            "Epoch: [17][270/391]\tTime  0.175 ( 0.174)\tLoss 2.0353e+00 (2.0155e+00)\tAcc@1  46.09 ( 45.95)\tAcc@5  80.47 ( 77.07)\n",
            "Epoch: [17][300/391]\tTime  0.174 ( 0.174)\tLoss 2.1223e+00 (2.0191e+00)\tAcc@1  48.44 ( 45.93)\tAcc@5  75.00 ( 77.01)\n",
            "Epoch: [17][330/391]\tTime  0.176 ( 0.174)\tLoss 2.2522e+00 (2.0206e+00)\tAcc@1  38.28 ( 46.00)\tAcc@5  74.22 ( 77.00)\n",
            "Epoch: [17][360/391]\tTime  0.176 ( 0.174)\tLoss 2.0417e+00 (2.0176e+00)\tAcc@1  48.44 ( 46.07)\tAcc@5  78.12 ( 77.03)\n",
            "Epoch: [17][390/391]\tTime  0.155 ( 0.174)\tLoss 2.1211e+00 (2.0185e+00)\tAcc@1  40.00 ( 45.95)\tAcc@5  76.25 ( 76.99)\n",
            "==> Train Accuracy: Acc@1 45.954 || Acc@5 76.994\n",
            "==> Test Accuracy:  Acc@1 49.290 || Acc@5 79.020\n",
            "==> 72.55 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 18, lr: 0.1 -----\n",
            "Epoch: [18][  0/391]\tTime  0.246 ( 0.246)\tLoss 1.9620e+00 (1.9620e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  75.78 ( 75.78)\n",
            "Epoch: [18][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.9740e+00 (1.9793e+00)\tAcc@1  50.00 ( 47.05)\tAcc@5  76.56 ( 77.57)\n",
            "Epoch: [18][ 60/391]\tTime  0.174 ( 0.175)\tLoss 2.1907e+00 (1.9685e+00)\tAcc@1  41.41 ( 47.81)\tAcc@5  72.66 ( 77.70)\n",
            "Epoch: [18][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.9355e+00 (1.9582e+00)\tAcc@1  44.53 ( 47.70)\tAcc@5  78.91 ( 78.21)\n",
            "Epoch: [18][120/391]\tTime  0.173 ( 0.175)\tLoss 1.8906e+00 (1.9721e+00)\tAcc@1  50.00 ( 47.34)\tAcc@5  80.47 ( 77.85)\n",
            "Epoch: [18][150/391]\tTime  0.173 ( 0.175)\tLoss 1.9296e+00 (1.9767e+00)\tAcc@1  50.78 ( 47.27)\tAcc@5  76.56 ( 77.80)\n",
            "Epoch: [18][180/391]\tTime  0.175 ( 0.175)\tLoss 1.8855e+00 (1.9818e+00)\tAcc@1  46.88 ( 47.25)\tAcc@5  80.47 ( 77.71)\n",
            "Epoch: [18][210/391]\tTime  0.173 ( 0.175)\tLoss 2.3214e+00 (1.9884e+00)\tAcc@1  35.16 ( 47.03)\tAcc@5  75.00 ( 77.58)\n",
            "Epoch: [18][240/391]\tTime  0.174 ( 0.175)\tLoss 2.0637e+00 (1.9955e+00)\tAcc@1  46.88 ( 46.72)\tAcc@5  78.12 ( 77.42)\n",
            "Epoch: [18][270/391]\tTime  0.177 ( 0.175)\tLoss 1.7174e+00 (1.9988e+00)\tAcc@1  55.47 ( 46.63)\tAcc@5  82.81 ( 77.32)\n",
            "Epoch: [18][300/391]\tTime  0.173 ( 0.174)\tLoss 2.2954e+00 (1.9940e+00)\tAcc@1  42.19 ( 46.81)\tAcc@5  70.31 ( 77.43)\n",
            "Epoch: [18][330/391]\tTime  0.175 ( 0.174)\tLoss 1.9270e+00 (1.9963e+00)\tAcc@1  51.56 ( 46.71)\tAcc@5  78.12 ( 77.39)\n",
            "Epoch: [18][360/391]\tTime  0.174 ( 0.174)\tLoss 1.9496e+00 (2.0023e+00)\tAcc@1  50.00 ( 46.60)\tAcc@5  78.12 ( 77.26)\n",
            "Epoch: [18][390/391]\tTime  0.156 ( 0.174)\tLoss 2.2926e+00 (2.0005e+00)\tAcc@1  42.50 ( 46.64)\tAcc@5  68.75 ( 77.30)\n",
            "==> Train Accuracy: Acc@1 46.638 || Acc@5 77.300\n",
            "==> Test Accuracy:  Acc@1 51.600 || Acc@5 82.200\n",
            "==> 72.57 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 19, lr: 0.1 -----\n",
            "Epoch: [19][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.8685e+00 (1.8685e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [19][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.7690e+00 (1.9246e+00)\tAcc@1  53.91 ( 47.66)\tAcc@5  82.03 ( 78.33)\n",
            "Epoch: [19][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.8944e+00 (1.9317e+00)\tAcc@1  49.22 ( 47.90)\tAcc@5  79.69 ( 78.64)\n",
            "Epoch: [19][ 90/391]\tTime  0.173 ( 0.175)\tLoss 2.0402e+00 (1.9401e+00)\tAcc@1  39.84 ( 47.74)\tAcc@5  76.56 ( 78.45)\n",
            "Epoch: [19][120/391]\tTime  0.174 ( 0.175)\tLoss 2.2519e+00 (1.9397e+00)\tAcc@1  38.28 ( 47.72)\tAcc@5  74.22 ( 78.64)\n",
            "Epoch: [19][150/391]\tTime  0.175 ( 0.175)\tLoss 1.9828e+00 (1.9391e+00)\tAcc@1  50.78 ( 47.65)\tAcc@5  75.78 ( 78.59)\n",
            "Epoch: [19][180/391]\tTime  0.176 ( 0.175)\tLoss 2.0820e+00 (1.9530e+00)\tAcc@1  50.00 ( 47.24)\tAcc@5  77.34 ( 78.28)\n",
            "Epoch: [19][210/391]\tTime  0.175 ( 0.175)\tLoss 1.8316e+00 (1.9625e+00)\tAcc@1  53.12 ( 47.01)\tAcc@5  80.47 ( 78.21)\n",
            "Epoch: [19][240/391]\tTime  0.174 ( 0.175)\tLoss 2.0499e+00 (1.9607e+00)\tAcc@1  44.53 ( 47.07)\tAcc@5  77.34 ( 78.17)\n",
            "Epoch: [19][270/391]\tTime  0.175 ( 0.175)\tLoss 2.1196e+00 (1.9656e+00)\tAcc@1  39.84 ( 47.01)\tAcc@5  74.22 ( 78.10)\n",
            "Epoch: [19][300/391]\tTime  0.176 ( 0.175)\tLoss 2.0753e+00 (1.9685e+00)\tAcc@1  46.09 ( 46.93)\tAcc@5  70.31 ( 78.07)\n",
            "Epoch: [19][330/391]\tTime  0.175 ( 0.175)\tLoss 1.8948e+00 (1.9703e+00)\tAcc@1  48.44 ( 46.95)\tAcc@5  79.69 ( 78.06)\n",
            "Epoch: [19][360/391]\tTime  0.173 ( 0.175)\tLoss 1.7188e+00 (1.9681e+00)\tAcc@1  50.00 ( 46.94)\tAcc@5  83.59 ( 78.12)\n",
            "Epoch: [19][390/391]\tTime  0.157 ( 0.175)\tLoss 1.9229e+00 (1.9700e+00)\tAcc@1  51.25 ( 46.88)\tAcc@5  77.50 ( 78.06)\n",
            "==> Train Accuracy: Acc@1 46.884 || Acc@5 78.056\n",
            "==> Test Accuracy:  Acc@1 45.620 || Acc@5 77.870\n",
            "==> 72.63 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 20, lr: 0.1 -----\n",
            "Epoch: [20][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.9905e+00 (1.9905e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  75.78 ( 75.78)\n",
            "Epoch: [20][ 30/391]\tTime  0.170 ( 0.177)\tLoss 2.0452e+00 (1.9320e+00)\tAcc@1  46.88 ( 48.08)\tAcc@5  78.12 ( 78.60)\n",
            "Epoch: [20][ 60/391]\tTime  0.174 ( 0.176)\tLoss 1.9573e+00 (1.9409e+00)\tAcc@1  45.31 ( 47.80)\tAcc@5  81.25 ( 78.60)\n",
            "Epoch: [20][ 90/391]\tTime  0.175 ( 0.175)\tLoss 2.2274e+00 (1.9559e+00)\tAcc@1  40.62 ( 47.56)\tAcc@5  74.22 ( 78.37)\n",
            "Epoch: [20][120/391]\tTime  0.176 ( 0.175)\tLoss 1.7952e+00 (1.9568e+00)\tAcc@1  49.22 ( 47.37)\tAcc@5  80.47 ( 78.45)\n",
            "Epoch: [20][150/391]\tTime  0.175 ( 0.175)\tLoss 2.2420e+00 (1.9546e+00)\tAcc@1  42.97 ( 47.50)\tAcc@5  75.00 ( 78.45)\n",
            "Epoch: [20][180/391]\tTime  0.172 ( 0.175)\tLoss 1.9252e+00 (1.9515e+00)\tAcc@1  46.88 ( 47.38)\tAcc@5  79.69 ( 78.49)\n",
            "Epoch: [20][210/391]\tTime  0.173 ( 0.175)\tLoss 2.0152e+00 (1.9557e+00)\tAcc@1  41.41 ( 47.33)\tAcc@5  78.91 ( 78.38)\n",
            "Epoch: [20][240/391]\tTime  0.173 ( 0.175)\tLoss 2.1471e+00 (1.9594e+00)\tAcc@1  42.19 ( 47.24)\tAcc@5  76.56 ( 78.21)\n",
            "Epoch: [20][270/391]\tTime  0.175 ( 0.175)\tLoss 1.7596e+00 (1.9573e+00)\tAcc@1  42.97 ( 47.30)\tAcc@5  82.81 ( 78.27)\n",
            "Epoch: [20][300/391]\tTime  0.175 ( 0.175)\tLoss 1.8493e+00 (1.9570e+00)\tAcc@1  47.66 ( 47.38)\tAcc@5  83.59 ( 78.27)\n",
            "Epoch: [20][330/391]\tTime  0.173 ( 0.175)\tLoss 1.7021e+00 (1.9600e+00)\tAcc@1  54.69 ( 47.28)\tAcc@5  78.12 ( 78.16)\n",
            "Epoch: [20][360/391]\tTime  0.176 ( 0.175)\tLoss 1.9430e+00 (1.9602e+00)\tAcc@1  43.75 ( 47.19)\tAcc@5  80.47 ( 78.22)\n",
            "Epoch: [20][390/391]\tTime  0.157 ( 0.175)\tLoss 2.2358e+00 (1.9612e+00)\tAcc@1  45.00 ( 47.18)\tAcc@5  72.50 ( 78.21)\n",
            "==> Train Accuracy: Acc@1 47.182 || Acc@5 78.212\n",
            "==> Test Accuracy:  Acc@1 54.400 || Acc@5 83.660\n",
            "==> 72.62 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 21, lr: 0.1 -----\n",
            "Epoch: [21][  0/391]\tTime  0.263 ( 0.263)\tLoss 2.0574e+00 (2.0574e+00)\tAcc@1  40.62 ( 40.62)\tAcc@5  76.56 ( 76.56)\n",
            "Epoch: [21][ 30/391]\tTime  0.172 ( 0.177)\tLoss 1.9861e+00 (1.8729e+00)\tAcc@1  45.31 ( 48.29)\tAcc@5  82.03 ( 80.24)\n",
            "Epoch: [21][ 60/391]\tTime  0.174 ( 0.175)\tLoss 2.1217e+00 (1.8729e+00)\tAcc@1  45.31 ( 48.80)\tAcc@5  75.00 ( 79.55)\n",
            "Epoch: [21][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.9474e+00 (1.9106e+00)\tAcc@1  49.22 ( 48.27)\tAcc@5  76.56 ( 79.01)\n",
            "Epoch: [21][120/391]\tTime  0.174 ( 0.175)\tLoss 1.9673e+00 (1.9161e+00)\tAcc@1  39.06 ( 48.06)\tAcc@5  77.34 ( 78.96)\n",
            "Epoch: [21][150/391]\tTime  0.174 ( 0.175)\tLoss 2.0280e+00 (1.9185e+00)\tAcc@1  42.19 ( 47.97)\tAcc@5  78.91 ( 78.93)\n",
            "Epoch: [21][180/391]\tTime  0.176 ( 0.175)\tLoss 1.8071e+00 (1.9256e+00)\tAcc@1  50.78 ( 47.89)\tAcc@5  78.91 ( 78.82)\n",
            "Epoch: [21][210/391]\tTime  0.173 ( 0.175)\tLoss 1.8567e+00 (1.9312e+00)\tAcc@1  47.66 ( 47.82)\tAcc@5  82.03 ( 78.72)\n",
            "Epoch: [21][240/391]\tTime  0.175 ( 0.175)\tLoss 2.1933e+00 (1.9288e+00)\tAcc@1  44.53 ( 47.89)\tAcc@5  72.66 ( 78.81)\n",
            "Epoch: [21][270/391]\tTime  0.173 ( 0.175)\tLoss 1.8583e+00 (1.9270e+00)\tAcc@1  49.22 ( 47.94)\tAcc@5  77.34 ( 78.78)\n",
            "Epoch: [21][300/391]\tTime  0.172 ( 0.175)\tLoss 1.8514e+00 (1.9306e+00)\tAcc@1  49.22 ( 47.85)\tAcc@5  79.69 ( 78.70)\n",
            "Epoch: [21][330/391]\tTime  0.174 ( 0.175)\tLoss 1.8789e+00 (1.9362e+00)\tAcc@1  53.91 ( 47.76)\tAcc@5  80.47 ( 78.58)\n",
            "Epoch: [21][360/391]\tTime  0.177 ( 0.175)\tLoss 1.9055e+00 (1.9390e+00)\tAcc@1  47.66 ( 47.69)\tAcc@5  77.34 ( 78.52)\n",
            "Epoch: [21][390/391]\tTime  0.156 ( 0.175)\tLoss 2.1214e+00 (1.9418e+00)\tAcc@1  41.25 ( 47.62)\tAcc@5  77.50 ( 78.47)\n",
            "==> Train Accuracy: Acc@1 47.620 || Acc@5 78.470\n",
            "==> Test Accuracy:  Acc@1 50.580 || Acc@5 81.510\n",
            "==> 72.67 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 22, lr: 0.1 -----\n",
            "Epoch: [22][  0/391]\tTime  0.256 ( 0.256)\tLoss 2.0698e+00 (2.0698e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [22][ 30/391]\tTime  0.176 ( 0.177)\tLoss 2.0446e+00 (1.8700e+00)\tAcc@1  39.06 ( 49.09)\tAcc@5  78.12 ( 79.64)\n",
            "Epoch: [22][ 60/391]\tTime  0.175 ( 0.176)\tLoss 2.0619e+00 (1.9135e+00)\tAcc@1  41.41 ( 48.26)\tAcc@5  74.22 ( 78.82)\n",
            "Epoch: [22][ 90/391]\tTime  0.172 ( 0.175)\tLoss 1.8602e+00 (1.9111e+00)\tAcc@1  49.22 ( 48.33)\tAcc@5  81.25 ( 79.15)\n",
            "Epoch: [22][120/391]\tTime  0.174 ( 0.175)\tLoss 1.8109e+00 (1.9173e+00)\tAcc@1  50.78 ( 48.41)\tAcc@5  80.47 ( 78.79)\n",
            "Epoch: [22][150/391]\tTime  0.176 ( 0.175)\tLoss 2.0607e+00 (1.9127e+00)\tAcc@1  42.97 ( 48.44)\tAcc@5  76.56 ( 79.00)\n",
            "Epoch: [22][180/391]\tTime  0.175 ( 0.175)\tLoss 1.8029e+00 (1.9158e+00)\tAcc@1  52.34 ( 48.38)\tAcc@5  82.81 ( 78.88)\n",
            "Epoch: [22][210/391]\tTime  0.176 ( 0.175)\tLoss 1.8104e+00 (1.9180e+00)\tAcc@1  50.78 ( 48.38)\tAcc@5  80.47 ( 78.81)\n",
            "Epoch: [22][240/391]\tTime  0.174 ( 0.175)\tLoss 2.0911e+00 (1.9262e+00)\tAcc@1  46.88 ( 48.19)\tAcc@5  77.34 ( 78.60)\n",
            "Epoch: [22][270/391]\tTime  0.175 ( 0.175)\tLoss 1.9944e+00 (1.9243e+00)\tAcc@1  47.66 ( 48.21)\tAcc@5  79.69 ( 78.68)\n",
            "Epoch: [22][300/391]\tTime  0.171 ( 0.175)\tLoss 1.9040e+00 (1.9258e+00)\tAcc@1  51.56 ( 48.18)\tAcc@5  77.34 ( 78.62)\n",
            "Epoch: [22][330/391]\tTime  0.173 ( 0.175)\tLoss 1.7775e+00 (1.9237e+00)\tAcc@1  49.22 ( 48.26)\tAcc@5  83.59 ( 78.68)\n",
            "Epoch: [22][360/391]\tTime  0.174 ( 0.175)\tLoss 1.9180e+00 (1.9243e+00)\tAcc@1  47.66 ( 48.25)\tAcc@5  80.47 ( 78.68)\n",
            "Epoch: [22][390/391]\tTime  0.157 ( 0.174)\tLoss 1.9810e+00 (1.9245e+00)\tAcc@1  51.25 ( 48.26)\tAcc@5  71.25 ( 78.73)\n",
            "==> Train Accuracy: Acc@1 48.256 || Acc@5 78.726\n",
            "==> Test Accuracy:  Acc@1 53.410 || Acc@5 83.300\n",
            "==> 72.55 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 23, lr: 0.1 -----\n",
            "Epoch: [23][  0/391]\tTime  0.279 ( 0.279)\tLoss 1.9811e+00 (1.9811e+00)\tAcc@1  45.31 ( 45.31)\tAcc@5  77.34 ( 77.34)\n",
            "Epoch: [23][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.7087e+00 (1.8889e+00)\tAcc@1  50.78 ( 48.79)\tAcc@5  85.16 ( 79.86)\n",
            "Epoch: [23][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.5718e+00 (1.8919e+00)\tAcc@1  56.25 ( 48.89)\tAcc@5  84.38 ( 79.62)\n",
            "Epoch: [23][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.6861e+00 (1.8882e+00)\tAcc@1  49.22 ( 48.70)\tAcc@5  82.81 ( 79.44)\n",
            "Epoch: [23][120/391]\tTime  0.174 ( 0.175)\tLoss 1.8689e+00 (1.8924e+00)\tAcc@1  46.88 ( 48.82)\tAcc@5  80.47 ( 79.33)\n",
            "Epoch: [23][150/391]\tTime  0.172 ( 0.175)\tLoss 1.5872e+00 (1.8888e+00)\tAcc@1  57.03 ( 48.98)\tAcc@5  86.72 ( 79.48)\n",
            "Epoch: [23][180/391]\tTime  0.175 ( 0.174)\tLoss 1.9614e+00 (1.9016e+00)\tAcc@1  46.09 ( 48.52)\tAcc@5  76.56 ( 79.22)\n",
            "Epoch: [23][210/391]\tTime  0.176 ( 0.174)\tLoss 1.9319e+00 (1.8987e+00)\tAcc@1  55.47 ( 48.64)\tAcc@5  76.56 ( 79.34)\n",
            "Epoch: [23][240/391]\tTime  0.177 ( 0.174)\tLoss 1.6639e+00 (1.8991e+00)\tAcc@1  53.12 ( 48.64)\tAcc@5  82.81 ( 79.33)\n",
            "Epoch: [23][270/391]\tTime  0.175 ( 0.174)\tLoss 1.8452e+00 (1.9078e+00)\tAcc@1  50.00 ( 48.50)\tAcc@5  81.25 ( 79.19)\n",
            "Epoch: [23][300/391]\tTime  0.172 ( 0.174)\tLoss 1.7013e+00 (1.9154e+00)\tAcc@1  56.25 ( 48.27)\tAcc@5  85.16 ( 79.00)\n",
            "Epoch: [23][330/391]\tTime  0.174 ( 0.174)\tLoss 2.0633e+00 (1.9186e+00)\tAcc@1  46.09 ( 48.23)\tAcc@5  73.44 ( 78.92)\n",
            "Epoch: [23][360/391]\tTime  0.174 ( 0.174)\tLoss 2.0949e+00 (1.9202e+00)\tAcc@1  45.31 ( 48.26)\tAcc@5  75.00 ( 78.86)\n",
            "Epoch: [23][390/391]\tTime  0.158 ( 0.174)\tLoss 1.8340e+00 (1.9224e+00)\tAcc@1  43.75 ( 48.25)\tAcc@5  83.75 ( 78.82)\n",
            "==> Train Accuracy: Acc@1 48.252 || Acc@5 78.816\n",
            "==> Test Accuracy:  Acc@1 50.590 || Acc@5 81.080\n",
            "==> 72.49 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 24, lr: 0.1 -----\n",
            "Epoch: [24][  0/391]\tTime  0.258 ( 0.258)\tLoss 1.7374e+00 (1.7374e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  79.69 ( 79.69)\n",
            "Epoch: [24][ 30/391]\tTime  0.174 ( 0.176)\tLoss 2.0237e+00 (1.8263e+00)\tAcc@1  48.44 ( 50.63)\tAcc@5  75.78 ( 79.96)\n",
            "Epoch: [24][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.8923e+00 (1.8384e+00)\tAcc@1  52.34 ( 50.49)\tAcc@5  78.91 ( 79.82)\n",
            "Epoch: [24][ 90/391]\tTime  0.171 ( 0.175)\tLoss 1.6938e+00 (1.8691e+00)\tAcc@1  55.47 ( 50.00)\tAcc@5  83.59 ( 79.39)\n",
            "Epoch: [24][120/391]\tTime  0.175 ( 0.175)\tLoss 1.7470e+00 (1.8789e+00)\tAcc@1  51.56 ( 49.68)\tAcc@5  81.25 ( 79.27)\n",
            "Epoch: [24][150/391]\tTime  0.172 ( 0.175)\tLoss 1.9195e+00 (1.8782e+00)\tAcc@1  47.66 ( 49.57)\tAcc@5  80.47 ( 79.38)\n",
            "Epoch: [24][180/391]\tTime  0.174 ( 0.175)\tLoss 2.1018e+00 (1.8819e+00)\tAcc@1  42.19 ( 49.69)\tAcc@5  78.12 ( 79.46)\n",
            "Epoch: [24][210/391]\tTime  0.176 ( 0.175)\tLoss 2.0911e+00 (1.8828e+00)\tAcc@1  39.84 ( 49.53)\tAcc@5  71.88 ( 79.44)\n",
            "Epoch: [24][240/391]\tTime  0.172 ( 0.174)\tLoss 1.8565e+00 (1.8861e+00)\tAcc@1  50.78 ( 49.33)\tAcc@5  82.03 ( 79.42)\n",
            "Epoch: [24][270/391]\tTime  0.175 ( 0.174)\tLoss 1.8215e+00 (1.8899e+00)\tAcc@1  53.91 ( 49.23)\tAcc@5  76.56 ( 79.35)\n",
            "Epoch: [24][300/391]\tTime  0.176 ( 0.174)\tLoss 1.7567e+00 (1.8944e+00)\tAcc@1  57.03 ( 49.17)\tAcc@5  81.25 ( 79.32)\n",
            "Epoch: [24][330/391]\tTime  0.176 ( 0.174)\tLoss 1.9341e+00 (1.8964e+00)\tAcc@1  48.44 ( 49.16)\tAcc@5  81.25 ( 79.29)\n",
            "Epoch: [24][360/391]\tTime  0.174 ( 0.174)\tLoss 2.1297e+00 (1.8942e+00)\tAcc@1  44.53 ( 49.09)\tAcc@5  75.78 ( 79.29)\n",
            "Epoch: [24][390/391]\tTime  0.155 ( 0.174)\tLoss 1.9567e+00 (1.9001e+00)\tAcc@1  48.75 ( 48.97)\tAcc@5  76.25 ( 79.16)\n",
            "==> Train Accuracy: Acc@1 48.974 || Acc@5 79.162\n",
            "==> Test Accuracy:  Acc@1 51.220 || Acc@5 81.550\n",
            "==> 72.49 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 25, lr: 0.1 -----\n",
            "Epoch: [25][  0/391]\tTime  0.262 ( 0.262)\tLoss 1.8406e+00 (1.8406e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [25][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.7021e+00 (1.8584e+00)\tAcc@1  51.56 ( 49.97)\tAcc@5  85.16 ( 80.77)\n",
            "Epoch: [25][ 60/391]\tTime  0.173 ( 0.176)\tLoss 1.9169e+00 (1.8324e+00)\tAcc@1  50.78 ( 50.03)\tAcc@5  78.91 ( 80.93)\n",
            "Epoch: [25][ 90/391]\tTime  0.172 ( 0.175)\tLoss 1.8414e+00 (1.8479e+00)\tAcc@1  49.22 ( 49.88)\tAcc@5  77.34 ( 80.54)\n",
            "Epoch: [25][120/391]\tTime  0.174 ( 0.175)\tLoss 1.8763e+00 (1.8406e+00)\tAcc@1  50.00 ( 50.19)\tAcc@5  79.69 ( 80.40)\n",
            "Epoch: [25][150/391]\tTime  0.174 ( 0.175)\tLoss 1.7697e+00 (1.8536e+00)\tAcc@1  50.00 ( 49.84)\tAcc@5  82.03 ( 80.18)\n",
            "Epoch: [25][180/391]\tTime  0.174 ( 0.175)\tLoss 1.7975e+00 (1.8565e+00)\tAcc@1  52.34 ( 49.73)\tAcc@5  78.91 ( 80.11)\n",
            "Epoch: [25][210/391]\tTime  0.172 ( 0.175)\tLoss 1.9513e+00 (1.8622e+00)\tAcc@1  51.56 ( 49.59)\tAcc@5  75.78 ( 79.88)\n",
            "Epoch: [25][240/391]\tTime  0.172 ( 0.175)\tLoss 1.7804e+00 (1.8711e+00)\tAcc@1  49.22 ( 49.38)\tAcc@5  82.03 ( 79.66)\n",
            "Epoch: [25][270/391]\tTime  0.172 ( 0.175)\tLoss 2.2789e+00 (1.8750e+00)\tAcc@1  39.84 ( 49.24)\tAcc@5  73.44 ( 79.61)\n",
            "Epoch: [25][300/391]\tTime  0.174 ( 0.175)\tLoss 1.6290e+00 (1.8833e+00)\tAcc@1  53.12 ( 49.10)\tAcc@5  87.50 ( 79.43)\n",
            "Epoch: [25][330/391]\tTime  0.174 ( 0.175)\tLoss 1.5661e+00 (1.8869e+00)\tAcc@1  57.81 ( 49.00)\tAcc@5  85.94 ( 79.41)\n",
            "Epoch: [25][360/391]\tTime  0.174 ( 0.175)\tLoss 1.5761e+00 (1.8863e+00)\tAcc@1  56.25 ( 49.01)\tAcc@5  82.81 ( 79.40)\n",
            "Epoch: [25][390/391]\tTime  0.157 ( 0.174)\tLoss 1.7007e+00 (1.8846e+00)\tAcc@1  45.00 ( 49.04)\tAcc@5  83.75 ( 79.42)\n",
            "==> Train Accuracy: Acc@1 49.038 || Acc@5 79.422\n",
            "==> Test Accuracy:  Acc@1 50.840 || Acc@5 81.200\n",
            "==> 72.60 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 26, lr: 0.1 -----\n",
            "Epoch: [26][  0/391]\tTime  0.257 ( 0.257)\tLoss 1.8083e+00 (1.8083e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [26][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.6506e+00 (1.7960e+00)\tAcc@1  53.91 ( 51.11)\tAcc@5  84.38 ( 81.93)\n",
            "Epoch: [26][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.9262e+00 (1.8176e+00)\tAcc@1  42.19 ( 50.58)\tAcc@5  83.59 ( 81.19)\n",
            "Epoch: [26][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.7516e+00 (1.8312e+00)\tAcc@1  56.25 ( 50.22)\tAcc@5  79.69 ( 81.06)\n",
            "Epoch: [26][120/391]\tTime  0.174 ( 0.175)\tLoss 1.8959e+00 (1.8376e+00)\tAcc@1  51.56 ( 50.23)\tAcc@5  79.69 ( 80.86)\n",
            "Epoch: [26][150/391]\tTime  0.176 ( 0.175)\tLoss 1.7124e+00 (1.8444e+00)\tAcc@1  51.56 ( 49.97)\tAcc@5  85.16 ( 80.57)\n",
            "Epoch: [26][180/391]\tTime  0.172 ( 0.175)\tLoss 1.9852e+00 (1.8611e+00)\tAcc@1  51.56 ( 49.68)\tAcc@5  74.22 ( 80.17)\n",
            "Epoch: [26][210/391]\tTime  0.173 ( 0.175)\tLoss 1.7078e+00 (1.8575e+00)\tAcc@1  53.12 ( 49.64)\tAcc@5  80.47 ( 80.18)\n",
            "Epoch: [26][240/391]\tTime  0.176 ( 0.174)\tLoss 2.0020e+00 (1.8640e+00)\tAcc@1  48.44 ( 49.53)\tAcc@5  76.56 ( 80.05)\n",
            "Epoch: [26][270/391]\tTime  0.175 ( 0.174)\tLoss 1.7964e+00 (1.8691e+00)\tAcc@1  56.25 ( 49.43)\tAcc@5  78.12 ( 79.95)\n",
            "Epoch: [26][300/391]\tTime  0.176 ( 0.174)\tLoss 2.0496e+00 (1.8675e+00)\tAcc@1  45.31 ( 49.51)\tAcc@5  78.91 ( 79.87)\n",
            "Epoch: [26][330/391]\tTime  0.176 ( 0.174)\tLoss 1.8863e+00 (1.8642e+00)\tAcc@1  50.78 ( 49.55)\tAcc@5  78.91 ( 79.94)\n",
            "Epoch: [26][360/391]\tTime  0.173 ( 0.174)\tLoss 1.8560e+00 (1.8666e+00)\tAcc@1  51.56 ( 49.51)\tAcc@5  78.12 ( 79.82)\n",
            "Epoch: [26][390/391]\tTime  0.156 ( 0.174)\tLoss 2.0565e+00 (1.8690e+00)\tAcc@1  47.50 ( 49.44)\tAcc@5  76.25 ( 79.85)\n",
            "==> Train Accuracy: Acc@1 49.438 || Acc@5 79.848\n",
            "==> Test Accuracy:  Acc@1 51.510 || Acc@5 80.420\n",
            "==> 72.50 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 27, lr: 0.1 -----\n",
            "Epoch: [27][  0/391]\tTime  0.255 ( 0.255)\tLoss 1.8819e+00 (1.8819e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [27][ 30/391]\tTime  0.176 ( 0.177)\tLoss 2.0202e+00 (1.8782e+00)\tAcc@1  47.66 ( 48.89)\tAcc@5  77.34 ( 79.41)\n",
            "Epoch: [27][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.8378e+00 (1.8783e+00)\tAcc@1  46.88 ( 48.89)\tAcc@5  82.81 ( 79.50)\n",
            "Epoch: [27][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.8066e+00 (1.8783e+00)\tAcc@1  50.78 ( 48.98)\tAcc@5  81.25 ( 79.26)\n",
            "Epoch: [27][120/391]\tTime  0.173 ( 0.175)\tLoss 1.8778e+00 (1.8816e+00)\tAcc@1  51.56 ( 49.17)\tAcc@5  79.69 ( 79.20)\n",
            "Epoch: [27][150/391]\tTime  0.174 ( 0.175)\tLoss 1.8008e+00 (1.8798e+00)\tAcc@1  53.12 ( 49.19)\tAcc@5  75.00 ( 79.28)\n",
            "Epoch: [27][180/391]\tTime  0.173 ( 0.175)\tLoss 2.0478e+00 (1.8689e+00)\tAcc@1  45.31 ( 49.46)\tAcc@5  75.00 ( 79.40)\n",
            "Epoch: [27][210/391]\tTime  0.176 ( 0.174)\tLoss 1.7197e+00 (1.8689e+00)\tAcc@1  52.34 ( 49.40)\tAcc@5  82.81 ( 79.47)\n",
            "Epoch: [27][240/391]\tTime  0.173 ( 0.174)\tLoss 1.7426e+00 (1.8718e+00)\tAcc@1  52.34 ( 49.35)\tAcc@5  81.25 ( 79.44)\n",
            "Epoch: [27][270/391]\tTime  0.174 ( 0.174)\tLoss 2.0642e+00 (1.8717e+00)\tAcc@1  46.09 ( 49.22)\tAcc@5  77.34 ( 79.46)\n",
            "Epoch: [27][300/391]\tTime  0.173 ( 0.174)\tLoss 2.0756e+00 (1.8729e+00)\tAcc@1  41.41 ( 49.17)\tAcc@5  73.44 ( 79.51)\n",
            "Epoch: [27][330/391]\tTime  0.174 ( 0.174)\tLoss 2.0803e+00 (1.8694e+00)\tAcc@1  46.88 ( 49.31)\tAcc@5  75.00 ( 79.60)\n",
            "Epoch: [27][360/391]\tTime  0.175 ( 0.174)\tLoss 2.0369e+00 (1.8719e+00)\tAcc@1  46.88 ( 49.21)\tAcc@5  75.00 ( 79.55)\n",
            "Epoch: [27][390/391]\tTime  0.157 ( 0.174)\tLoss 1.7625e+00 (1.8724e+00)\tAcc@1  50.00 ( 49.17)\tAcc@5  81.25 ( 79.55)\n",
            "==> Train Accuracy: Acc@1 49.172 || Acc@5 79.548\n",
            "==> Test Accuracy:  Acc@1 50.540 || Acc@5 81.270\n",
            "==> 72.47 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 28, lr: 0.1 -----\n",
            "Epoch: [28][  0/391]\tTime  0.255 ( 0.255)\tLoss 1.9413e+00 (1.9413e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  80.47 ( 80.47)\n",
            "Epoch: [28][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.9082e+00 (1.7886e+00)\tAcc@1  47.66 ( 51.03)\tAcc@5  79.69 ( 82.06)\n",
            "Epoch: [28][ 60/391]\tTime  0.171 ( 0.175)\tLoss 2.2352e+00 (1.8458e+00)\tAcc@1  43.75 ( 49.87)\tAcc@5  75.00 ( 80.39)\n",
            "Epoch: [28][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.7669e+00 (1.8499e+00)\tAcc@1  46.88 ( 49.56)\tAcc@5  85.94 ( 80.38)\n",
            "Epoch: [28][120/391]\tTime  0.174 ( 0.175)\tLoss 1.8093e+00 (1.8497e+00)\tAcc@1  53.12 ( 49.70)\tAcc@5  81.25 ( 80.29)\n",
            "Epoch: [28][150/391]\tTime  0.174 ( 0.174)\tLoss 1.8178e+00 (1.8570e+00)\tAcc@1  51.56 ( 49.53)\tAcc@5  79.69 ( 80.22)\n",
            "Epoch: [28][180/391]\tTime  0.174 ( 0.174)\tLoss 2.0012e+00 (1.8675e+00)\tAcc@1  47.66 ( 49.31)\tAcc@5  76.56 ( 80.04)\n",
            "Epoch: [28][210/391]\tTime  0.172 ( 0.174)\tLoss 1.5202e+00 (1.8653e+00)\tAcc@1  58.59 ( 49.49)\tAcc@5  82.81 ( 80.04)\n",
            "Epoch: [28][240/391]\tTime  0.172 ( 0.174)\tLoss 1.8833e+00 (1.8673e+00)\tAcc@1  50.00 ( 49.60)\tAcc@5  82.03 ( 79.96)\n",
            "Epoch: [28][270/391]\tTime  0.176 ( 0.174)\tLoss 1.9182e+00 (1.8627e+00)\tAcc@1  53.12 ( 49.78)\tAcc@5  73.44 ( 80.06)\n",
            "Epoch: [28][300/391]\tTime  0.175 ( 0.174)\tLoss 1.7475e+00 (1.8614e+00)\tAcc@1  54.69 ( 49.76)\tAcc@5  79.69 ( 80.07)\n",
            "Epoch: [28][330/391]\tTime  0.173 ( 0.174)\tLoss 1.9980e+00 (1.8604e+00)\tAcc@1  46.88 ( 49.71)\tAcc@5  82.81 ( 80.11)\n",
            "Epoch: [28][360/391]\tTime  0.173 ( 0.174)\tLoss 1.7746e+00 (1.8611e+00)\tAcc@1  51.56 ( 49.68)\tAcc@5  80.47 ( 80.10)\n",
            "Epoch: [28][390/391]\tTime  0.162 ( 0.174)\tLoss 2.1726e+00 (1.8607e+00)\tAcc@1  41.25 ( 49.64)\tAcc@5  72.50 ( 80.02)\n",
            "==> Train Accuracy: Acc@1 49.640 || Acc@5 80.018\n",
            "==> Test Accuracy:  Acc@1 55.330 || Acc@5 84.520\n",
            "==> 72.43 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 29, lr: 0.1 -----\n",
            "Epoch: [29][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.9486e+00 (1.9486e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  81.25 ( 81.25)\n",
            "Epoch: [29][ 30/391]\tTime  0.175 ( 0.176)\tLoss 2.1054e+00 (1.8380e+00)\tAcc@1  45.31 ( 50.33)\tAcc@5  75.78 ( 80.29)\n",
            "Epoch: [29][ 60/391]\tTime  0.178 ( 0.175)\tLoss 2.0771e+00 (1.8284e+00)\tAcc@1  43.75 ( 50.90)\tAcc@5  75.00 ( 80.38)\n",
            "Epoch: [29][ 90/391]\tTime  0.170 ( 0.175)\tLoss 2.2923e+00 (1.8523e+00)\tAcc@1  37.50 ( 50.09)\tAcc@5  72.66 ( 80.44)\n",
            "Epoch: [29][120/391]\tTime  0.174 ( 0.175)\tLoss 1.7895e+00 (1.8654e+00)\tAcc@1  47.66 ( 49.82)\tAcc@5  85.94 ( 80.13)\n",
            "Epoch: [29][150/391]\tTime  0.173 ( 0.175)\tLoss 1.9585e+00 (1.8487e+00)\tAcc@1  46.09 ( 50.22)\tAcc@5  76.56 ( 80.38)\n",
            "Epoch: [29][180/391]\tTime  0.175 ( 0.174)\tLoss 1.8864e+00 (1.8445e+00)\tAcc@1  43.75 ( 50.14)\tAcc@5  78.12 ( 80.49)\n",
            "Epoch: [29][210/391]\tTime  0.172 ( 0.174)\tLoss 1.5670e+00 (1.8469e+00)\tAcc@1  53.91 ( 49.95)\tAcc@5  85.16 ( 80.35)\n",
            "Epoch: [29][240/391]\tTime  0.175 ( 0.174)\tLoss 2.0384e+00 (1.8473e+00)\tAcc@1  43.75 ( 49.99)\tAcc@5  81.25 ( 80.40)\n",
            "Epoch: [29][270/391]\tTime  0.174 ( 0.174)\tLoss 2.0427e+00 (1.8477e+00)\tAcc@1  49.22 ( 49.86)\tAcc@5  80.47 ( 80.44)\n",
            "Epoch: [29][300/391]\tTime  0.175 ( 0.174)\tLoss 1.9308e+00 (1.8466e+00)\tAcc@1  46.88 ( 49.97)\tAcc@5  78.12 ( 80.35)\n",
            "Epoch: [29][330/391]\tTime  0.175 ( 0.174)\tLoss 1.6308e+00 (1.8513e+00)\tAcc@1  58.59 ( 49.95)\tAcc@5  85.16 ( 80.19)\n",
            "Epoch: [29][360/391]\tTime  0.174 ( 0.174)\tLoss 2.0782e+00 (1.8550e+00)\tAcc@1  42.97 ( 49.87)\tAcc@5  75.78 ( 80.11)\n",
            "Epoch: [29][390/391]\tTime  0.158 ( 0.174)\tLoss 1.9490e+00 (1.8548e+00)\tAcc@1  53.75 ( 49.86)\tAcc@5  75.00 ( 80.12)\n",
            "==> Train Accuracy: Acc@1 49.864 || Acc@5 80.118\n",
            "==> Test Accuracy:  Acc@1 54.910 || Acc@5 84.980\n",
            "==> 72.56 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 30, lr: 0.1 -----\n",
            "Epoch: [30][  0/391]\tTime  0.260 ( 0.260)\tLoss 1.9855e+00 (1.9855e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  74.22 ( 74.22)\n",
            "Epoch: [30][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.7520e+00 (1.8137e+00)\tAcc@1  48.44 ( 50.71)\tAcc@5  82.81 ( 81.00)\n",
            "Epoch: [30][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.8803e+00 (1.8096e+00)\tAcc@1  53.12 ( 51.13)\tAcc@5  77.34 ( 80.33)\n",
            "Epoch: [30][ 90/391]\tTime  0.176 ( 0.175)\tLoss 1.8586e+00 (1.8248e+00)\tAcc@1  50.78 ( 50.94)\tAcc@5  78.12 ( 80.04)\n",
            "Epoch: [30][120/391]\tTime  0.176 ( 0.175)\tLoss 1.7970e+00 (1.8209e+00)\tAcc@1  54.69 ( 50.92)\tAcc@5  79.69 ( 80.02)\n",
            "Epoch: [30][150/391]\tTime  0.174 ( 0.175)\tLoss 1.8847e+00 (1.8204e+00)\tAcc@1  47.66 ( 50.84)\tAcc@5  78.12 ( 80.12)\n",
            "Epoch: [30][180/391]\tTime  0.175 ( 0.175)\tLoss 1.9070e+00 (1.8197e+00)\tAcc@1  50.78 ( 50.82)\tAcc@5  77.34 ( 80.29)\n",
            "Epoch: [30][210/391]\tTime  0.173 ( 0.175)\tLoss 1.8979e+00 (1.8272e+00)\tAcc@1  50.00 ( 50.57)\tAcc@5  77.34 ( 80.18)\n",
            "Epoch: [30][240/391]\tTime  0.174 ( 0.175)\tLoss 2.0286e+00 (1.8271e+00)\tAcc@1  45.31 ( 50.58)\tAcc@5  76.56 ( 80.18)\n",
            "Epoch: [30][270/391]\tTime  0.174 ( 0.175)\tLoss 1.8783e+00 (1.8293e+00)\tAcc@1  51.56 ( 50.62)\tAcc@5  80.47 ( 80.20)\n",
            "Epoch: [30][300/391]\tTime  0.174 ( 0.175)\tLoss 1.8221e+00 (1.8294e+00)\tAcc@1  54.69 ( 50.60)\tAcc@5  82.03 ( 80.22)\n",
            "Epoch: [30][330/391]\tTime  0.176 ( 0.175)\tLoss 2.0085e+00 (1.8331e+00)\tAcc@1  49.22 ( 50.50)\tAcc@5  76.56 ( 80.12)\n",
            "Epoch: [30][360/391]\tTime  0.175 ( 0.175)\tLoss 1.9049e+00 (1.8334e+00)\tAcc@1  46.88 ( 50.52)\tAcc@5  75.78 ( 80.12)\n",
            "Epoch: [30][390/391]\tTime  0.157 ( 0.174)\tLoss 2.0066e+00 (1.8358e+00)\tAcc@1  53.75 ( 50.49)\tAcc@5  82.50 ( 80.09)\n",
            "==> Train Accuracy: Acc@1 50.486 || Acc@5 80.086\n",
            "==> Test Accuracy:  Acc@1 51.290 || Acc@5 80.870\n",
            "==> 72.58 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 31, lr: 0.1 -----\n",
            "Epoch: [31][  0/391]\tTime  0.266 ( 0.266)\tLoss 1.7571e+00 (1.7571e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  85.16 ( 85.16)\n",
            "Epoch: [31][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.7534e+00 (1.7447e+00)\tAcc@1  50.78 ( 52.29)\tAcc@5  81.25 ( 82.66)\n",
            "Epoch: [31][ 60/391]\tTime  0.176 ( 0.176)\tLoss 1.7116e+00 (1.7958e+00)\tAcc@1  50.78 ( 50.79)\tAcc@5  82.03 ( 81.39)\n",
            "Epoch: [31][ 90/391]\tTime  0.176 ( 0.175)\tLoss 1.5813e+00 (1.8128e+00)\tAcc@1  56.25 ( 50.85)\tAcc@5  84.38 ( 80.91)\n",
            "Epoch: [31][120/391]\tTime  0.174 ( 0.175)\tLoss 1.6762e+00 (1.8081e+00)\tAcc@1  56.25 ( 50.80)\tAcc@5  82.81 ( 81.09)\n",
            "Epoch: [31][150/391]\tTime  0.174 ( 0.175)\tLoss 1.5485e+00 (1.8210e+00)\tAcc@1  57.03 ( 50.57)\tAcc@5  87.50 ( 80.77)\n",
            "Epoch: [31][180/391]\tTime  0.171 ( 0.175)\tLoss 1.6753e+00 (1.8202e+00)\tAcc@1  55.47 ( 50.83)\tAcc@5  82.03 ( 80.80)\n",
            "Epoch: [31][210/391]\tTime  0.174 ( 0.175)\tLoss 1.6841e+00 (1.8264e+00)\tAcc@1  57.03 ( 50.67)\tAcc@5  85.94 ( 80.60)\n",
            "Epoch: [31][240/391]\tTime  0.172 ( 0.175)\tLoss 1.6318e+00 (1.8228e+00)\tAcc@1  48.44 ( 50.81)\tAcc@5  85.16 ( 80.72)\n",
            "Epoch: [31][270/391]\tTime  0.177 ( 0.175)\tLoss 1.7417e+00 (1.8295e+00)\tAcc@1  48.44 ( 50.66)\tAcc@5  83.59 ( 80.54)\n",
            "Epoch: [31][300/391]\tTime  0.174 ( 0.175)\tLoss 1.8835e+00 (1.8309e+00)\tAcc@1  48.44 ( 50.68)\tAcc@5  78.12 ( 80.49)\n",
            "Epoch: [31][330/391]\tTime  0.172 ( 0.175)\tLoss 1.8405e+00 (1.8321e+00)\tAcc@1  49.22 ( 50.60)\tAcc@5  82.81 ( 80.46)\n",
            "Epoch: [31][360/391]\tTime  0.174 ( 0.175)\tLoss 1.8825e+00 (1.8365e+00)\tAcc@1  51.56 ( 50.48)\tAcc@5  78.91 ( 80.37)\n",
            "Epoch: [31][390/391]\tTime  0.156 ( 0.175)\tLoss 1.6982e+00 (1.8418e+00)\tAcc@1  56.25 ( 50.37)\tAcc@5  83.75 ( 80.24)\n",
            "==> Train Accuracy: Acc@1 50.374 || Acc@5 80.240\n",
            "==> Test Accuracy:  Acc@1 51.770 || Acc@5 82.270\n",
            "==> 72.64 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 32, lr: 0.1 -----\n",
            "Epoch: [32][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.8983e+00 (1.8983e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  75.78 ( 75.78)\n",
            "Epoch: [32][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.5942e+00 (1.7423e+00)\tAcc@1  60.16 ( 51.59)\tAcc@5  82.03 ( 82.43)\n",
            "Epoch: [32][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.7101e+00 (1.7536e+00)\tAcc@1  50.78 ( 52.05)\tAcc@5  82.81 ( 81.89)\n",
            "Epoch: [32][ 90/391]\tTime  0.172 ( 0.175)\tLoss 1.6514e+00 (1.7542e+00)\tAcc@1  53.12 ( 51.79)\tAcc@5  81.25 ( 82.12)\n",
            "Epoch: [32][120/391]\tTime  0.173 ( 0.175)\tLoss 2.1017e+00 (1.7618e+00)\tAcc@1  42.19 ( 51.66)\tAcc@5  78.91 ( 81.91)\n",
            "Epoch: [32][150/391]\tTime  0.172 ( 0.175)\tLoss 1.9690e+00 (1.7937e+00)\tAcc@1  44.53 ( 50.87)\tAcc@5  78.12 ( 81.27)\n",
            "Epoch: [32][180/391]\tTime  0.175 ( 0.175)\tLoss 1.8448e+00 (1.8082e+00)\tAcc@1  53.12 ( 50.63)\tAcc@5  80.47 ( 81.04)\n",
            "Epoch: [32][210/391]\tTime  0.175 ( 0.175)\tLoss 1.7771e+00 (1.8073e+00)\tAcc@1  50.78 ( 50.52)\tAcc@5  81.25 ( 81.08)\n",
            "Epoch: [32][240/391]\tTime  0.175 ( 0.175)\tLoss 1.7810e+00 (1.8161e+00)\tAcc@1  52.34 ( 50.40)\tAcc@5  82.81 ( 80.92)\n",
            "Epoch: [32][270/391]\tTime  0.173 ( 0.175)\tLoss 1.7298e+00 (1.8211e+00)\tAcc@1  50.00 ( 50.32)\tAcc@5  81.25 ( 80.81)\n",
            "Epoch: [32][300/391]\tTime  0.175 ( 0.175)\tLoss 1.5231e+00 (1.8272e+00)\tAcc@1  60.94 ( 50.28)\tAcc@5  85.94 ( 80.67)\n",
            "Epoch: [32][330/391]\tTime  0.173 ( 0.175)\tLoss 1.8688e+00 (1.8241e+00)\tAcc@1  46.09 ( 50.36)\tAcc@5  81.25 ( 80.69)\n",
            "Epoch: [32][360/391]\tTime  0.175 ( 0.175)\tLoss 1.8766e+00 (1.8268e+00)\tAcc@1  45.31 ( 50.37)\tAcc@5  79.69 ( 80.61)\n",
            "Epoch: [32][390/391]\tTime  0.159 ( 0.175)\tLoss 1.9190e+00 (1.8277e+00)\tAcc@1  51.25 ( 50.41)\tAcc@5  78.75 ( 80.56)\n",
            "==> Train Accuracy: Acc@1 50.412 || Acc@5 80.562\n",
            "==> Test Accuracy:  Acc@1 51.820 || Acc@5 82.390\n",
            "==> 72.63 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 33, lr: 0.1 -----\n",
            "Epoch: [33][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.4396e+00 (1.4396e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [33][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.6994e+00 (1.7927e+00)\tAcc@1  56.25 ( 51.56)\tAcc@5  79.69 ( 80.67)\n",
            "Epoch: [33][ 60/391]\tTime  0.176 ( 0.176)\tLoss 1.6793e+00 (1.7962e+00)\tAcc@1  57.81 ( 51.51)\tAcc@5  81.25 ( 80.81)\n",
            "Epoch: [33][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.9076e+00 (1.7806e+00)\tAcc@1  39.06 ( 51.46)\tAcc@5  84.38 ( 81.22)\n",
            "Epoch: [33][120/391]\tTime  0.174 ( 0.175)\tLoss 1.3891e+00 (1.7911e+00)\tAcc@1  60.94 ( 51.32)\tAcc@5  89.06 ( 81.17)\n",
            "Epoch: [33][150/391]\tTime  0.172 ( 0.175)\tLoss 1.7573e+00 (1.8018e+00)\tAcc@1  50.00 ( 51.02)\tAcc@5  82.03 ( 81.07)\n",
            "Epoch: [33][180/391]\tTime  0.175 ( 0.175)\tLoss 1.8365e+00 (1.8139e+00)\tAcc@1  49.22 ( 50.77)\tAcc@5  78.12 ( 80.88)\n",
            "Epoch: [33][210/391]\tTime  0.175 ( 0.175)\tLoss 1.8755e+00 (1.8191e+00)\tAcc@1  52.34 ( 50.67)\tAcc@5  78.12 ( 80.74)\n",
            "Epoch: [33][240/391]\tTime  0.176 ( 0.175)\tLoss 1.9281e+00 (1.8179e+00)\tAcc@1  48.44 ( 50.63)\tAcc@5  80.47 ( 80.82)\n",
            "Epoch: [33][270/391]\tTime  0.173 ( 0.175)\tLoss 1.8451e+00 (1.8202e+00)\tAcc@1  50.00 ( 50.60)\tAcc@5  79.69 ( 80.70)\n",
            "Epoch: [33][300/391]\tTime  0.172 ( 0.175)\tLoss 1.7285e+00 (1.8221e+00)\tAcc@1  54.69 ( 50.55)\tAcc@5  83.59 ( 80.67)\n",
            "Epoch: [33][330/391]\tTime  0.176 ( 0.175)\tLoss 1.9393e+00 (1.8209e+00)\tAcc@1  48.44 ( 50.59)\tAcc@5  78.12 ( 80.67)\n",
            "Epoch: [33][360/391]\tTime  0.174 ( 0.175)\tLoss 1.8196e+00 (1.8234e+00)\tAcc@1  55.47 ( 50.56)\tAcc@5  80.47 ( 80.57)\n",
            "Epoch: [33][390/391]\tTime  0.155 ( 0.174)\tLoss 1.6531e+00 (1.8257e+00)\tAcc@1  50.00 ( 50.57)\tAcc@5  81.25 ( 80.48)\n",
            "==> Train Accuracy: Acc@1 50.570 || Acc@5 80.478\n",
            "==> Test Accuracy:  Acc@1 52.180 || Acc@5 80.910\n",
            "==> 72.59 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 34, lr: 0.1 -----\n",
            "Epoch: [34][  0/391]\tTime  0.253 ( 0.253)\tLoss 1.9130e+00 (1.9130e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  81.25 ( 81.25)\n",
            "Epoch: [34][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.8264e+00 (1.7409e+00)\tAcc@1  53.91 ( 51.79)\tAcc@5  80.47 ( 82.23)\n",
            "Epoch: [34][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.9134e+00 (1.7724e+00)\tAcc@1  46.88 ( 51.51)\tAcc@5  80.47 ( 81.81)\n",
            "Epoch: [34][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.6974e+00 (1.7691e+00)\tAcc@1  55.47 ( 51.91)\tAcc@5  83.59 ( 81.61)\n",
            "Epoch: [34][120/391]\tTime  0.176 ( 0.175)\tLoss 1.8392e+00 (1.7887e+00)\tAcc@1  46.88 ( 51.25)\tAcc@5  83.59 ( 81.27)\n",
            "Epoch: [34][150/391]\tTime  0.174 ( 0.175)\tLoss 2.0467e+00 (1.8000e+00)\tAcc@1  42.97 ( 50.99)\tAcc@5  77.34 ( 81.00)\n",
            "Epoch: [34][180/391]\tTime  0.175 ( 0.175)\tLoss 1.9017e+00 (1.8048e+00)\tAcc@1  43.75 ( 50.91)\tAcc@5  78.91 ( 80.87)\n",
            "Epoch: [34][210/391]\tTime  0.174 ( 0.175)\tLoss 1.6506e+00 (1.8058e+00)\tAcc@1  58.59 ( 50.98)\tAcc@5  81.25 ( 80.85)\n",
            "Epoch: [34][240/391]\tTime  0.172 ( 0.175)\tLoss 1.9527e+00 (1.8137e+00)\tAcc@1  50.00 ( 50.80)\tAcc@5  76.56 ( 80.79)\n",
            "Epoch: [34][270/391]\tTime  0.174 ( 0.175)\tLoss 2.1179e+00 (1.8177e+00)\tAcc@1  43.75 ( 50.72)\tAcc@5  77.34 ( 80.71)\n",
            "Epoch: [34][300/391]\tTime  0.175 ( 0.174)\tLoss 1.9940e+00 (1.8252e+00)\tAcc@1  46.88 ( 50.58)\tAcc@5  79.69 ( 80.65)\n",
            "Epoch: [34][330/391]\tTime  0.173 ( 0.174)\tLoss 1.9981e+00 (1.8268e+00)\tAcc@1  50.00 ( 50.57)\tAcc@5  78.91 ( 80.56)\n",
            "Epoch: [34][360/391]\tTime  0.174 ( 0.174)\tLoss 1.6389e+00 (1.8285e+00)\tAcc@1  58.59 ( 50.52)\tAcc@5  82.03 ( 80.50)\n",
            "Epoch: [34][390/391]\tTime  0.160 ( 0.174)\tLoss 1.8474e+00 (1.8272e+00)\tAcc@1  47.50 ( 50.56)\tAcc@5  78.75 ( 80.42)\n",
            "==> Train Accuracy: Acc@1 50.558 || Acc@5 80.424\n",
            "==> Test Accuracy:  Acc@1 54.270 || Acc@5 83.680\n",
            "==> 72.55 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 35, lr: 0.1 -----\n",
            "Epoch: [35][  0/391]\tTime  0.248 ( 0.248)\tLoss 1.5892e+00 (1.5892e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [35][ 30/391]\tTime  0.172 ( 0.176)\tLoss 1.6785e+00 (1.7588e+00)\tAcc@1  53.91 ( 52.29)\tAcc@5  86.72 ( 81.15)\n",
            "Epoch: [35][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.6142e+00 (1.7606e+00)\tAcc@1  57.03 ( 51.90)\tAcc@5  84.38 ( 81.62)\n",
            "Epoch: [35][ 90/391]\tTime  0.178 ( 0.175)\tLoss 1.8126e+00 (1.7737e+00)\tAcc@1  49.22 ( 51.97)\tAcc@5  78.91 ( 81.48)\n",
            "Epoch: [35][120/391]\tTime  0.171 ( 0.175)\tLoss 2.0915e+00 (1.7777e+00)\tAcc@1  44.53 ( 51.55)\tAcc@5  77.34 ( 81.27)\n",
            "Epoch: [35][150/391]\tTime  0.174 ( 0.175)\tLoss 1.6818e+00 (1.7867e+00)\tAcc@1  51.56 ( 51.21)\tAcc@5  85.16 ( 81.17)\n",
            "Epoch: [35][180/391]\tTime  0.173 ( 0.174)\tLoss 1.6502e+00 (1.7929e+00)\tAcc@1  53.91 ( 51.20)\tAcc@5  84.38 ( 81.07)\n",
            "Epoch: [35][210/391]\tTime  0.174 ( 0.174)\tLoss 1.9262e+00 (1.8007e+00)\tAcc@1  50.00 ( 51.09)\tAcc@5  78.91 ( 80.98)\n",
            "Epoch: [35][240/391]\tTime  0.175 ( 0.174)\tLoss 1.7057e+00 (1.8000e+00)\tAcc@1  53.91 ( 51.08)\tAcc@5  85.16 ( 81.01)\n",
            "Epoch: [35][270/391]\tTime  0.174 ( 0.174)\tLoss 1.9472e+00 (1.8065e+00)\tAcc@1  47.66 ( 50.95)\tAcc@5  78.12 ( 80.84)\n",
            "Epoch: [35][300/391]\tTime  0.174 ( 0.174)\tLoss 1.6647e+00 (1.8066e+00)\tAcc@1  52.34 ( 51.00)\tAcc@5  85.16 ( 80.84)\n",
            "Epoch: [35][330/391]\tTime  0.176 ( 0.174)\tLoss 1.6546e+00 (1.8079e+00)\tAcc@1  55.47 ( 50.96)\tAcc@5  85.16 ( 80.90)\n",
            "Epoch: [35][360/391]\tTime  0.174 ( 0.174)\tLoss 1.9565e+00 (1.8111e+00)\tAcc@1  44.53 ( 50.93)\tAcc@5  76.56 ( 80.77)\n",
            "Epoch: [35][390/391]\tTime  0.158 ( 0.174)\tLoss 1.8950e+00 (1.8083e+00)\tAcc@1  41.25 ( 50.98)\tAcc@5  86.25 ( 80.88)\n",
            "==> Train Accuracy: Acc@1 50.980 || Acc@5 80.878\n",
            "==> Test Accuracy:  Acc@1 56.170 || Acc@5 84.830\n",
            "==> 72.46 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 36, lr: 0.1 -----\n",
            "Epoch: [36][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.4728e+00 (1.4728e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  82.81 ( 82.81)\n",
            "Epoch: [36][ 30/391]\tTime  0.173 ( 0.176)\tLoss 1.7154e+00 (1.7752e+00)\tAcc@1  56.25 ( 51.94)\tAcc@5  85.94 ( 81.65)\n",
            "Epoch: [36][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.9349e+00 (1.7856e+00)\tAcc@1  53.91 ( 51.86)\tAcc@5  76.56 ( 81.34)\n",
            "Epoch: [36][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.5809e+00 (1.7723e+00)\tAcc@1  57.03 ( 52.02)\tAcc@5  82.81 ( 81.53)\n",
            "Epoch: [36][120/391]\tTime  0.173 ( 0.175)\tLoss 1.4349e+00 (1.7678e+00)\tAcc@1  58.59 ( 52.10)\tAcc@5  86.72 ( 81.52)\n",
            "Epoch: [36][150/391]\tTime  0.175 ( 0.175)\tLoss 1.9598e+00 (1.7709e+00)\tAcc@1  46.88 ( 51.97)\tAcc@5  76.56 ( 81.44)\n",
            "Epoch: [36][180/391]\tTime  0.175 ( 0.175)\tLoss 2.1850e+00 (1.7859e+00)\tAcc@1  46.09 ( 51.62)\tAcc@5  74.22 ( 81.09)\n",
            "Epoch: [36][210/391]\tTime  0.173 ( 0.175)\tLoss 1.9139e+00 (1.7847e+00)\tAcc@1  47.66 ( 51.67)\tAcc@5  81.25 ( 81.21)\n",
            "Epoch: [36][240/391]\tTime  0.171 ( 0.175)\tLoss 1.4718e+00 (1.7873e+00)\tAcc@1  57.81 ( 51.61)\tAcc@5  87.50 ( 81.18)\n",
            "Epoch: [36][270/391]\tTime  0.174 ( 0.175)\tLoss 1.8347e+00 (1.7967e+00)\tAcc@1  48.44 ( 51.39)\tAcc@5  77.34 ( 81.02)\n",
            "Epoch: [36][300/391]\tTime  0.176 ( 0.175)\tLoss 1.8272e+00 (1.8034e+00)\tAcc@1  50.78 ( 51.28)\tAcc@5  81.25 ( 80.87)\n",
            "Epoch: [36][330/391]\tTime  0.173 ( 0.175)\tLoss 1.7423e+00 (1.8054e+00)\tAcc@1  57.03 ( 51.30)\tAcc@5  81.25 ( 80.86)\n",
            "Epoch: [36][360/391]\tTime  0.174 ( 0.175)\tLoss 1.6284e+00 (1.8068e+00)\tAcc@1  56.25 ( 51.24)\tAcc@5  84.38 ( 80.86)\n",
            "Epoch: [36][390/391]\tTime  0.157 ( 0.174)\tLoss 1.7023e+00 (1.8081e+00)\tAcc@1  53.75 ( 51.16)\tAcc@5  81.25 ( 80.83)\n",
            "==> Train Accuracy: Acc@1 51.162 || Acc@5 80.828\n",
            "==> Test Accuracy:  Acc@1 55.410 || Acc@5 84.730\n",
            "==> 72.58 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 37, lr: 0.1 -----\n",
            "Epoch: [37][  0/391]\tTime  0.252 ( 0.252)\tLoss 1.8779e+00 (1.8779e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  78.91 ( 78.91)\n",
            "Epoch: [37][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.7084e+00 (1.7487e+00)\tAcc@1  53.91 ( 52.12)\tAcc@5  83.59 ( 82.13)\n",
            "Epoch: [37][ 60/391]\tTime  0.170 ( 0.175)\tLoss 1.8596e+00 (1.7746e+00)\tAcc@1  51.56 ( 51.33)\tAcc@5  76.56 ( 81.39)\n",
            "Epoch: [37][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.8326e+00 (1.7846e+00)\tAcc@1  51.56 ( 51.33)\tAcc@5  78.91 ( 81.20)\n",
            "Epoch: [37][120/391]\tTime  0.174 ( 0.175)\tLoss 1.7243e+00 (1.7991e+00)\tAcc@1  55.47 ( 50.97)\tAcc@5  79.69 ( 80.91)\n",
            "Epoch: [37][150/391]\tTime  0.176 ( 0.175)\tLoss 1.7121e+00 (1.7951e+00)\tAcc@1  56.25 ( 51.13)\tAcc@5  80.47 ( 81.01)\n",
            "Epoch: [37][180/391]\tTime  0.175 ( 0.175)\tLoss 1.7953e+00 (1.7966e+00)\tAcc@1  50.78 ( 51.08)\tAcc@5  82.03 ( 81.05)\n",
            "Epoch: [37][210/391]\tTime  0.174 ( 0.174)\tLoss 1.7091e+00 (1.8005e+00)\tAcc@1  53.12 ( 50.95)\tAcc@5  87.50 ( 80.91)\n",
            "Epoch: [37][240/391]\tTime  0.173 ( 0.174)\tLoss 1.8532e+00 (1.7998e+00)\tAcc@1  48.44 ( 50.96)\tAcc@5  77.34 ( 80.89)\n",
            "Epoch: [37][270/391]\tTime  0.174 ( 0.174)\tLoss 1.7804e+00 (1.7987e+00)\tAcc@1  52.34 ( 50.99)\tAcc@5  78.91 ( 80.84)\n",
            "Epoch: [37][300/391]\tTime  0.170 ( 0.174)\tLoss 1.9106e+00 (1.8018e+00)\tAcc@1  49.22 ( 50.97)\tAcc@5  82.81 ( 80.85)\n",
            "Epoch: [37][330/391]\tTime  0.174 ( 0.174)\tLoss 1.8086e+00 (1.8027e+00)\tAcc@1  49.22 ( 50.94)\tAcc@5  78.12 ( 80.77)\n",
            "Epoch: [37][360/391]\tTime  0.176 ( 0.174)\tLoss 2.0116e+00 (1.8074e+00)\tAcc@1  50.00 ( 50.93)\tAcc@5  74.22 ( 80.73)\n",
            "Epoch: [37][390/391]\tTime  0.160 ( 0.174)\tLoss 1.8718e+00 (1.8085e+00)\tAcc@1  46.25 ( 50.93)\tAcc@5  81.25 ( 80.69)\n",
            "==> Train Accuracy: Acc@1 50.934 || Acc@5 80.690\n",
            "==> Test Accuracy:  Acc@1 47.140 || Acc@5 78.710\n",
            "==> 72.49 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 38, lr: 0.1 -----\n",
            "Epoch: [38][  0/391]\tTime  0.270 ( 0.270)\tLoss 1.8872e+00 (1.8872e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  78.91 ( 78.91)\n",
            "Epoch: [38][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.7325e+00 (1.7484e+00)\tAcc@1  52.34 ( 52.19)\tAcc@5  85.16 ( 82.06)\n",
            "Epoch: [38][ 60/391]\tTime  0.173 ( 0.176)\tLoss 1.9212e+00 (1.7690e+00)\tAcc@1  48.44 ( 51.59)\tAcc@5  78.12 ( 81.49)\n",
            "Epoch: [38][ 90/391]\tTime  0.174 ( 0.175)\tLoss 2.1904e+00 (1.7760e+00)\tAcc@1  39.84 ( 51.31)\tAcc@5  72.66 ( 81.17)\n",
            "Epoch: [38][120/391]\tTime  0.175 ( 0.175)\tLoss 1.7772e+00 (1.7789e+00)\tAcc@1  49.22 ( 51.23)\tAcc@5  80.47 ( 81.24)\n",
            "Epoch: [38][150/391]\tTime  0.173 ( 0.175)\tLoss 1.8934e+00 (1.7892e+00)\tAcc@1  49.22 ( 51.04)\tAcc@5  81.25 ( 81.13)\n",
            "Epoch: [38][180/391]\tTime  0.173 ( 0.174)\tLoss 2.0301e+00 (1.7918e+00)\tAcc@1  46.09 ( 50.95)\tAcc@5  76.56 ( 81.09)\n",
            "Epoch: [38][210/391]\tTime  0.175 ( 0.174)\tLoss 1.7999e+00 (1.7972e+00)\tAcc@1  47.66 ( 50.88)\tAcc@5  81.25 ( 81.01)\n",
            "Epoch: [38][240/391]\tTime  0.176 ( 0.174)\tLoss 1.7010e+00 (1.7990e+00)\tAcc@1  56.25 ( 50.87)\tAcc@5  82.81 ( 80.93)\n",
            "Epoch: [38][270/391]\tTime  0.175 ( 0.174)\tLoss 1.9581e+00 (1.8001e+00)\tAcc@1  49.22 ( 50.93)\tAcc@5  78.12 ( 80.95)\n",
            "Epoch: [38][300/391]\tTime  0.177 ( 0.174)\tLoss 1.6906e+00 (1.7979e+00)\tAcc@1  52.34 ( 50.91)\tAcc@5  85.16 ( 81.04)\n",
            "Epoch: [38][330/391]\tTime  0.173 ( 0.174)\tLoss 2.0057e+00 (1.7981e+00)\tAcc@1  46.09 ( 51.01)\tAcc@5  75.78 ( 80.97)\n",
            "Epoch: [38][360/391]\tTime  0.176 ( 0.174)\tLoss 1.6594e+00 (1.7996e+00)\tAcc@1  50.78 ( 50.94)\tAcc@5  83.59 ( 80.94)\n",
            "Epoch: [38][390/391]\tTime  0.155 ( 0.174)\tLoss 1.7282e+00 (1.8000e+00)\tAcc@1  58.75 ( 50.99)\tAcc@5  82.50 ( 80.98)\n",
            "==> Train Accuracy: Acc@1 50.988 || Acc@5 80.982\n",
            "==> Test Accuracy:  Acc@1 52.710 || Acc@5 81.270\n",
            "==> 72.46 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 39, lr: 0.1 -----\n",
            "Epoch: [39][  0/391]\tTime  0.257 ( 0.257)\tLoss 1.8027e+00 (1.8027e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  82.03 ( 82.03)\n",
            "Epoch: [39][ 30/391]\tTime  0.175 ( 0.176)\tLoss 2.0155e+00 (1.7490e+00)\tAcc@1  46.09 ( 52.24)\tAcc@5  78.12 ( 81.70)\n",
            "Epoch: [39][ 60/391]\tTime  0.171 ( 0.175)\tLoss 1.7591e+00 (1.7670e+00)\tAcc@1  50.78 ( 51.93)\tAcc@5  85.16 ( 81.21)\n",
            "Epoch: [39][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.8370e+00 (1.7622e+00)\tAcc@1  50.00 ( 52.02)\tAcc@5  79.69 ( 81.16)\n",
            "Epoch: [39][120/391]\tTime  0.174 ( 0.175)\tLoss 1.7425e+00 (1.7780e+00)\tAcc@1  52.34 ( 51.79)\tAcc@5  81.25 ( 81.17)\n",
            "Epoch: [39][150/391]\tTime  0.175 ( 0.175)\tLoss 1.7658e+00 (1.7737e+00)\tAcc@1  53.91 ( 51.95)\tAcc@5  82.03 ( 81.26)\n",
            "Epoch: [39][180/391]\tTime  0.173 ( 0.174)\tLoss 1.9886e+00 (1.7800e+00)\tAcc@1  44.53 ( 51.56)\tAcc@5  78.12 ( 81.17)\n",
            "Epoch: [39][210/391]\tTime  0.173 ( 0.174)\tLoss 1.6650e+00 (1.7830e+00)\tAcc@1  57.81 ( 51.57)\tAcc@5  87.50 ( 81.15)\n",
            "Epoch: [39][240/391]\tTime  0.173 ( 0.174)\tLoss 1.9877e+00 (1.7873e+00)\tAcc@1  44.53 ( 51.51)\tAcc@5  82.03 ( 81.03)\n",
            "Epoch: [39][270/391]\tTime  0.174 ( 0.174)\tLoss 1.5135e+00 (1.7897e+00)\tAcc@1  60.94 ( 51.59)\tAcc@5  85.16 ( 80.96)\n",
            "Epoch: [39][300/391]\tTime  0.173 ( 0.174)\tLoss 1.9906e+00 (1.7938e+00)\tAcc@1  46.88 ( 51.56)\tAcc@5  78.12 ( 80.88)\n",
            "Epoch: [39][330/391]\tTime  0.174 ( 0.174)\tLoss 1.8128e+00 (1.7980e+00)\tAcc@1  50.78 ( 51.49)\tAcc@5  80.47 ( 80.85)\n",
            "Epoch: [39][360/391]\tTime  0.176 ( 0.174)\tLoss 1.7068e+00 (1.7990e+00)\tAcc@1  52.34 ( 51.49)\tAcc@5  79.69 ( 80.85)\n",
            "Epoch: [39][390/391]\tTime  0.158 ( 0.174)\tLoss 1.6364e+00 (1.7976e+00)\tAcc@1  55.00 ( 51.47)\tAcc@5  83.75 ( 80.92)\n",
            "==> Train Accuracy: Acc@1 51.466 || Acc@5 80.918\n",
            "==> Test Accuracy:  Acc@1 54.460 || Acc@5 84.240\n",
            "==> 72.47 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 40, lr: 0.1 -----\n",
            "Epoch: [40][  0/391]\tTime  0.259 ( 0.259)\tLoss 1.7440e+00 (1.7440e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  81.25 ( 81.25)\n",
            "Epoch: [40][ 30/391]\tTime  0.173 ( 0.176)\tLoss 2.0131e+00 (1.7453e+00)\tAcc@1  44.53 ( 51.84)\tAcc@5  77.34 ( 81.91)\n",
            "Epoch: [40][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.6092e+00 (1.7614e+00)\tAcc@1  57.81 ( 51.52)\tAcc@5  82.03 ( 81.53)\n",
            "Epoch: [40][ 90/391]\tTime  0.177 ( 0.175)\tLoss 2.0321e+00 (1.7728e+00)\tAcc@1  47.66 ( 51.69)\tAcc@5  75.78 ( 81.51)\n",
            "Epoch: [40][120/391]\tTime  0.173 ( 0.175)\tLoss 1.8056e+00 (1.7745e+00)\tAcc@1  52.34 ( 51.74)\tAcc@5  81.25 ( 81.62)\n",
            "Epoch: [40][150/391]\tTime  0.174 ( 0.175)\tLoss 1.7415e+00 (1.7747e+00)\tAcc@1  52.34 ( 51.76)\tAcc@5  81.25 ( 81.49)\n",
            "Epoch: [40][180/391]\tTime  0.174 ( 0.174)\tLoss 1.8516e+00 (1.7784e+00)\tAcc@1  50.00 ( 51.66)\tAcc@5  82.03 ( 81.46)\n",
            "Epoch: [40][210/391]\tTime  0.173 ( 0.174)\tLoss 1.8187e+00 (1.7752e+00)\tAcc@1  52.34 ( 51.83)\tAcc@5  81.25 ( 81.49)\n",
            "Epoch: [40][240/391]\tTime  0.174 ( 0.174)\tLoss 1.8406e+00 (1.7752e+00)\tAcc@1  45.31 ( 51.78)\tAcc@5  79.69 ( 81.45)\n",
            "Epoch: [40][270/391]\tTime  0.174 ( 0.174)\tLoss 1.9392e+00 (1.7830e+00)\tAcc@1  52.34 ( 51.70)\tAcc@5  79.69 ( 81.31)\n",
            "Epoch: [40][300/391]\tTime  0.175 ( 0.174)\tLoss 1.9060e+00 (1.7883e+00)\tAcc@1  46.88 ( 51.50)\tAcc@5  78.12 ( 81.24)\n",
            "Epoch: [40][330/391]\tTime  0.173 ( 0.174)\tLoss 1.7642e+00 (1.7887e+00)\tAcc@1  48.44 ( 51.45)\tAcc@5  84.38 ( 81.21)\n",
            "Epoch: [40][360/391]\tTime  0.177 ( 0.174)\tLoss 1.7085e+00 (1.7926e+00)\tAcc@1  54.69 ( 51.37)\tAcc@5  82.03 ( 81.09)\n",
            "Epoch: [40][390/391]\tTime  0.157 ( 0.174)\tLoss 1.5831e+00 (1.7929e+00)\tAcc@1  53.75 ( 51.38)\tAcc@5  83.75 ( 81.09)\n",
            "==> Train Accuracy: Acc@1 51.384 || Acc@5 81.092\n",
            "==> Test Accuracy:  Acc@1 54.050 || Acc@5 83.680\n",
            "==> 72.50 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 41, lr: 0.1 -----\n",
            "Epoch: [41][  0/391]\tTime  0.254 ( 0.254)\tLoss 1.5458e+00 (1.5458e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  86.72 ( 86.72)\n",
            "Epoch: [41][ 30/391]\tTime  0.171 ( 0.177)\tLoss 1.9607e+00 (1.7071e+00)\tAcc@1  48.44 ( 53.30)\tAcc@5  77.34 ( 82.41)\n",
            "Epoch: [41][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.6200e+00 (1.7367e+00)\tAcc@1  53.91 ( 52.09)\tAcc@5  83.59 ( 82.10)\n",
            "Epoch: [41][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.7178e+00 (1.7421e+00)\tAcc@1  53.12 ( 52.15)\tAcc@5  76.56 ( 81.83)\n",
            "Epoch: [41][120/391]\tTime  0.173 ( 0.175)\tLoss 1.9484e+00 (1.7441e+00)\tAcc@1  45.31 ( 52.23)\tAcc@5  76.56 ( 81.93)\n",
            "Epoch: [41][150/391]\tTime  0.176 ( 0.174)\tLoss 1.8065e+00 (1.7554e+00)\tAcc@1  48.44 ( 51.85)\tAcc@5  82.03 ( 81.82)\n",
            "Epoch: [41][180/391]\tTime  0.175 ( 0.174)\tLoss 1.8587e+00 (1.7629e+00)\tAcc@1  50.78 ( 51.59)\tAcc@5  80.47 ( 81.86)\n",
            "Epoch: [41][210/391]\tTime  0.173 ( 0.174)\tLoss 1.9462e+00 (1.7689e+00)\tAcc@1  48.44 ( 51.65)\tAcc@5  79.69 ( 81.66)\n",
            "Epoch: [41][240/391]\tTime  0.175 ( 0.174)\tLoss 2.0067e+00 (1.7746e+00)\tAcc@1  44.53 ( 51.59)\tAcc@5  76.56 ( 81.55)\n",
            "Epoch: [41][270/391]\tTime  0.175 ( 0.174)\tLoss 1.5926e+00 (1.7803e+00)\tAcc@1  58.59 ( 51.53)\tAcc@5  84.38 ( 81.34)\n",
            "Epoch: [41][300/391]\tTime  0.173 ( 0.174)\tLoss 1.7509e+00 (1.7842e+00)\tAcc@1  57.03 ( 51.56)\tAcc@5  83.59 ( 81.22)\n",
            "Epoch: [41][330/391]\tTime  0.172 ( 0.174)\tLoss 1.7360e+00 (1.7822e+00)\tAcc@1  52.34 ( 51.52)\tAcc@5  82.03 ( 81.24)\n",
            "Epoch: [41][360/391]\tTime  0.173 ( 0.174)\tLoss 1.8510e+00 (1.7849e+00)\tAcc@1  49.22 ( 51.49)\tAcc@5  81.25 ( 81.18)\n",
            "Epoch: [41][390/391]\tTime  0.158 ( 0.174)\tLoss 1.8600e+00 (1.7878e+00)\tAcc@1  48.75 ( 51.46)\tAcc@5  81.25 ( 81.14)\n",
            "==> Train Accuracy: Acc@1 51.464 || Acc@5 81.144\n",
            "==> Test Accuracy:  Acc@1 55.520 || Acc@5 83.950\n",
            "==> 72.45 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 42, lr: 0.1 -----\n",
            "Epoch: [42][  0/391]\tTime  0.254 ( 0.254)\tLoss 1.8047e+00 (1.8047e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  82.81 ( 82.81)\n",
            "Epoch: [42][ 30/391]\tTime  0.173 ( 0.176)\tLoss 1.6865e+00 (1.7007e+00)\tAcc@1  50.00 ( 53.07)\tAcc@5  82.03 ( 83.11)\n",
            "Epoch: [42][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.7261e+00 (1.7374e+00)\tAcc@1  53.12 ( 52.60)\tAcc@5  78.91 ( 82.39)\n",
            "Epoch: [42][ 90/391]\tTime  0.172 ( 0.175)\tLoss 1.8555e+00 (1.7682e+00)\tAcc@1  52.34 ( 51.96)\tAcc@5  72.66 ( 81.94)\n",
            "Epoch: [42][120/391]\tTime  0.174 ( 0.174)\tLoss 1.4649e+00 (1.7651e+00)\tAcc@1  57.81 ( 51.94)\tAcc@5  89.06 ( 82.00)\n",
            "Epoch: [42][150/391]\tTime  0.174 ( 0.174)\tLoss 1.7113e+00 (1.7754e+00)\tAcc@1  52.34 ( 51.77)\tAcc@5  80.47 ( 81.67)\n",
            "Epoch: [42][180/391]\tTime  0.174 ( 0.174)\tLoss 1.9623e+00 (1.7788e+00)\tAcc@1  50.78 ( 51.75)\tAcc@5  78.91 ( 81.63)\n",
            "Epoch: [42][210/391]\tTime  0.175 ( 0.174)\tLoss 1.9861e+00 (1.7816e+00)\tAcc@1  48.44 ( 51.78)\tAcc@5  80.47 ( 81.59)\n",
            "Epoch: [42][240/391]\tTime  0.173 ( 0.174)\tLoss 1.6533e+00 (1.7791e+00)\tAcc@1  51.56 ( 51.85)\tAcc@5  84.38 ( 81.60)\n",
            "Epoch: [42][270/391]\tTime  0.176 ( 0.174)\tLoss 1.7211e+00 (1.7803e+00)\tAcc@1  52.34 ( 51.87)\tAcc@5  84.38 ( 81.56)\n",
            "Epoch: [42][300/391]\tTime  0.174 ( 0.174)\tLoss 1.5819e+00 (1.7792e+00)\tAcc@1  57.81 ( 51.86)\tAcc@5  82.81 ( 81.58)\n",
            "Epoch: [42][330/391]\tTime  0.172 ( 0.174)\tLoss 2.0158e+00 (1.7792e+00)\tAcc@1  43.75 ( 51.86)\tAcc@5  78.91 ( 81.55)\n",
            "Epoch: [42][360/391]\tTime  0.173 ( 0.174)\tLoss 1.5265e+00 (1.7834e+00)\tAcc@1  61.72 ( 51.72)\tAcc@5  83.59 ( 81.44)\n",
            "Epoch: [42][390/391]\tTime  0.155 ( 0.174)\tLoss 1.7832e+00 (1.7850e+00)\tAcc@1  51.25 ( 51.65)\tAcc@5  80.00 ( 81.42)\n",
            "==> Train Accuracy: Acc@1 51.654 || Acc@5 81.416\n",
            "==> Test Accuracy:  Acc@1 55.370 || Acc@5 84.010\n",
            "==> 72.38 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 43, lr: 0.1 -----\n",
            "Epoch: [43][  0/391]\tTime  0.262 ( 0.262)\tLoss 1.8596e+00 (1.8596e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  77.34 ( 77.34)\n",
            "Epoch: [43][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.8362e+00 (1.7661e+00)\tAcc@1  42.97 ( 51.76)\tAcc@5  81.25 ( 81.17)\n",
            "Epoch: [43][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.3674e+00 (1.7626e+00)\tAcc@1  59.38 ( 51.79)\tAcc@5  85.94 ( 81.45)\n",
            "Epoch: [43][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.6135e+00 (1.7517e+00)\tAcc@1  54.69 ( 52.13)\tAcc@5  82.03 ( 81.57)\n",
            "Epoch: [43][120/391]\tTime  0.176 ( 0.175)\tLoss 1.9796e+00 (1.7652e+00)\tAcc@1  45.31 ( 51.85)\tAcc@5  77.34 ( 81.46)\n",
            "Epoch: [43][150/391]\tTime  0.177 ( 0.174)\tLoss 1.6514e+00 (1.7657e+00)\tAcc@1  57.81 ( 51.97)\tAcc@5  87.50 ( 81.43)\n",
            "Epoch: [43][180/391]\tTime  0.175 ( 0.174)\tLoss 1.7929e+00 (1.7632e+00)\tAcc@1  53.12 ( 52.11)\tAcc@5  85.16 ( 81.49)\n",
            "Epoch: [43][210/391]\tTime  0.174 ( 0.174)\tLoss 1.7467e+00 (1.7671e+00)\tAcc@1  50.78 ( 52.09)\tAcc@5  84.38 ( 81.45)\n",
            "Epoch: [43][240/391]\tTime  0.176 ( 0.174)\tLoss 1.8884e+00 (1.7768e+00)\tAcc@1  53.91 ( 51.92)\tAcc@5  78.12 ( 81.33)\n",
            "Epoch: [43][270/391]\tTime  0.174 ( 0.174)\tLoss 1.6949e+00 (1.7796e+00)\tAcc@1  55.47 ( 51.74)\tAcc@5  78.91 ( 81.29)\n",
            "Epoch: [43][300/391]\tTime  0.173 ( 0.174)\tLoss 1.6758e+00 (1.7841e+00)\tAcc@1  52.34 ( 51.56)\tAcc@5  81.25 ( 81.20)\n",
            "Epoch: [43][330/391]\tTime  0.174 ( 0.174)\tLoss 1.5723e+00 (1.7845e+00)\tAcc@1  57.03 ( 51.57)\tAcc@5  88.28 ( 81.21)\n",
            "Epoch: [43][360/391]\tTime  0.174 ( 0.174)\tLoss 2.0007e+00 (1.7853e+00)\tAcc@1  47.66 ( 51.52)\tAcc@5  78.12 ( 81.19)\n",
            "Epoch: [43][390/391]\tTime  0.155 ( 0.174)\tLoss 1.7423e+00 (1.7819e+00)\tAcc@1  53.75 ( 51.64)\tAcc@5  83.75 ( 81.22)\n",
            "==> Train Accuracy: Acc@1 51.638 || Acc@5 81.218\n",
            "==> Test Accuracy:  Acc@1 54.420 || Acc@5 82.640\n",
            "==> 72.39 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 44, lr: 0.1 -----\n",
            "Epoch: [44][  0/391]\tTime  0.252 ( 0.252)\tLoss 1.6888e+00 (1.6888e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  81.25 ( 81.25)\n",
            "Epoch: [44][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.9564e+00 (1.7924e+00)\tAcc@1  50.00 ( 51.76)\tAcc@5  75.00 ( 80.75)\n",
            "Epoch: [44][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.7381e+00 (1.7621e+00)\tAcc@1  55.47 ( 52.59)\tAcc@5  78.12 ( 81.25)\n",
            "Epoch: [44][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.5744e+00 (1.7735e+00)\tAcc@1  57.81 ( 52.30)\tAcc@5  84.38 ( 81.08)\n",
            "Epoch: [44][120/391]\tTime  0.174 ( 0.175)\tLoss 1.7997e+00 (1.7629e+00)\tAcc@1  50.00 ( 52.63)\tAcc@5  81.25 ( 81.37)\n",
            "Epoch: [44][150/391]\tTime  0.173 ( 0.174)\tLoss 1.7020e+00 (1.7685e+00)\tAcc@1  52.34 ( 52.24)\tAcc@5  82.81 ( 81.38)\n",
            "Epoch: [44][180/391]\tTime  0.172 ( 0.174)\tLoss 1.6867e+00 (1.7655e+00)\tAcc@1  55.47 ( 52.31)\tAcc@5  83.59 ( 81.43)\n",
            "Epoch: [44][210/391]\tTime  0.174 ( 0.174)\tLoss 2.0390e+00 (1.7739e+00)\tAcc@1  46.88 ( 52.03)\tAcc@5  71.88 ( 81.35)\n",
            "Epoch: [44][240/391]\tTime  0.175 ( 0.174)\tLoss 1.7823e+00 (1.7787e+00)\tAcc@1  53.12 ( 51.79)\tAcc@5  80.47 ( 81.28)\n",
            "Epoch: [44][270/391]\tTime  0.176 ( 0.174)\tLoss 2.0673e+00 (1.7839e+00)\tAcc@1  45.31 ( 51.71)\tAcc@5  74.22 ( 81.21)\n",
            "Epoch: [44][300/391]\tTime  0.171 ( 0.174)\tLoss 1.6694e+00 (1.7824e+00)\tAcc@1  57.03 ( 51.79)\tAcc@5  83.59 ( 81.23)\n",
            "Epoch: [44][330/391]\tTime  0.173 ( 0.174)\tLoss 1.5522e+00 (1.7795e+00)\tAcc@1  57.03 ( 51.79)\tAcc@5  85.94 ( 81.30)\n",
            "Epoch: [44][360/391]\tTime  0.173 ( 0.174)\tLoss 1.5993e+00 (1.7824e+00)\tAcc@1  57.81 ( 51.71)\tAcc@5  81.25 ( 81.23)\n",
            "Epoch: [44][390/391]\tTime  0.156 ( 0.174)\tLoss 1.9296e+00 (1.7801e+00)\tAcc@1  45.00 ( 51.76)\tAcc@5  78.75 ( 81.33)\n",
            "==> Train Accuracy: Acc@1 51.758 || Acc@5 81.330\n",
            "==> Test Accuracy:  Acc@1 55.640 || Acc@5 85.010\n",
            "==> 72.40 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 45, lr: 0.1 -----\n",
            "Epoch: [45][  0/391]\tTime  0.261 ( 0.261)\tLoss 1.7088e+00 (1.7088e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  80.47 ( 80.47)\n",
            "Epoch: [45][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.3227e+00 (1.7491e+00)\tAcc@1  65.62 ( 52.22)\tAcc@5  92.19 ( 82.18)\n",
            "Epoch: [45][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.8842e+00 (1.7356e+00)\tAcc@1  49.22 ( 52.27)\tAcc@5  81.25 ( 82.48)\n",
            "Epoch: [45][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.6815e+00 (1.7454e+00)\tAcc@1  53.12 ( 52.14)\tAcc@5  82.03 ( 82.26)\n",
            "Epoch: [45][120/391]\tTime  0.174 ( 0.175)\tLoss 1.6120e+00 (1.7534e+00)\tAcc@1  53.91 ( 51.96)\tAcc@5  84.38 ( 82.08)\n",
            "Epoch: [45][150/391]\tTime  0.174 ( 0.174)\tLoss 1.7351e+00 (1.7576e+00)\tAcc@1  53.91 ( 52.02)\tAcc@5  80.47 ( 81.78)\n",
            "Epoch: [45][180/391]\tTime  0.174 ( 0.174)\tLoss 1.6302e+00 (1.7580e+00)\tAcc@1  54.69 ( 52.06)\tAcc@5  83.59 ( 81.66)\n",
            "Epoch: [45][210/391]\tTime  0.173 ( 0.174)\tLoss 1.8367e+00 (1.7606e+00)\tAcc@1  50.78 ( 51.99)\tAcc@5  80.47 ( 81.68)\n",
            "Epoch: [45][240/391]\tTime  0.175 ( 0.174)\tLoss 1.7925e+00 (1.7630e+00)\tAcc@1  49.22 ( 52.10)\tAcc@5  87.50 ( 81.66)\n",
            "Epoch: [45][270/391]\tTime  0.174 ( 0.174)\tLoss 2.2205e+00 (1.7663e+00)\tAcc@1  45.31 ( 52.13)\tAcc@5  71.88 ( 81.57)\n",
            "Epoch: [45][300/391]\tTime  0.174 ( 0.174)\tLoss 1.7511e+00 (1.7688e+00)\tAcc@1  52.34 ( 52.11)\tAcc@5  79.69 ( 81.48)\n",
            "Epoch: [45][330/391]\tTime  0.174 ( 0.174)\tLoss 1.8007e+00 (1.7683e+00)\tAcc@1  47.66 ( 52.08)\tAcc@5  82.03 ( 81.46)\n",
            "Epoch: [45][360/391]\tTime  0.176 ( 0.174)\tLoss 1.9968e+00 (1.7702e+00)\tAcc@1  41.41 ( 52.04)\tAcc@5  78.91 ( 81.44)\n",
            "Epoch: [45][390/391]\tTime  0.157 ( 0.174)\tLoss 1.6563e+00 (1.7701e+00)\tAcc@1  53.75 ( 52.00)\tAcc@5  86.25 ( 81.45)\n",
            "==> Train Accuracy: Acc@1 52.004 || Acc@5 81.454\n",
            "==> Test Accuracy:  Acc@1 54.290 || Acc@5 84.630\n",
            "==> 72.50 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 46, lr: 0.1 -----\n",
            "Epoch: [46][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.4231e+00 (1.4231e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [46][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.7742e+00 (1.6994e+00)\tAcc@1  52.34 ( 54.33)\tAcc@5  85.16 ( 82.76)\n",
            "Epoch: [46][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.7277e+00 (1.7168e+00)\tAcc@1  47.66 ( 53.47)\tAcc@5  85.16 ( 82.31)\n",
            "Epoch: [46][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.7769e+00 (1.7377e+00)\tAcc@1  51.56 ( 52.72)\tAcc@5  83.59 ( 82.00)\n",
            "Epoch: [46][120/391]\tTime  0.174 ( 0.175)\tLoss 1.7646e+00 (1.7357e+00)\tAcc@1  46.88 ( 52.71)\tAcc@5  84.38 ( 82.06)\n",
            "Epoch: [46][150/391]\tTime  0.174 ( 0.174)\tLoss 1.6902e+00 (1.7301e+00)\tAcc@1  49.22 ( 52.69)\tAcc@5  82.81 ( 82.12)\n",
            "Epoch: [46][180/391]\tTime  0.173 ( 0.174)\tLoss 1.7546e+00 (1.7428e+00)\tAcc@1  53.91 ( 52.34)\tAcc@5  79.69 ( 82.01)\n",
            "Epoch: [46][210/391]\tTime  0.173 ( 0.174)\tLoss 1.8797e+00 (1.7519e+00)\tAcc@1  48.44 ( 52.23)\tAcc@5  79.69 ( 81.87)\n",
            "Epoch: [46][240/391]\tTime  0.174 ( 0.174)\tLoss 1.6238e+00 (1.7574e+00)\tAcc@1  58.59 ( 52.20)\tAcc@5  83.59 ( 81.78)\n",
            "Epoch: [46][270/391]\tTime  0.175 ( 0.174)\tLoss 1.8731e+00 (1.7591e+00)\tAcc@1  46.88 ( 52.14)\tAcc@5  82.81 ( 81.67)\n",
            "Epoch: [46][300/391]\tTime  0.173 ( 0.174)\tLoss 1.6641e+00 (1.7616e+00)\tAcc@1  51.56 ( 52.01)\tAcc@5  82.03 ( 81.67)\n",
            "Epoch: [46][330/391]\tTime  0.173 ( 0.174)\tLoss 1.5526e+00 (1.7630e+00)\tAcc@1  57.81 ( 52.06)\tAcc@5  87.50 ( 81.59)\n",
            "Epoch: [46][360/391]\tTime  0.174 ( 0.174)\tLoss 1.6657e+00 (1.7690e+00)\tAcc@1  53.12 ( 51.91)\tAcc@5  83.59 ( 81.51)\n",
            "Epoch: [46][390/391]\tTime  0.156 ( 0.174)\tLoss 1.7375e+00 (1.7706e+00)\tAcc@1  52.50 ( 51.86)\tAcc@5  83.75 ( 81.48)\n",
            "==> Train Accuracy: Acc@1 51.858 || Acc@5 81.476\n",
            "==> Test Accuracy:  Acc@1 53.740 || Acc@5 83.950\n",
            "==> 72.33 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 47, lr: 0.1 -----\n",
            "Epoch: [47][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.9414e+00 (1.9414e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  77.34 ( 77.34)\n",
            "Epoch: [47][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.9309e+00 (1.7360e+00)\tAcc@1  50.78 ( 53.02)\tAcc@5  81.25 ( 81.83)\n",
            "Epoch: [47][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.8236e+00 (1.7362e+00)\tAcc@1  49.22 ( 52.41)\tAcc@5  79.69 ( 81.95)\n",
            "Epoch: [47][ 90/391]\tTime  0.174 ( 0.174)\tLoss 1.8654e+00 (1.7344e+00)\tAcc@1  54.69 ( 53.08)\tAcc@5  78.12 ( 81.95)\n",
            "Epoch: [47][120/391]\tTime  0.174 ( 0.174)\tLoss 1.8784e+00 (1.7404e+00)\tAcc@1  50.00 ( 53.09)\tAcc@5  78.91 ( 82.06)\n",
            "Epoch: [47][150/391]\tTime  0.172 ( 0.174)\tLoss 1.8877e+00 (1.7413e+00)\tAcc@1  47.66 ( 53.02)\tAcc@5  79.69 ( 82.10)\n",
            "Epoch: [47][180/391]\tTime  0.174 ( 0.174)\tLoss 1.6391e+00 (1.7482e+00)\tAcc@1  53.91 ( 52.88)\tAcc@5  80.47 ( 81.98)\n",
            "Epoch: [47][210/391]\tTime  0.172 ( 0.174)\tLoss 1.8203e+00 (1.7455e+00)\tAcc@1  48.44 ( 52.79)\tAcc@5  84.38 ( 82.05)\n",
            "Epoch: [47][240/391]\tTime  0.174 ( 0.174)\tLoss 1.9465e+00 (1.7525e+00)\tAcc@1  49.22 ( 52.81)\tAcc@5  79.69 ( 81.86)\n",
            "Epoch: [47][270/391]\tTime  0.174 ( 0.174)\tLoss 1.7898e+00 (1.7561e+00)\tAcc@1  52.34 ( 52.62)\tAcc@5  81.25 ( 81.85)\n",
            "Epoch: [47][300/391]\tTime  0.172 ( 0.174)\tLoss 1.7369e+00 (1.7654e+00)\tAcc@1  50.00 ( 52.34)\tAcc@5  85.94 ( 81.68)\n",
            "Epoch: [47][330/391]\tTime  0.173 ( 0.174)\tLoss 1.7879e+00 (1.7677e+00)\tAcc@1  48.44 ( 52.24)\tAcc@5  81.25 ( 81.61)\n",
            "Epoch: [47][360/391]\tTime  0.172 ( 0.173)\tLoss 1.8092e+00 (1.7645e+00)\tAcc@1  52.34 ( 52.33)\tAcc@5  80.47 ( 81.67)\n",
            "Epoch: [47][390/391]\tTime  0.156 ( 0.173)\tLoss 2.0284e+00 (1.7719e+00)\tAcc@1  41.25 ( 52.17)\tAcc@5  77.50 ( 81.52)\n",
            "==> Train Accuracy: Acc@1 52.166 || Acc@5 81.520\n",
            "==> Test Accuracy:  Acc@1 55.920 || Acc@5 84.870\n",
            "==> 72.16 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 48, lr: 0.1 -----\n",
            "Epoch: [48][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.6270e+00 (1.6270e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [48][ 30/391]\tTime  0.178 ( 0.176)\tLoss 1.5127e+00 (1.6886e+00)\tAcc@1  56.25 ( 53.07)\tAcc@5  85.16 ( 83.19)\n",
            "Epoch: [48][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.9545e+00 (1.7348e+00)\tAcc@1  49.22 ( 52.15)\tAcc@5  70.31 ( 81.98)\n",
            "Epoch: [48][ 90/391]\tTime  0.171 ( 0.174)\tLoss 1.9003e+00 (1.7439e+00)\tAcc@1  48.44 ( 52.15)\tAcc@5  75.00 ( 81.59)\n",
            "Epoch: [48][120/391]\tTime  0.173 ( 0.174)\tLoss 1.8760e+00 (1.7507e+00)\tAcc@1  48.44 ( 51.98)\tAcc@5  79.69 ( 81.56)\n",
            "Epoch: [48][150/391]\tTime  0.172 ( 0.174)\tLoss 1.5713e+00 (1.7515e+00)\tAcc@1  60.16 ( 51.91)\tAcc@5  85.94 ( 81.65)\n",
            "Epoch: [48][180/391]\tTime  0.174 ( 0.174)\tLoss 1.5895e+00 (1.7532e+00)\tAcc@1  53.91 ( 51.85)\tAcc@5  85.94 ( 81.64)\n",
            "Epoch: [48][210/391]\tTime  0.174 ( 0.174)\tLoss 1.7457e+00 (1.7595e+00)\tAcc@1  52.34 ( 51.81)\tAcc@5  84.38 ( 81.61)\n",
            "Epoch: [48][240/391]\tTime  0.172 ( 0.174)\tLoss 1.7223e+00 (1.7610e+00)\tAcc@1  50.78 ( 51.80)\tAcc@5  84.38 ( 81.53)\n",
            "Epoch: [48][270/391]\tTime  0.172 ( 0.174)\tLoss 1.6314e+00 (1.7593e+00)\tAcc@1  50.00 ( 51.85)\tAcc@5  86.72 ( 81.57)\n",
            "Epoch: [48][300/391]\tTime  0.173 ( 0.174)\tLoss 1.6232e+00 (1.7622e+00)\tAcc@1  54.69 ( 51.82)\tAcc@5  84.38 ( 81.53)\n",
            "Epoch: [48][330/391]\tTime  0.176 ( 0.174)\tLoss 1.6732e+00 (1.7633e+00)\tAcc@1  51.56 ( 51.89)\tAcc@5  81.25 ( 81.46)\n",
            "Epoch: [48][360/391]\tTime  0.176 ( 0.174)\tLoss 1.7790e+00 (1.7607e+00)\tAcc@1  52.34 ( 51.99)\tAcc@5  81.25 ( 81.50)\n",
            "Epoch: [48][390/391]\tTime  0.156 ( 0.174)\tLoss 1.9749e+00 (1.7654e+00)\tAcc@1  43.75 ( 51.95)\tAcc@5  76.25 ( 81.39)\n",
            "==> Train Accuracy: Acc@1 51.946 || Acc@5 81.392\n",
            "==> Test Accuracy:  Acc@1 51.980 || Acc@5 82.320\n",
            "==> 72.26 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 49, lr: 0.1 -----\n",
            "Epoch: [49][  0/391]\tTime  0.247 ( 0.247)\tLoss 1.6159e+00 (1.6159e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  81.25 ( 81.25)\n",
            "Epoch: [49][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.6871e+00 (1.6957e+00)\tAcc@1  53.12 ( 53.68)\tAcc@5  87.50 ( 82.96)\n",
            "Epoch: [49][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.8195e+00 (1.7218e+00)\tAcc@1  52.34 ( 53.07)\tAcc@5  81.25 ( 82.45)\n",
            "Epoch: [49][ 90/391]\tTime  0.175 ( 0.174)\tLoss 1.7231e+00 (1.7259e+00)\tAcc@1  51.56 ( 53.01)\tAcc@5  85.16 ( 82.51)\n",
            "Epoch: [49][120/391]\tTime  0.174 ( 0.174)\tLoss 1.7068e+00 (1.7291e+00)\tAcc@1  53.12 ( 52.92)\tAcc@5  82.03 ( 82.46)\n",
            "Epoch: [49][150/391]\tTime  0.174 ( 0.174)\tLoss 1.9895e+00 (1.7469e+00)\tAcc@1  45.31 ( 52.62)\tAcc@5  75.00 ( 82.13)\n",
            "Epoch: [49][180/391]\tTime  0.174 ( 0.174)\tLoss 1.8578e+00 (1.7411e+00)\tAcc@1  55.47 ( 52.78)\tAcc@5  77.34 ( 82.12)\n",
            "Epoch: [49][210/391]\tTime  0.175 ( 0.174)\tLoss 1.5458e+00 (1.7489e+00)\tAcc@1  60.94 ( 52.61)\tAcc@5  83.59 ( 81.83)\n",
            "Epoch: [49][240/391]\tTime  0.173 ( 0.174)\tLoss 1.6910e+00 (1.7485e+00)\tAcc@1  52.34 ( 52.63)\tAcc@5  85.16 ( 81.80)\n",
            "Epoch: [49][270/391]\tTime  0.175 ( 0.174)\tLoss 1.6425e+00 (1.7482e+00)\tAcc@1  57.81 ( 52.62)\tAcc@5  81.25 ( 81.75)\n",
            "Epoch: [49][300/391]\tTime  0.174 ( 0.174)\tLoss 1.7536e+00 (1.7495e+00)\tAcc@1  50.78 ( 52.55)\tAcc@5  82.81 ( 81.74)\n",
            "Epoch: [49][330/391]\tTime  0.174 ( 0.174)\tLoss 1.7481e+00 (1.7558e+00)\tAcc@1  56.25 ( 52.47)\tAcc@5  81.25 ( 81.66)\n",
            "Epoch: [49][360/391]\tTime  0.173 ( 0.174)\tLoss 1.8301e+00 (1.7613e+00)\tAcc@1  50.00 ( 52.35)\tAcc@5  81.25 ( 81.59)\n",
            "Epoch: [49][390/391]\tTime  0.157 ( 0.174)\tLoss 1.8752e+00 (1.7642e+00)\tAcc@1  43.75 ( 52.23)\tAcc@5  81.25 ( 81.60)\n",
            "==> Train Accuracy: Acc@1 52.230 || Acc@5 81.602\n",
            "==> Test Accuracy:  Acc@1 55.710 || Acc@5 83.350\n",
            "==> 72.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 50, lr: 0.1 -----\n",
            "Epoch: [50][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.4562e+00 (1.4562e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [50][ 30/391]\tTime  0.174 ( 0.176)\tLoss 2.1057e+00 (1.6758e+00)\tAcc@1  42.19 ( 55.34)\tAcc@5  71.09 ( 83.47)\n",
            "Epoch: [50][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.7529e+00 (1.7142e+00)\tAcc@1  55.47 ( 54.11)\tAcc@5  81.25 ( 82.51)\n",
            "Epoch: [50][ 90/391]\tTime  0.177 ( 0.175)\tLoss 1.5275e+00 (1.7032e+00)\tAcc@1  55.47 ( 54.40)\tAcc@5  85.94 ( 82.64)\n",
            "Epoch: [50][120/391]\tTime  0.175 ( 0.175)\tLoss 1.9719e+00 (1.7166e+00)\tAcc@1  48.44 ( 54.09)\tAcc@5  75.00 ( 82.44)\n",
            "Epoch: [50][150/391]\tTime  0.172 ( 0.174)\tLoss 1.6277e+00 (1.7196e+00)\tAcc@1  49.22 ( 53.73)\tAcc@5  82.81 ( 82.41)\n",
            "Epoch: [50][180/391]\tTime  0.173 ( 0.174)\tLoss 1.7645e+00 (1.7243e+00)\tAcc@1  49.22 ( 53.45)\tAcc@5  83.59 ( 82.39)\n",
            "Epoch: [50][210/391]\tTime  0.172 ( 0.174)\tLoss 1.6900e+00 (1.7297e+00)\tAcc@1  56.25 ( 53.13)\tAcc@5  84.38 ( 82.24)\n",
            "Epoch: [50][240/391]\tTime  0.174 ( 0.174)\tLoss 1.6715e+00 (1.7362e+00)\tAcc@1  55.47 ( 52.98)\tAcc@5  80.47 ( 82.04)\n",
            "Epoch: [50][270/391]\tTime  0.175 ( 0.174)\tLoss 1.7197e+00 (1.7416e+00)\tAcc@1  53.91 ( 52.77)\tAcc@5  82.03 ( 81.93)\n",
            "Epoch: [50][300/391]\tTime  0.172 ( 0.174)\tLoss 1.7325e+00 (1.7465e+00)\tAcc@1  58.59 ( 52.72)\tAcc@5  79.69 ( 81.83)\n",
            "Epoch: [50][330/391]\tTime  0.167 ( 0.174)\tLoss 1.8451e+00 (1.7493e+00)\tAcc@1  57.81 ( 52.73)\tAcc@5  78.12 ( 81.72)\n",
            "Epoch: [50][360/391]\tTime  0.172 ( 0.174)\tLoss 1.8359e+00 (1.7553e+00)\tAcc@1  45.31 ( 52.56)\tAcc@5  82.03 ( 81.61)\n",
            "Epoch: [50][390/391]\tTime  0.158 ( 0.174)\tLoss 1.6097e+00 (1.7557e+00)\tAcc@1  56.25 ( 52.50)\tAcc@5  82.50 ( 81.63)\n",
            "==> Train Accuracy: Acc@1 52.498 || Acc@5 81.632\n",
            "==> Test Accuracy:  Acc@1 57.530 || Acc@5 86.330\n",
            "==> 72.41 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 51, lr: 0.1 -----\n",
            "Epoch: [51][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.4876e+00 (1.4876e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [51][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.6433e+00 (1.6388e+00)\tAcc@1  57.03 ( 55.42)\tAcc@5  85.94 ( 84.12)\n",
            "Epoch: [51][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.4838e+00 (1.6648e+00)\tAcc@1  56.25 ( 54.82)\tAcc@5  85.16 ( 83.32)\n",
            "Epoch: [51][ 90/391]\tTime  0.174 ( 0.174)\tLoss 1.8957e+00 (1.6970e+00)\tAcc@1  47.66 ( 53.94)\tAcc@5  81.25 ( 83.06)\n",
            "Epoch: [51][120/391]\tTime  0.174 ( 0.174)\tLoss 1.8203e+00 (1.7055e+00)\tAcc@1  49.22 ( 53.80)\tAcc@5  81.25 ( 82.98)\n",
            "Epoch: [51][150/391]\tTime  0.173 ( 0.174)\tLoss 1.7506e+00 (1.7146e+00)\tAcc@1  49.22 ( 53.40)\tAcc@5  82.81 ( 82.77)\n",
            "Epoch: [51][180/391]\tTime  0.176 ( 0.174)\tLoss 2.0968e+00 (1.7194e+00)\tAcc@1  44.53 ( 53.13)\tAcc@5  74.22 ( 82.63)\n",
            "Epoch: [51][210/391]\tTime  0.173 ( 0.174)\tLoss 1.8072e+00 (1.7325e+00)\tAcc@1  50.78 ( 52.87)\tAcc@5  81.25 ( 82.37)\n",
            "Epoch: [51][240/391]\tTime  0.172 ( 0.174)\tLoss 1.9727e+00 (1.7338e+00)\tAcc@1  43.75 ( 52.87)\tAcc@5  80.47 ( 82.32)\n",
            "Epoch: [51][270/391]\tTime  0.172 ( 0.174)\tLoss 1.7645e+00 (1.7384e+00)\tAcc@1  52.34 ( 52.75)\tAcc@5  79.69 ( 82.18)\n",
            "Epoch: [51][300/391]\tTime  0.174 ( 0.174)\tLoss 1.8308e+00 (1.7447e+00)\tAcc@1  46.88 ( 52.64)\tAcc@5  84.38 ( 82.06)\n",
            "Epoch: [51][330/391]\tTime  0.172 ( 0.174)\tLoss 1.7313e+00 (1.7462e+00)\tAcc@1  51.56 ( 52.59)\tAcc@5  80.47 ( 82.01)\n",
            "Epoch: [51][360/391]\tTime  0.175 ( 0.174)\tLoss 1.6424e+00 (1.7522e+00)\tAcc@1  55.47 ( 52.34)\tAcc@5  82.03 ( 81.94)\n",
            "Epoch: [51][390/391]\tTime  0.157 ( 0.174)\tLoss 1.9250e+00 (1.7544e+00)\tAcc@1  51.25 ( 52.34)\tAcc@5  71.25 ( 81.84)\n",
            "==> Train Accuracy: Acc@1 52.336 || Acc@5 81.842\n",
            "==> Test Accuracy:  Acc@1 54.740 || Acc@5 83.970\n",
            "==> 72.24 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 52, lr: 0.1 -----\n",
            "Epoch: [52][  0/391]\tTime  0.245 ( 0.245)\tLoss 1.7809e+00 (1.7809e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  79.69 ( 79.69)\n",
            "Epoch: [52][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.6779e+00 (1.7248e+00)\tAcc@1  50.78 ( 52.72)\tAcc@5  85.16 ( 82.26)\n",
            "Epoch: [52][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.6078e+00 (1.7021e+00)\tAcc@1  57.81 ( 53.11)\tAcc@5  86.72 ( 82.88)\n",
            "Epoch: [52][ 90/391]\tTime  0.173 ( 0.174)\tLoss 1.8514e+00 (1.7037e+00)\tAcc@1  55.47 ( 53.31)\tAcc@5  78.12 ( 82.94)\n",
            "Epoch: [52][120/391]\tTime  0.176 ( 0.174)\tLoss 1.5951e+00 (1.7126e+00)\tAcc@1  54.69 ( 53.09)\tAcc@5  85.16 ( 82.59)\n",
            "Epoch: [52][150/391]\tTime  0.172 ( 0.174)\tLoss 1.8956e+00 (1.7211e+00)\tAcc@1  49.22 ( 52.84)\tAcc@5  79.69 ( 82.45)\n",
            "Epoch: [52][180/391]\tTime  0.176 ( 0.174)\tLoss 1.8244e+00 (1.7280e+00)\tAcc@1  53.12 ( 52.75)\tAcc@5  82.03 ( 82.47)\n",
            "Epoch: [52][210/391]\tTime  0.176 ( 0.174)\tLoss 1.5805e+00 (1.7279e+00)\tAcc@1  53.91 ( 52.78)\tAcc@5  86.72 ( 82.53)\n",
            "Epoch: [52][240/391]\tTime  0.174 ( 0.174)\tLoss 1.9024e+00 (1.7323e+00)\tAcc@1  49.22 ( 52.68)\tAcc@5  76.56 ( 82.36)\n",
            "Epoch: [52][270/391]\tTime  0.173 ( 0.174)\tLoss 1.7602e+00 (1.7339e+00)\tAcc@1  57.81 ( 52.61)\tAcc@5  82.03 ( 82.37)\n",
            "Epoch: [52][300/391]\tTime  0.171 ( 0.174)\tLoss 1.8016e+00 (1.7392e+00)\tAcc@1  53.12 ( 52.45)\tAcc@5  78.12 ( 82.27)\n",
            "Epoch: [52][330/391]\tTime  0.172 ( 0.174)\tLoss 1.5801e+00 (1.7457e+00)\tAcc@1  57.03 ( 52.36)\tAcc@5  88.28 ( 82.14)\n",
            "Epoch: [52][360/391]\tTime  0.173 ( 0.174)\tLoss 1.8014e+00 (1.7491e+00)\tAcc@1  53.91 ( 52.29)\tAcc@5  79.69 ( 82.08)\n",
            "Epoch: [52][390/391]\tTime  0.157 ( 0.174)\tLoss 1.6637e+00 (1.7495e+00)\tAcc@1  50.00 ( 52.26)\tAcc@5  88.75 ( 82.07)\n",
            "==> Train Accuracy: Acc@1 52.260 || Acc@5 82.074\n",
            "==> Test Accuracy:  Acc@1 55.640 || Acc@5 84.770\n",
            "==> 72.23 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 53, lr: 0.1 -----\n",
            "Epoch: [53][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.6556e+00 (1.6556e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [53][ 30/391]\tTime  0.173 ( 0.176)\tLoss 1.7067e+00 (1.6885e+00)\tAcc@1  54.69 ( 54.61)\tAcc@5  83.59 ( 82.86)\n",
            "Epoch: [53][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.5297e+00 (1.6881e+00)\tAcc@1  60.94 ( 54.28)\tAcc@5  85.16 ( 83.03)\n",
            "Epoch: [53][ 90/391]\tTime  0.175 ( 0.174)\tLoss 1.6947e+00 (1.7138e+00)\tAcc@1  56.25 ( 53.38)\tAcc@5  77.34 ( 82.43)\n",
            "Epoch: [53][120/391]\tTime  0.174 ( 0.174)\tLoss 1.6468e+00 (1.7140e+00)\tAcc@1  53.91 ( 53.22)\tAcc@5  82.03 ( 82.39)\n",
            "Epoch: [53][150/391]\tTime  0.173 ( 0.174)\tLoss 1.8525e+00 (1.7245e+00)\tAcc@1  53.91 ( 53.00)\tAcc@5  82.03 ( 82.30)\n",
            "Epoch: [53][180/391]\tTime  0.174 ( 0.174)\tLoss 1.4512e+00 (1.7328e+00)\tAcc@1  57.81 ( 52.86)\tAcc@5  84.38 ( 82.22)\n",
            "Epoch: [53][210/391]\tTime  0.173 ( 0.174)\tLoss 1.7512e+00 (1.7426e+00)\tAcc@1  50.78 ( 52.57)\tAcc@5  76.56 ( 82.06)\n",
            "Epoch: [53][240/391]\tTime  0.175 ( 0.174)\tLoss 1.5146e+00 (1.7442e+00)\tAcc@1  57.81 ( 52.51)\tAcc@5  85.94 ( 82.01)\n",
            "Epoch: [53][270/391]\tTime  0.176 ( 0.174)\tLoss 2.0369e+00 (1.7507e+00)\tAcc@1  50.00 ( 52.42)\tAcc@5  73.44 ( 81.86)\n",
            "Epoch: [53][300/391]\tTime  0.174 ( 0.174)\tLoss 1.8396e+00 (1.7534e+00)\tAcc@1  50.78 ( 52.37)\tAcc@5  80.47 ( 81.79)\n",
            "Epoch: [53][330/391]\tTime  0.174 ( 0.174)\tLoss 2.0440e+00 (1.7517e+00)\tAcc@1  49.22 ( 52.40)\tAcc@5  75.78 ( 81.80)\n",
            "Epoch: [53][360/391]\tTime  0.175 ( 0.174)\tLoss 1.7886e+00 (1.7528e+00)\tAcc@1  58.59 ( 52.37)\tAcc@5  80.47 ( 81.82)\n",
            "Epoch: [53][390/391]\tTime  0.154 ( 0.174)\tLoss 1.9454e+00 (1.7525e+00)\tAcc@1  50.00 ( 52.41)\tAcc@5  73.75 ( 81.80)\n",
            "==> Train Accuracy: Acc@1 52.406 || Acc@5 81.800\n",
            "==> Test Accuracy:  Acc@1 55.670 || Acc@5 84.490\n",
            "==> 72.30 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 54, lr: 0.1 -----\n",
            "Epoch: [54][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.5634e+00 (1.5634e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [54][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.4816e+00 (1.6552e+00)\tAcc@1  57.03 ( 55.70)\tAcc@5  88.28 ( 83.49)\n",
            "Epoch: [54][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.8039e+00 (1.6725e+00)\tAcc@1  49.22 ( 54.93)\tAcc@5  80.47 ( 83.41)\n",
            "Epoch: [54][ 90/391]\tTime  0.173 ( 0.175)\tLoss 2.0512e+00 (1.6997e+00)\tAcc@1  46.88 ( 54.14)\tAcc@5  78.91 ( 82.80)\n",
            "Epoch: [54][120/391]\tTime  0.173 ( 0.174)\tLoss 1.5189e+00 (1.7040e+00)\tAcc@1  61.72 ( 53.94)\tAcc@5  85.16 ( 82.66)\n",
            "Epoch: [54][150/391]\tTime  0.174 ( 0.174)\tLoss 1.8879e+00 (1.7034e+00)\tAcc@1  43.75 ( 53.73)\tAcc@5  79.69 ( 82.64)\n",
            "Epoch: [54][180/391]\tTime  0.176 ( 0.174)\tLoss 1.7905e+00 (1.7187e+00)\tAcc@1  50.78 ( 53.35)\tAcc@5  78.12 ( 82.29)\n",
            "Epoch: [54][210/391]\tTime  0.173 ( 0.174)\tLoss 1.6495e+00 (1.7264e+00)\tAcc@1  57.03 ( 53.21)\tAcc@5  82.81 ( 82.08)\n",
            "Epoch: [54][240/391]\tTime  0.173 ( 0.174)\tLoss 1.7941e+00 (1.7326e+00)\tAcc@1  53.12 ( 52.95)\tAcc@5  78.91 ( 82.07)\n",
            "Epoch: [54][270/391]\tTime  0.175 ( 0.174)\tLoss 1.5929e+00 (1.7376e+00)\tAcc@1  57.03 ( 52.77)\tAcc@5  82.03 ( 81.98)\n",
            "Epoch: [54][300/391]\tTime  0.173 ( 0.174)\tLoss 1.8852e+00 (1.7440e+00)\tAcc@1  53.91 ( 52.66)\tAcc@5  78.12 ( 81.92)\n",
            "Epoch: [54][330/391]\tTime  0.172 ( 0.174)\tLoss 1.7684e+00 (1.7428e+00)\tAcc@1  57.03 ( 52.73)\tAcc@5  75.78 ( 81.93)\n",
            "Epoch: [54][360/391]\tTime  0.174 ( 0.174)\tLoss 1.6575e+00 (1.7440e+00)\tAcc@1  56.25 ( 52.71)\tAcc@5  79.69 ( 81.93)\n",
            "Epoch: [54][390/391]\tTime  0.159 ( 0.174)\tLoss 1.7329e+00 (1.7475e+00)\tAcc@1  51.25 ( 52.70)\tAcc@5  78.75 ( 81.84)\n",
            "==> Train Accuracy: Acc@1 52.696 || Acc@5 81.844\n",
            "==> Test Accuracy:  Acc@1 57.530 || Acc@5 85.210\n",
            "==> 72.40 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 55, lr: 0.1 -----\n",
            "Epoch: [55][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.7158e+00 (1.7158e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  82.81 ( 82.81)\n",
            "Epoch: [55][ 30/391]\tTime  0.172 ( 0.176)\tLoss 1.8083e+00 (1.6922e+00)\tAcc@1  47.66 ( 54.61)\tAcc@5  82.81 ( 82.66)\n",
            "Epoch: [55][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.6784e+00 (1.7015e+00)\tAcc@1  53.12 ( 54.15)\tAcc@5  84.38 ( 82.54)\n",
            "Epoch: [55][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.4908e+00 (1.6976e+00)\tAcc@1  61.72 ( 53.78)\tAcc@5  85.94 ( 82.61)\n",
            "Epoch: [55][120/391]\tTime  0.173 ( 0.175)\tLoss 1.8954e+00 (1.7178e+00)\tAcc@1  49.22 ( 53.45)\tAcc@5  72.66 ( 82.30)\n",
            "Epoch: [55][150/391]\tTime  0.173 ( 0.174)\tLoss 1.8461e+00 (1.7317e+00)\tAcc@1  49.22 ( 53.02)\tAcc@5  82.81 ( 82.10)\n",
            "Epoch: [55][180/391]\tTime  0.172 ( 0.174)\tLoss 1.7093e+00 (1.7365e+00)\tAcc@1  52.34 ( 52.80)\tAcc@5  80.47 ( 82.08)\n",
            "Epoch: [55][210/391]\tTime  0.175 ( 0.174)\tLoss 1.7484e+00 (1.7417e+00)\tAcc@1  52.34 ( 52.61)\tAcc@5  82.81 ( 82.03)\n",
            "Epoch: [55][240/391]\tTime  0.174 ( 0.174)\tLoss 1.8162e+00 (1.7440e+00)\tAcc@1  51.56 ( 52.52)\tAcc@5  81.25 ( 81.90)\n",
            "Epoch: [55][270/391]\tTime  0.175 ( 0.174)\tLoss 1.6638e+00 (1.7465e+00)\tAcc@1  50.00 ( 52.53)\tAcc@5  79.69 ( 81.82)\n",
            "Epoch: [55][300/391]\tTime  0.177 ( 0.174)\tLoss 1.9195e+00 (1.7446e+00)\tAcc@1  46.88 ( 52.52)\tAcc@5  77.34 ( 81.88)\n",
            "Epoch: [55][330/391]\tTime  0.175 ( 0.174)\tLoss 1.6582e+00 (1.7426e+00)\tAcc@1  54.69 ( 52.53)\tAcc@5  82.81 ( 81.89)\n",
            "Epoch: [55][360/391]\tTime  0.173 ( 0.174)\tLoss 1.8494e+00 (1.7393e+00)\tAcc@1  50.78 ( 52.65)\tAcc@5  77.34 ( 81.96)\n",
            "Epoch: [55][390/391]\tTime  0.158 ( 0.174)\tLoss 1.5496e+00 (1.7458e+00)\tAcc@1  57.50 ( 52.46)\tAcc@5  92.50 ( 81.90)\n",
            "==> Train Accuracy: Acc@1 52.462 || Acc@5 81.898\n",
            "==> Test Accuracy:  Acc@1 53.920 || Acc@5 83.640\n",
            "==> 72.45 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 56, lr: 0.1 -----\n",
            "Epoch: [56][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.6835e+00 (1.6835e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  81.25 ( 81.25)\n",
            "Epoch: [56][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.6583e+00 (1.6790e+00)\tAcc@1  60.16 ( 54.54)\tAcc@5  81.25 ( 83.19)\n",
            "Epoch: [56][ 60/391]\tTime  0.176 ( 0.175)\tLoss 1.6534e+00 (1.7035e+00)\tAcc@1  52.34 ( 54.03)\tAcc@5  82.81 ( 82.45)\n",
            "Epoch: [56][ 90/391]\tTime  0.176 ( 0.175)\tLoss 1.5896e+00 (1.7036e+00)\tAcc@1  56.25 ( 54.01)\tAcc@5  89.06 ( 82.32)\n",
            "Epoch: [56][120/391]\tTime  0.175 ( 0.175)\tLoss 1.6157e+00 (1.7026e+00)\tAcc@1  52.34 ( 53.51)\tAcc@5  88.28 ( 82.60)\n",
            "Epoch: [56][150/391]\tTime  0.175 ( 0.174)\tLoss 1.8035e+00 (1.7215e+00)\tAcc@1  46.09 ( 53.16)\tAcc@5  85.16 ( 82.19)\n",
            "Epoch: [56][180/391]\tTime  0.173 ( 0.174)\tLoss 1.7281e+00 (1.7164e+00)\tAcc@1  58.59 ( 53.36)\tAcc@5  79.69 ( 82.30)\n",
            "Epoch: [56][210/391]\tTime  0.175 ( 0.174)\tLoss 1.7502e+00 (1.7204e+00)\tAcc@1  51.56 ( 53.10)\tAcc@5  81.25 ( 82.35)\n",
            "Epoch: [56][240/391]\tTime  0.174 ( 0.174)\tLoss 1.8473e+00 (1.7315e+00)\tAcc@1  51.56 ( 52.85)\tAcc@5  77.34 ( 82.06)\n",
            "Epoch: [56][270/391]\tTime  0.174 ( 0.174)\tLoss 1.7357e+00 (1.7403e+00)\tAcc@1  51.56 ( 52.70)\tAcc@5  79.69 ( 81.96)\n",
            "Epoch: [56][300/391]\tTime  0.174 ( 0.174)\tLoss 1.6682e+00 (1.7390e+00)\tAcc@1  51.56 ( 52.80)\tAcc@5  86.72 ( 81.98)\n",
            "Epoch: [56][330/391]\tTime  0.173 ( 0.174)\tLoss 1.7327e+00 (1.7401e+00)\tAcc@1  51.56 ( 52.82)\tAcc@5  80.47 ( 81.92)\n",
            "Epoch: [56][360/391]\tTime  0.175 ( 0.174)\tLoss 1.6505e+00 (1.7401e+00)\tAcc@1  50.78 ( 52.75)\tAcc@5  83.59 ( 81.93)\n",
            "Epoch: [56][390/391]\tTime  0.156 ( 0.174)\tLoss 1.5137e+00 (1.7427e+00)\tAcc@1  55.00 ( 52.70)\tAcc@5  90.00 ( 81.84)\n",
            "==> Train Accuracy: Acc@1 52.702 || Acc@5 81.838\n",
            "==> Test Accuracy:  Acc@1 52.670 || Acc@5 83.800\n",
            "==> 72.44 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 57, lr: 0.1 -----\n",
            "Epoch: [57][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.6677e+00 (1.6677e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  85.16 ( 85.16)\n",
            "Epoch: [57][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.5830e+00 (1.6740e+00)\tAcc@1  61.72 ( 54.36)\tAcc@5  82.03 ( 83.39)\n",
            "Epoch: [57][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.7399e+00 (1.6794e+00)\tAcc@1  57.03 ( 54.43)\tAcc@5  83.59 ( 83.04)\n",
            "Epoch: [57][ 90/391]\tTime  0.175 ( 0.175)\tLoss 2.0742e+00 (1.7115e+00)\tAcc@1  44.53 ( 53.40)\tAcc@5  78.91 ( 82.62)\n",
            "Epoch: [57][120/391]\tTime  0.173 ( 0.175)\tLoss 1.7484e+00 (1.7205e+00)\tAcc@1  51.56 ( 53.33)\tAcc@5  83.59 ( 82.37)\n",
            "Epoch: [57][150/391]\tTime  0.175 ( 0.174)\tLoss 1.8652e+00 (1.7194e+00)\tAcc@1  48.44 ( 53.33)\tAcc@5  80.47 ( 82.27)\n",
            "Epoch: [57][180/391]\tTime  0.175 ( 0.174)\tLoss 1.8293e+00 (1.7206e+00)\tAcc@1  51.56 ( 53.20)\tAcc@5  78.91 ( 82.31)\n",
            "Epoch: [57][210/391]\tTime  0.175 ( 0.174)\tLoss 1.6610e+00 (1.7235e+00)\tAcc@1  51.56 ( 53.05)\tAcc@5  85.94 ( 82.22)\n",
            "Epoch: [57][240/391]\tTime  0.175 ( 0.174)\tLoss 1.7889e+00 (1.7250e+00)\tAcc@1  55.47 ( 52.94)\tAcc@5  82.81 ( 82.20)\n",
            "Epoch: [57][270/391]\tTime  0.174 ( 0.174)\tLoss 1.8387e+00 (1.7282e+00)\tAcc@1  51.56 ( 52.83)\tAcc@5  81.25 ( 82.15)\n",
            "Epoch: [57][300/391]\tTime  0.173 ( 0.174)\tLoss 1.8488e+00 (1.7260e+00)\tAcc@1  54.69 ( 52.96)\tAcc@5  81.25 ( 82.21)\n",
            "Epoch: [57][330/391]\tTime  0.173 ( 0.174)\tLoss 1.8141e+00 (1.7241e+00)\tAcc@1  54.69 ( 53.03)\tAcc@5  79.69 ( 82.17)\n",
            "Epoch: [57][360/391]\tTime  0.175 ( 0.174)\tLoss 2.0316e+00 (1.7259e+00)\tAcc@1  43.75 ( 53.05)\tAcc@5  78.12 ( 82.12)\n",
            "Epoch: [57][390/391]\tTime  0.155 ( 0.174)\tLoss 1.9228e+00 (1.7291e+00)\tAcc@1  50.00 ( 52.94)\tAcc@5  76.25 ( 82.07)\n",
            "==> Train Accuracy: Acc@1 52.936 || Acc@5 82.074\n",
            "==> Test Accuracy:  Acc@1 55.650 || Acc@5 84.830\n",
            "==> 72.36 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 58, lr: 0.1 -----\n",
            "Epoch: [58][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.5480e+00 (1.5480e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  86.72 ( 86.72)\n",
            "Epoch: [58][ 30/391]\tTime  0.176 ( 0.176)\tLoss 2.0890e+00 (1.7210e+00)\tAcc@1  42.97 ( 53.83)\tAcc@5  71.88 ( 81.30)\n",
            "Epoch: [58][ 60/391]\tTime  0.170 ( 0.175)\tLoss 1.8296e+00 (1.7387e+00)\tAcc@1  49.22 ( 53.05)\tAcc@5  79.69 ( 81.54)\n",
            "Epoch: [58][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.7493e+00 (1.7416e+00)\tAcc@1  53.91 ( 52.71)\tAcc@5  79.69 ( 81.67)\n",
            "Epoch: [58][120/391]\tTime  0.173 ( 0.174)\tLoss 1.6002e+00 (1.7408e+00)\tAcc@1  53.12 ( 52.92)\tAcc@5  83.59 ( 81.71)\n",
            "Epoch: [58][150/391]\tTime  0.175 ( 0.174)\tLoss 1.8121e+00 (1.7320e+00)\tAcc@1  50.78 ( 53.09)\tAcc@5  82.81 ( 81.89)\n",
            "Epoch: [58][180/391]\tTime  0.173 ( 0.174)\tLoss 1.5323e+00 (1.7333e+00)\tAcc@1  56.25 ( 52.93)\tAcc@5  85.94 ( 82.00)\n",
            "Epoch: [58][210/391]\tTime  0.174 ( 0.174)\tLoss 1.9822e+00 (1.7327e+00)\tAcc@1  42.19 ( 52.89)\tAcc@5  81.25 ( 82.01)\n",
            "Epoch: [58][240/391]\tTime  0.173 ( 0.174)\tLoss 1.5834e+00 (1.7382e+00)\tAcc@1  57.81 ( 52.73)\tAcc@5  82.81 ( 81.92)\n",
            "Epoch: [58][270/391]\tTime  0.173 ( 0.174)\tLoss 1.5597e+00 (1.7338e+00)\tAcc@1  61.72 ( 52.87)\tAcc@5  82.81 ( 82.02)\n",
            "Epoch: [58][300/391]\tTime  0.172 ( 0.174)\tLoss 1.6305e+00 (1.7351e+00)\tAcc@1  52.34 ( 52.86)\tAcc@5  84.38 ( 82.05)\n",
            "Epoch: [58][330/391]\tTime  0.173 ( 0.174)\tLoss 2.0692e+00 (1.7375e+00)\tAcc@1  39.06 ( 52.74)\tAcc@5  78.91 ( 82.01)\n",
            "Epoch: [58][360/391]\tTime  0.174 ( 0.174)\tLoss 1.7013e+00 (1.7362e+00)\tAcc@1  47.66 ( 52.76)\tAcc@5  82.81 ( 82.00)\n",
            "Epoch: [58][390/391]\tTime  0.156 ( 0.174)\tLoss 1.9781e+00 (1.7402e+00)\tAcc@1  48.75 ( 52.67)\tAcc@5  81.25 ( 81.98)\n",
            "==> Train Accuracy: Acc@1 52.672 || Acc@5 81.982\n",
            "==> Test Accuracy:  Acc@1 56.180 || Acc@5 84.650\n",
            "==> 72.34 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 59, lr: 0.1 -----\n",
            "Epoch: [59][  0/391]\tTime  0.265 ( 0.265)\tLoss 1.7302e+00 (1.7302e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  83.59 ( 83.59)\n",
            "Epoch: [59][ 30/391]\tTime  0.178 ( 0.177)\tLoss 1.5817e+00 (1.6976e+00)\tAcc@1  54.69 ( 53.12)\tAcc@5  85.94 ( 82.61)\n",
            "Epoch: [59][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.8823e+00 (1.7015e+00)\tAcc@1  49.22 ( 53.29)\tAcc@5  81.25 ( 82.68)\n",
            "Epoch: [59][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.5380e+00 (1.7071e+00)\tAcc@1  58.59 ( 53.37)\tAcc@5  85.94 ( 82.43)\n",
            "Epoch: [59][120/391]\tTime  0.174 ( 0.174)\tLoss 1.9398e+00 (1.7053e+00)\tAcc@1  52.34 ( 53.47)\tAcc@5  74.22 ( 82.44)\n",
            "Epoch: [59][150/391]\tTime  0.175 ( 0.174)\tLoss 1.7275e+00 (1.7190e+00)\tAcc@1  54.69 ( 53.27)\tAcc@5  79.69 ( 82.15)\n",
            "Epoch: [59][180/391]\tTime  0.173 ( 0.174)\tLoss 1.6301e+00 (1.7211e+00)\tAcc@1  49.22 ( 53.05)\tAcc@5  85.94 ( 82.18)\n",
            "Epoch: [59][210/391]\tTime  0.175 ( 0.174)\tLoss 1.7395e+00 (1.7275e+00)\tAcc@1  48.44 ( 52.77)\tAcc@5  83.59 ( 82.13)\n",
            "Epoch: [59][240/391]\tTime  0.172 ( 0.174)\tLoss 1.7076e+00 (1.7365e+00)\tAcc@1  54.69 ( 52.62)\tAcc@5  85.16 ( 82.04)\n",
            "Epoch: [59][270/391]\tTime  0.174 ( 0.174)\tLoss 1.6474e+00 (1.7411e+00)\tAcc@1  53.91 ( 52.55)\tAcc@5  82.03 ( 81.97)\n",
            "Epoch: [59][300/391]\tTime  0.172 ( 0.174)\tLoss 1.7009e+00 (1.7358e+00)\tAcc@1  56.25 ( 52.73)\tAcc@5  82.03 ( 82.08)\n",
            "Epoch: [59][330/391]\tTime  0.172 ( 0.174)\tLoss 1.6714e+00 (1.7327e+00)\tAcc@1  50.78 ( 52.72)\tAcc@5  87.50 ( 82.19)\n",
            "Epoch: [59][360/391]\tTime  0.173 ( 0.174)\tLoss 1.8145e+00 (1.7338e+00)\tAcc@1  51.56 ( 52.71)\tAcc@5  80.47 ( 82.15)\n",
            "Epoch: [59][390/391]\tTime  0.157 ( 0.174)\tLoss 1.6299e+00 (1.7366e+00)\tAcc@1  51.25 ( 52.69)\tAcc@5  87.50 ( 82.10)\n",
            "==> Train Accuracy: Acc@1 52.690 || Acc@5 82.096\n",
            "==> Test Accuracy:  Acc@1 53.550 || Acc@5 82.910\n",
            "==> 72.30 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 60, lr: 0.020000000000000004 -----\n",
            "Epoch: [60][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.7789e+00 (1.7789e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [60][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.3737e+00 (1.5529e+00)\tAcc@1  63.28 ( 56.70)\tAcc@5  85.16 ( 85.18)\n",
            "Epoch: [60][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.4639e+00 (1.4971e+00)\tAcc@1  53.91 ( 58.72)\tAcc@5  84.38 ( 85.69)\n",
            "Epoch: [60][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.4244e+00 (1.4756e+00)\tAcc@1  62.50 ( 59.47)\tAcc@5  89.06 ( 86.16)\n",
            "Epoch: [60][120/391]\tTime  0.174 ( 0.174)\tLoss 1.3705e+00 (1.4357e+00)\tAcc@1  60.94 ( 60.45)\tAcc@5  88.28 ( 86.80)\n",
            "Epoch: [60][150/391]\tTime  0.174 ( 0.174)\tLoss 1.3447e+00 (1.4151e+00)\tAcc@1  63.28 ( 60.84)\tAcc@5  85.16 ( 86.99)\n",
            "Epoch: [60][180/391]\tTime  0.175 ( 0.174)\tLoss 1.3881e+00 (1.3954e+00)\tAcc@1  62.50 ( 61.37)\tAcc@5  85.94 ( 87.29)\n",
            "Epoch: [60][210/391]\tTime  0.174 ( 0.174)\tLoss 1.3757e+00 (1.3825e+00)\tAcc@1  60.16 ( 61.71)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [60][240/391]\tTime  0.174 ( 0.174)\tLoss 1.4844e+00 (1.3722e+00)\tAcc@1  61.72 ( 61.87)\tAcc@5  89.84 ( 87.63)\n",
            "Epoch: [60][270/391]\tTime  0.172 ( 0.174)\tLoss 1.3567e+00 (1.3653e+00)\tAcc@1  62.50 ( 62.04)\tAcc@5  85.94 ( 87.66)\n",
            "Epoch: [60][300/391]\tTime  0.174 ( 0.174)\tLoss 1.2908e+00 (1.3541e+00)\tAcc@1  65.62 ( 62.38)\tAcc@5  90.62 ( 87.78)\n",
            "Epoch: [60][330/391]\tTime  0.174 ( 0.174)\tLoss 1.3529e+00 (1.3477e+00)\tAcc@1  64.06 ( 62.47)\tAcc@5  86.72 ( 87.84)\n",
            "Epoch: [60][360/391]\tTime  0.176 ( 0.174)\tLoss 1.2021e+00 (1.3458e+00)\tAcc@1  67.97 ( 62.47)\tAcc@5  88.28 ( 87.85)\n",
            "Epoch: [60][390/391]\tTime  0.156 ( 0.174)\tLoss 1.2486e+00 (1.3382e+00)\tAcc@1  63.75 ( 62.67)\tAcc@5  92.50 ( 88.00)\n",
            "==> Train Accuracy: Acc@1 62.672 || Acc@5 87.996\n",
            "==> Test Accuracy:  Acc@1 70.510 || Acc@5 92.220\n",
            "==> 72.36 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 61, lr: 0.020000000000000004 -----\n",
            "Epoch: [61][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.3106e+00 (1.3106e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [61][ 30/391]\tTime  0.177 ( 0.177)\tLoss 1.2294e+00 (1.1961e+00)\tAcc@1  61.72 ( 65.78)\tAcc@5  89.84 ( 89.94)\n",
            "Epoch: [61][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.3066e+00 (1.1854e+00)\tAcc@1  59.38 ( 66.24)\tAcc@5  92.19 ( 90.14)\n",
            "Epoch: [61][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.2768e+00 (1.1954e+00)\tAcc@1  62.50 ( 66.17)\tAcc@5  87.50 ( 89.98)\n",
            "Epoch: [61][120/391]\tTime  0.174 ( 0.175)\tLoss 1.1594e+00 (1.1980e+00)\tAcc@1  66.41 ( 66.08)\tAcc@5  92.19 ( 89.95)\n",
            "Epoch: [61][150/391]\tTime  0.175 ( 0.174)\tLoss 1.2673e+00 (1.1965e+00)\tAcc@1  63.28 ( 66.19)\tAcc@5  87.50 ( 89.95)\n",
            "Epoch: [61][180/391]\tTime  0.173 ( 0.174)\tLoss 1.3498e+00 (1.1994e+00)\tAcc@1  64.84 ( 66.07)\tAcc@5  89.06 ( 89.85)\n",
            "Epoch: [61][210/391]\tTime  0.172 ( 0.174)\tLoss 1.1556e+00 (1.2080e+00)\tAcc@1  65.62 ( 65.89)\tAcc@5  89.84 ( 89.64)\n",
            "Epoch: [61][240/391]\tTime  0.173 ( 0.174)\tLoss 1.0535e+00 (1.2114e+00)\tAcc@1  73.44 ( 65.85)\tAcc@5  91.41 ( 89.64)\n",
            "Epoch: [61][270/391]\tTime  0.173 ( 0.174)\tLoss 1.2258e+00 (1.2139e+00)\tAcc@1  66.41 ( 65.67)\tAcc@5  89.06 ( 89.65)\n",
            "Epoch: [61][300/391]\tTime  0.175 ( 0.174)\tLoss 1.1220e+00 (1.2127e+00)\tAcc@1  71.88 ( 65.77)\tAcc@5  89.84 ( 89.65)\n",
            "Epoch: [61][330/391]\tTime  0.173 ( 0.174)\tLoss 1.1077e+00 (1.2123e+00)\tAcc@1  68.75 ( 65.79)\tAcc@5  91.41 ( 89.64)\n",
            "Epoch: [61][360/391]\tTime  0.176 ( 0.174)\tLoss 1.0664e+00 (1.2139e+00)\tAcc@1  70.31 ( 65.75)\tAcc@5  91.41 ( 89.63)\n",
            "Epoch: [61][390/391]\tTime  0.157 ( 0.174)\tLoss 1.3373e+00 (1.2146e+00)\tAcc@1  60.00 ( 65.74)\tAcc@5  91.25 ( 89.55)\n",
            "==> Train Accuracy: Acc@1 65.742 || Acc@5 89.554\n",
            "==> Test Accuracy:  Acc@1 71.350 || Acc@5 92.910\n",
            "==> 72.39 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 62, lr: 0.020000000000000004 -----\n",
            "Epoch: [62][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.2277e+00 (1.2277e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [62][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.0306e+00 (1.1209e+00)\tAcc@1  74.22 ( 68.93)\tAcc@5  89.06 ( 90.75)\n",
            "Epoch: [62][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.1683e+00 (1.1205e+00)\tAcc@1  63.28 ( 68.06)\tAcc@5  94.53 ( 91.09)\n",
            "Epoch: [62][ 90/391]\tTime  0.167 ( 0.175)\tLoss 1.0223e+00 (1.1486e+00)\tAcc@1  71.88 ( 67.74)\tAcc@5  92.97 ( 90.56)\n",
            "Epoch: [62][120/391]\tTime  0.175 ( 0.175)\tLoss 1.2768e+00 (1.1539e+00)\tAcc@1  67.19 ( 67.54)\tAcc@5  87.50 ( 90.41)\n",
            "Epoch: [62][150/391]\tTime  0.171 ( 0.174)\tLoss 8.5105e-01 (1.1512e+00)\tAcc@1  78.91 ( 67.53)\tAcc@5  93.75 ( 90.56)\n",
            "Epoch: [62][180/391]\tTime  0.174 ( 0.174)\tLoss 1.1037e+00 (1.1527e+00)\tAcc@1  69.53 ( 67.38)\tAcc@5  90.62 ( 90.47)\n",
            "Epoch: [62][210/391]\tTime  0.175 ( 0.174)\tLoss 1.0443e+00 (1.1619e+00)\tAcc@1  71.09 ( 67.18)\tAcc@5  91.41 ( 90.29)\n",
            "Epoch: [62][240/391]\tTime  0.175 ( 0.174)\tLoss 1.0094e+00 (1.1620e+00)\tAcc@1  68.75 ( 67.18)\tAcc@5  94.53 ( 90.29)\n",
            "Epoch: [62][270/391]\tTime  0.176 ( 0.174)\tLoss 1.1093e+00 (1.1543e+00)\tAcc@1  67.19 ( 67.39)\tAcc@5  95.31 ( 90.42)\n",
            "Epoch: [62][300/391]\tTime  0.175 ( 0.174)\tLoss 1.1632e+00 (1.1558e+00)\tAcc@1  68.75 ( 67.29)\tAcc@5  94.53 ( 90.47)\n",
            "Epoch: [62][330/391]\tTime  0.174 ( 0.174)\tLoss 1.0100e+00 (1.1535e+00)\tAcc@1  71.09 ( 67.33)\tAcc@5  93.75 ( 90.50)\n",
            "Epoch: [62][360/391]\tTime  0.171 ( 0.174)\tLoss 1.2379e+00 (1.1576e+00)\tAcc@1  72.66 ( 67.24)\tAcc@5  86.72 ( 90.46)\n",
            "Epoch: [62][390/391]\tTime  0.155 ( 0.174)\tLoss 9.9365e-01 (1.1577e+00)\tAcc@1  71.25 ( 67.26)\tAcc@5  95.00 ( 90.46)\n",
            "==> Train Accuracy: Acc@1 67.262 || Acc@5 90.462\n",
            "==> Test Accuracy:  Acc@1 71.320 || Acc@5 92.920\n",
            "==> 72.40 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 63, lr: 0.020000000000000004 -----\n",
            "Epoch: [63][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.1349e+00 (1.1349e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [63][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.0261e+00 (1.0932e+00)\tAcc@1  72.66 ( 68.65)\tAcc@5  91.41 ( 91.03)\n",
            "Epoch: [63][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.1504e+00 (1.1167e+00)\tAcc@1  64.84 ( 68.17)\tAcc@5  93.75 ( 90.77)\n",
            "Epoch: [63][ 90/391]\tTime  0.171 ( 0.175)\tLoss 1.3550e+00 (1.1183e+00)\tAcc@1  64.06 ( 68.29)\tAcc@5  87.50 ( 90.78)\n",
            "Epoch: [63][120/391]\tTime  0.174 ( 0.175)\tLoss 1.0612e+00 (1.1241e+00)\tAcc@1  67.97 ( 68.14)\tAcc@5  90.62 ( 90.73)\n",
            "Epoch: [63][150/391]\tTime  0.175 ( 0.174)\tLoss 1.3000e+00 (1.1315e+00)\tAcc@1  61.72 ( 68.00)\tAcc@5  90.62 ( 90.65)\n",
            "Epoch: [63][180/391]\tTime  0.175 ( 0.174)\tLoss 1.0356e+00 (1.1269e+00)\tAcc@1  75.00 ( 68.04)\tAcc@5  92.19 ( 90.81)\n",
            "Epoch: [63][210/391]\tTime  0.175 ( 0.174)\tLoss 1.0920e+00 (1.1368e+00)\tAcc@1  70.31 ( 67.77)\tAcc@5  89.84 ( 90.63)\n",
            "Epoch: [63][240/391]\tTime  0.175 ( 0.174)\tLoss 9.3233e-01 (1.1328e+00)\tAcc@1  71.88 ( 67.85)\tAcc@5  92.97 ( 90.71)\n",
            "Epoch: [63][270/391]\tTime  0.175 ( 0.174)\tLoss 1.2139e+00 (1.1335e+00)\tAcc@1  67.19 ( 67.94)\tAcc@5  89.84 ( 90.70)\n",
            "Epoch: [63][300/391]\tTime  0.172 ( 0.174)\tLoss 1.1270e+00 (1.1354e+00)\tAcc@1  68.75 ( 67.83)\tAcc@5  91.41 ( 90.69)\n",
            "Epoch: [63][330/391]\tTime  0.173 ( 0.174)\tLoss 1.3754e+00 (1.1380e+00)\tAcc@1  64.84 ( 67.73)\tAcc@5  85.16 ( 90.71)\n",
            "Epoch: [63][360/391]\tTime  0.174 ( 0.174)\tLoss 9.3799e-01 (1.1383e+00)\tAcc@1  70.31 ( 67.78)\tAcc@5  96.09 ( 90.72)\n",
            "Epoch: [63][390/391]\tTime  0.156 ( 0.174)\tLoss 1.0615e+00 (1.1379e+00)\tAcc@1  65.00 ( 67.72)\tAcc@5  92.50 ( 90.70)\n",
            "==> Train Accuracy: Acc@1 67.724 || Acc@5 90.704\n",
            "==> Test Accuracy:  Acc@1 71.960 || Acc@5 93.070\n",
            "==> 72.39 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 64, lr: 0.020000000000000004 -----\n",
            "Epoch: [64][  0/391]\tTime  0.247 ( 0.247)\tLoss 1.0537e+00 (1.0537e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [64][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.0100e+00 (1.0689e+00)\tAcc@1  74.22 ( 70.59)\tAcc@5  88.28 ( 91.28)\n",
            "Epoch: [64][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.0642e+00 (1.0671e+00)\tAcc@1  67.97 ( 70.59)\tAcc@5  87.50 ( 91.20)\n",
            "Epoch: [64][ 90/391]\tTime  0.172 ( 0.174)\tLoss 1.0273e+00 (1.0764e+00)\tAcc@1  71.88 ( 70.18)\tAcc@5  90.62 ( 91.21)\n",
            "Epoch: [64][120/391]\tTime  0.172 ( 0.174)\tLoss 9.1046e-01 (1.0804e+00)\tAcc@1  72.66 ( 69.91)\tAcc@5  95.31 ( 91.14)\n",
            "Epoch: [64][150/391]\tTime  0.173 ( 0.174)\tLoss 1.1257e+00 (1.0920e+00)\tAcc@1  66.41 ( 69.44)\tAcc@5  92.97 ( 91.08)\n",
            "Epoch: [64][180/391]\tTime  0.174 ( 0.174)\tLoss 1.0652e+00 (1.0933e+00)\tAcc@1  68.75 ( 69.32)\tAcc@5  92.19 ( 91.06)\n",
            "Epoch: [64][210/391]\tTime  0.173 ( 0.174)\tLoss 1.0421e+00 (1.0936e+00)\tAcc@1  68.75 ( 69.24)\tAcc@5  95.31 ( 91.12)\n",
            "Epoch: [64][240/391]\tTime  0.175 ( 0.174)\tLoss 1.1885e+00 (1.0900e+00)\tAcc@1  63.28 ( 69.21)\tAcc@5  92.19 ( 91.18)\n",
            "Epoch: [64][270/391]\tTime  0.174 ( 0.174)\tLoss 1.1329e+00 (1.0970e+00)\tAcc@1  61.72 ( 68.92)\tAcc@5  91.41 ( 91.05)\n",
            "Epoch: [64][300/391]\tTime  0.173 ( 0.174)\tLoss 1.1659e+00 (1.0998e+00)\tAcc@1  64.06 ( 68.81)\tAcc@5  92.97 ( 91.04)\n",
            "Epoch: [64][330/391]\tTime  0.172 ( 0.174)\tLoss 1.1326e+00 (1.1026e+00)\tAcc@1  64.84 ( 68.79)\tAcc@5  93.75 ( 91.05)\n",
            "Epoch: [64][360/391]\tTime  0.174 ( 0.174)\tLoss 1.2532e+00 (1.1052e+00)\tAcc@1  65.62 ( 68.72)\tAcc@5  88.28 ( 91.01)\n",
            "Epoch: [64][390/391]\tTime  0.155 ( 0.174)\tLoss 1.0183e+00 (1.1091e+00)\tAcc@1  70.00 ( 68.61)\tAcc@5  91.25 ( 90.91)\n",
            "==> Train Accuracy: Acc@1 68.612 || Acc@5 90.912\n",
            "==> Test Accuracy:  Acc@1 71.070 || Acc@5 93.060\n",
            "==> 72.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 65, lr: 0.020000000000000004 -----\n",
            "Epoch: [65][  0/391]\tTime  0.256 ( 0.256)\tLoss 9.0888e-01 (9.0888e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [65][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.1297e+00 (1.0282e+00)\tAcc@1  68.75 ( 71.17)\tAcc@5  92.19 ( 91.91)\n",
            "Epoch: [65][ 60/391]\tTime  0.173 ( 0.175)\tLoss 9.7546e-01 (1.0171e+00)\tAcc@1  76.56 ( 71.20)\tAcc@5  94.53 ( 92.26)\n",
            "Epoch: [65][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.1658e+00 (1.0222e+00)\tAcc@1  64.06 ( 71.15)\tAcc@5  90.62 ( 92.14)\n",
            "Epoch: [65][120/391]\tTime  0.174 ( 0.174)\tLoss 1.2264e+00 (1.0435e+00)\tAcc@1  62.50 ( 70.71)\tAcc@5  89.06 ( 91.92)\n",
            "Epoch: [65][150/391]\tTime  0.175 ( 0.174)\tLoss 1.2696e+00 (1.0578e+00)\tAcc@1  64.06 ( 70.42)\tAcc@5  90.62 ( 91.69)\n",
            "Epoch: [65][180/391]\tTime  0.173 ( 0.174)\tLoss 9.9303e-01 (1.0617e+00)\tAcc@1  71.88 ( 70.20)\tAcc@5  93.75 ( 91.67)\n",
            "Epoch: [65][210/391]\tTime  0.174 ( 0.174)\tLoss 9.6816e-01 (1.0604e+00)\tAcc@1  71.88 ( 70.25)\tAcc@5  90.62 ( 91.72)\n",
            "Epoch: [65][240/391]\tTime  0.174 ( 0.174)\tLoss 1.1467e+00 (1.0660e+00)\tAcc@1  64.84 ( 70.00)\tAcc@5  93.75 ( 91.66)\n",
            "Epoch: [65][270/391]\tTime  0.173 ( 0.174)\tLoss 1.0517e+00 (1.0739e+00)\tAcc@1  69.53 ( 69.67)\tAcc@5  92.19 ( 91.59)\n",
            "Epoch: [65][300/391]\tTime  0.173 ( 0.174)\tLoss 1.1068e+00 (1.0779e+00)\tAcc@1  67.19 ( 69.52)\tAcc@5  91.41 ( 91.55)\n",
            "Epoch: [65][330/391]\tTime  0.172 ( 0.174)\tLoss 7.9151e-01 (1.0807e+00)\tAcc@1  78.91 ( 69.43)\tAcc@5  97.66 ( 91.51)\n",
            "Epoch: [65][360/391]\tTime  0.175 ( 0.174)\tLoss 1.2176e+00 (1.0849e+00)\tAcc@1  66.41 ( 69.28)\tAcc@5  89.06 ( 91.45)\n",
            "Epoch: [65][390/391]\tTime  0.155 ( 0.174)\tLoss 1.0633e+00 (1.0862e+00)\tAcc@1  73.75 ( 69.24)\tAcc@5  90.00 ( 91.43)\n",
            "==> Train Accuracy: Acc@1 69.238 || Acc@5 91.430\n",
            "==> Test Accuracy:  Acc@1 72.340 || Acc@5 93.230\n",
            "==> 72.31 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 66, lr: 0.020000000000000004 -----\n",
            "Epoch: [66][  0/391]\tTime  0.256 ( 0.256)\tLoss 9.6445e-01 (9.6445e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [66][ 30/391]\tTime  0.171 ( 0.176)\tLoss 9.1314e-01 (1.0366e+00)\tAcc@1  74.22 ( 69.78)\tAcc@5  92.19 ( 92.16)\n",
            "Epoch: [66][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.0771e+00 (1.0470e+00)\tAcc@1  67.97 ( 69.86)\tAcc@5  92.97 ( 91.85)\n",
            "Epoch: [66][ 90/391]\tTime  0.173 ( 0.174)\tLoss 1.0224e+00 (1.0656e+00)\tAcc@1  67.19 ( 69.33)\tAcc@5  92.97 ( 91.60)\n",
            "Epoch: [66][120/391]\tTime  0.173 ( 0.174)\tLoss 1.0426e+00 (1.0652e+00)\tAcc@1  69.53 ( 69.32)\tAcc@5  91.41 ( 91.63)\n",
            "Epoch: [66][150/391]\tTime  0.173 ( 0.174)\tLoss 1.3377e+00 (1.0694e+00)\tAcc@1  64.84 ( 69.37)\tAcc@5  87.50 ( 91.49)\n",
            "Epoch: [66][180/391]\tTime  0.173 ( 0.174)\tLoss 1.2695e+00 (1.0646e+00)\tAcc@1  65.62 ( 69.48)\tAcc@5  90.62 ( 91.57)\n",
            "Epoch: [66][210/391]\tTime  0.173 ( 0.174)\tLoss 9.6945e-01 (1.0707e+00)\tAcc@1  78.12 ( 69.38)\tAcc@5  93.75 ( 91.54)\n",
            "Epoch: [66][240/391]\tTime  0.172 ( 0.174)\tLoss 1.0343e+00 (1.0781e+00)\tAcc@1  72.66 ( 69.24)\tAcc@5  92.19 ( 91.38)\n",
            "Epoch: [66][270/391]\tTime  0.173 ( 0.174)\tLoss 1.0229e+00 (1.0769e+00)\tAcc@1  64.84 ( 69.23)\tAcc@5  95.31 ( 91.37)\n",
            "Epoch: [66][300/391]\tTime  0.171 ( 0.174)\tLoss 1.1305e+00 (1.0761e+00)\tAcc@1  69.53 ( 69.29)\tAcc@5  91.41 ( 91.35)\n",
            "Epoch: [66][330/391]\tTime  0.173 ( 0.174)\tLoss 1.1221e+00 (1.0783e+00)\tAcc@1  64.06 ( 69.19)\tAcc@5  94.53 ( 91.36)\n",
            "Epoch: [66][360/391]\tTime  0.172 ( 0.174)\tLoss 1.0888e+00 (1.0814e+00)\tAcc@1  72.66 ( 69.12)\tAcc@5  90.62 ( 91.29)\n",
            "Epoch: [66][390/391]\tTime  0.156 ( 0.173)\tLoss 1.0717e+00 (1.0830e+00)\tAcc@1  68.75 ( 69.14)\tAcc@5  95.00 ( 91.27)\n",
            "==> Train Accuracy: Acc@1 69.138 || Acc@5 91.274\n",
            "==> Test Accuracy:  Acc@1 71.610 || Acc@5 93.220\n",
            "==> 72.17 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 67, lr: 0.020000000000000004 -----\n",
            "Epoch: [67][  0/391]\tTime  0.249 ( 0.249)\tLoss 1.0081e+00 (1.0081e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [67][ 30/391]\tTime  0.172 ( 0.176)\tLoss 9.1365e-01 (1.0137e+00)\tAcc@1  70.31 ( 70.51)\tAcc@5  96.09 ( 92.34)\n",
            "Epoch: [67][ 60/391]\tTime  0.173 ( 0.175)\tLoss 8.2233e-01 (1.0115e+00)\tAcc@1  76.56 ( 71.02)\tAcc@5  93.75 ( 92.26)\n",
            "Epoch: [67][ 90/391]\tTime  0.172 ( 0.174)\tLoss 1.0123e+00 (1.0166e+00)\tAcc@1  70.31 ( 70.87)\tAcc@5  91.41 ( 92.26)\n",
            "Epoch: [67][120/391]\tTime  0.174 ( 0.174)\tLoss 9.3846e-01 (1.0267e+00)\tAcc@1  75.78 ( 70.65)\tAcc@5  92.97 ( 92.05)\n",
            "Epoch: [67][150/391]\tTime  0.174 ( 0.174)\tLoss 1.2139e+00 (1.0304e+00)\tAcc@1  67.97 ( 70.64)\tAcc@5  87.50 ( 92.10)\n",
            "Epoch: [67][180/391]\tTime  0.173 ( 0.174)\tLoss 1.2302e+00 (1.0436e+00)\tAcc@1  67.97 ( 70.25)\tAcc@5  88.28 ( 92.03)\n",
            "Epoch: [67][210/391]\tTime  0.173 ( 0.174)\tLoss 1.0999e+00 (1.0507e+00)\tAcc@1  65.62 ( 70.00)\tAcc@5  92.97 ( 91.93)\n",
            "Epoch: [67][240/391]\tTime  0.175 ( 0.174)\tLoss 1.0896e+00 (1.0540e+00)\tAcc@1  69.53 ( 69.93)\tAcc@5  92.97 ( 91.82)\n",
            "Epoch: [67][270/391]\tTime  0.173 ( 0.174)\tLoss 9.5502e-01 (1.0611e+00)\tAcc@1  73.44 ( 69.69)\tAcc@5  92.97 ( 91.72)\n",
            "Epoch: [67][300/391]\tTime  0.174 ( 0.174)\tLoss 1.2306e+00 (1.0656e+00)\tAcc@1  63.28 ( 69.56)\tAcc@5  85.94 ( 91.67)\n",
            "Epoch: [67][330/391]\tTime  0.175 ( 0.174)\tLoss 1.0312e+00 (1.0665e+00)\tAcc@1  70.31 ( 69.50)\tAcc@5  90.62 ( 91.65)\n",
            "Epoch: [67][360/391]\tTime  0.171 ( 0.174)\tLoss 1.1402e+00 (1.0709e+00)\tAcc@1  68.75 ( 69.43)\tAcc@5  86.72 ( 91.58)\n",
            "Epoch: [67][390/391]\tTime  0.157 ( 0.174)\tLoss 1.0475e+00 (1.0724e+00)\tAcc@1  68.75 ( 69.39)\tAcc@5  93.75 ( 91.58)\n",
            "==> Train Accuracy: Acc@1 69.386 || Acc@5 91.580\n",
            "==> Test Accuracy:  Acc@1 72.070 || Acc@5 93.080\n",
            "==> 72.21 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 68, lr: 0.020000000000000004 -----\n",
            "Epoch: [68][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.1209e+00 (1.1209e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [68][ 30/391]\tTime  0.175 ( 0.177)\tLoss 8.8388e-01 (1.0301e+00)\tAcc@1  69.53 ( 70.99)\tAcc@5  96.09 ( 92.26)\n",
            "Epoch: [68][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.0728e+00 (1.0382e+00)\tAcc@1  71.88 ( 70.75)\tAcc@5  92.19 ( 92.07)\n",
            "Epoch: [68][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.1108e+00 (1.0363e+00)\tAcc@1  65.62 ( 70.53)\tAcc@5  90.62 ( 92.14)\n",
            "Epoch: [68][120/391]\tTime  0.174 ( 0.174)\tLoss 8.0280e-01 (1.0273e+00)\tAcc@1  75.00 ( 70.72)\tAcc@5  93.75 ( 92.31)\n",
            "Epoch: [68][150/391]\tTime  0.175 ( 0.174)\tLoss 1.1231e+00 (1.0402e+00)\tAcc@1  70.31 ( 70.48)\tAcc@5  86.72 ( 92.06)\n",
            "Epoch: [68][180/391]\tTime  0.175 ( 0.174)\tLoss 1.1228e+00 (1.0473e+00)\tAcc@1  71.09 ( 70.34)\tAcc@5  91.41 ( 91.97)\n",
            "Epoch: [68][210/391]\tTime  0.174 ( 0.174)\tLoss 1.0385e+00 (1.0508e+00)\tAcc@1  75.00 ( 70.33)\tAcc@5  92.19 ( 91.81)\n",
            "Epoch: [68][240/391]\tTime  0.172 ( 0.174)\tLoss 9.3742e-01 (1.0501e+00)\tAcc@1  70.31 ( 70.32)\tAcc@5  93.75 ( 91.80)\n",
            "Epoch: [68][270/391]\tTime  0.174 ( 0.174)\tLoss 1.1407e+00 (1.0545e+00)\tAcc@1  68.75 ( 70.11)\tAcc@5  86.72 ( 91.74)\n",
            "Epoch: [68][300/391]\tTime  0.174 ( 0.174)\tLoss 1.1690e+00 (1.0610e+00)\tAcc@1  66.41 ( 69.90)\tAcc@5  94.53 ( 91.63)\n",
            "Epoch: [68][330/391]\tTime  0.174 ( 0.174)\tLoss 9.1333e-01 (1.0647e+00)\tAcc@1  69.53 ( 69.74)\tAcc@5  93.75 ( 91.58)\n",
            "Epoch: [68][360/391]\tTime  0.171 ( 0.174)\tLoss 1.1779e+00 (1.0669e+00)\tAcc@1  67.97 ( 69.70)\tAcc@5  89.06 ( 91.52)\n",
            "Epoch: [68][390/391]\tTime  0.157 ( 0.174)\tLoss 1.1001e+00 (1.0704e+00)\tAcc@1  65.00 ( 69.57)\tAcc@5  91.25 ( 91.49)\n",
            "==> Train Accuracy: Acc@1 69.570 || Acc@5 91.486\n",
            "==> Test Accuracy:  Acc@1 71.400 || Acc@5 92.880\n",
            "==> 72.36 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 69, lr: 0.020000000000000004 -----\n",
            "Epoch: [69][  0/391]\tTime  0.259 ( 0.259)\tLoss 1.1328e+00 (1.1328e+00)\tAcc@1  69.53 ( 69.53)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [69][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.0226e+00 (1.0266e+00)\tAcc@1  69.53 ( 70.67)\tAcc@5  93.75 ( 92.62)\n",
            "Epoch: [69][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.0242e+00 (1.0297e+00)\tAcc@1  71.88 ( 70.72)\tAcc@5  92.19 ( 92.33)\n",
            "Epoch: [69][ 90/391]\tTime  0.172 ( 0.174)\tLoss 1.1715e+00 (1.0254e+00)\tAcc@1  67.19 ( 70.89)\tAcc@5  89.84 ( 92.02)\n",
            "Epoch: [69][120/391]\tTime  0.172 ( 0.174)\tLoss 9.1710e-01 (1.0221e+00)\tAcc@1  72.66 ( 70.98)\tAcc@5  96.09 ( 92.08)\n",
            "Epoch: [69][150/391]\tTime  0.175 ( 0.174)\tLoss 1.1749e+00 (1.0246e+00)\tAcc@1  67.97 ( 70.93)\tAcc@5  88.28 ( 92.12)\n",
            "Epoch: [69][180/391]\tTime  0.174 ( 0.174)\tLoss 1.0030e+00 (1.0361e+00)\tAcc@1  67.97 ( 70.63)\tAcc@5  93.75 ( 91.92)\n",
            "Epoch: [69][210/391]\tTime  0.175 ( 0.174)\tLoss 9.5167e-01 (1.0432e+00)\tAcc@1  71.09 ( 70.38)\tAcc@5  94.53 ( 91.88)\n",
            "Epoch: [69][240/391]\tTime  0.172 ( 0.174)\tLoss 9.4181e-01 (1.0479e+00)\tAcc@1  72.66 ( 70.20)\tAcc@5  93.75 ( 91.85)\n",
            "Epoch: [69][270/391]\tTime  0.171 ( 0.174)\tLoss 9.3839e-01 (1.0516e+00)\tAcc@1  75.78 ( 70.19)\tAcc@5  93.75 ( 91.78)\n",
            "Epoch: [69][300/391]\tTime  0.174 ( 0.174)\tLoss 9.7706e-01 (1.0545e+00)\tAcc@1  71.88 ( 70.13)\tAcc@5  93.75 ( 91.76)\n",
            "Epoch: [69][330/391]\tTime  0.174 ( 0.174)\tLoss 1.1121e+00 (1.0600e+00)\tAcc@1  72.66 ( 69.99)\tAcc@5  89.06 ( 91.70)\n",
            "Epoch: [69][360/391]\tTime  0.175 ( 0.174)\tLoss 1.2980e+00 (1.0673e+00)\tAcc@1  59.38 ( 69.81)\tAcc@5  89.06 ( 91.58)\n",
            "Epoch: [69][390/391]\tTime  0.157 ( 0.174)\tLoss 1.1502e+00 (1.0668e+00)\tAcc@1  72.50 ( 69.79)\tAcc@5  95.00 ( 91.59)\n",
            "==> Train Accuracy: Acc@1 69.794 || Acc@5 91.594\n",
            "==> Test Accuracy:  Acc@1 70.360 || Acc@5 92.740\n",
            "==> 72.36 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 70, lr: 0.020000000000000004 -----\n",
            "Epoch: [70][  0/391]\tTime  0.268 ( 0.268)\tLoss 8.3781e-01 (8.3781e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [70][ 30/391]\tTime  0.174 ( 0.177)\tLoss 9.9803e-01 (9.9687e-01)\tAcc@1  71.88 ( 71.62)\tAcc@5  90.62 ( 92.72)\n",
            "Epoch: [70][ 60/391]\tTime  0.178 ( 0.175)\tLoss 1.3223e+00 (9.9713e-01)\tAcc@1  57.81 ( 71.54)\tAcc@5  89.84 ( 92.62)\n",
            "Epoch: [70][ 90/391]\tTime  0.175 ( 0.175)\tLoss 9.0695e-01 (1.0099e+00)\tAcc@1  78.12 ( 71.36)\tAcc@5  92.97 ( 92.46)\n",
            "Epoch: [70][120/391]\tTime  0.173 ( 0.175)\tLoss 1.0842e+00 (1.0111e+00)\tAcc@1  71.88 ( 71.52)\tAcc@5  91.41 ( 92.46)\n",
            "Epoch: [70][150/391]\tTime  0.176 ( 0.174)\tLoss 1.0758e+00 (1.0169e+00)\tAcc@1  66.41 ( 71.21)\tAcc@5  90.62 ( 92.36)\n",
            "Epoch: [70][180/391]\tTime  0.173 ( 0.174)\tLoss 1.0079e+00 (1.0243e+00)\tAcc@1  71.09 ( 71.09)\tAcc@5  92.97 ( 92.18)\n",
            "Epoch: [70][210/391]\tTime  0.174 ( 0.174)\tLoss 1.0892e+00 (1.0315e+00)\tAcc@1  65.62 ( 70.81)\tAcc@5  91.41 ( 92.06)\n",
            "Epoch: [70][240/391]\tTime  0.174 ( 0.174)\tLoss 1.1292e+00 (1.0335e+00)\tAcc@1  65.62 ( 70.75)\tAcc@5  89.84 ( 92.10)\n",
            "Epoch: [70][270/391]\tTime  0.175 ( 0.174)\tLoss 1.1408e+00 (1.0359e+00)\tAcc@1  69.53 ( 70.68)\tAcc@5  92.19 ( 92.06)\n",
            "Epoch: [70][300/391]\tTime  0.174 ( 0.174)\tLoss 8.4472e-01 (1.0408e+00)\tAcc@1  77.34 ( 70.49)\tAcc@5  96.09 ( 92.04)\n",
            "Epoch: [70][330/391]\tTime  0.173 ( 0.174)\tLoss 9.5786e-01 (1.0438e+00)\tAcc@1  71.09 ( 70.35)\tAcc@5  92.97 ( 92.04)\n",
            "Epoch: [70][360/391]\tTime  0.174 ( 0.174)\tLoss 9.8420e-01 (1.0464e+00)\tAcc@1  75.00 ( 70.23)\tAcc@5  92.19 ( 92.05)\n",
            "Epoch: [70][390/391]\tTime  0.156 ( 0.174)\tLoss 1.3538e+00 (1.0515e+00)\tAcc@1  68.75 ( 70.13)\tAcc@5  86.25 ( 91.95)\n",
            "==> Train Accuracy: Acc@1 70.132 || Acc@5 91.954\n",
            "==> Test Accuracy:  Acc@1 70.610 || Acc@5 92.540\n",
            "==> 72.36 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 71, lr: 0.020000000000000004 -----\n",
            "Epoch: [71][  0/391]\tTime  0.254 ( 0.254)\tLoss 1.0685e+00 (1.0685e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [71][ 30/391]\tTime  0.168 ( 0.176)\tLoss 1.1185e+00 (1.0290e+00)\tAcc@1  68.75 ( 70.74)\tAcc@5  90.62 ( 91.51)\n",
            "Epoch: [71][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.2311e+00 (1.0278e+00)\tAcc@1  69.53 ( 70.93)\tAcc@5  89.06 ( 91.80)\n",
            "Epoch: [71][ 90/391]\tTime  0.172 ( 0.174)\tLoss 9.5363e-01 (1.0295e+00)\tAcc@1  72.66 ( 70.72)\tAcc@5  94.53 ( 92.01)\n",
            "Epoch: [71][120/391]\tTime  0.174 ( 0.174)\tLoss 1.1478e+00 (1.0358e+00)\tAcc@1  64.06 ( 70.54)\tAcc@5  96.09 ( 91.99)\n",
            "Epoch: [71][150/391]\tTime  0.173 ( 0.174)\tLoss 1.0558e+00 (1.0367e+00)\tAcc@1  65.62 ( 70.47)\tAcc@5  91.41 ( 92.04)\n",
            "Epoch: [71][180/391]\tTime  0.172 ( 0.174)\tLoss 1.1455e+00 (1.0465e+00)\tAcc@1  69.53 ( 70.23)\tAcc@5  90.62 ( 91.93)\n",
            "Epoch: [71][210/391]\tTime  0.172 ( 0.174)\tLoss 9.0562e-01 (1.0486e+00)\tAcc@1  75.00 ( 70.13)\tAcc@5  92.97 ( 91.95)\n",
            "Epoch: [71][240/391]\tTime  0.174 ( 0.174)\tLoss 9.0645e-01 (1.0482e+00)\tAcc@1  71.88 ( 70.08)\tAcc@5  93.75 ( 91.97)\n",
            "Epoch: [71][270/391]\tTime  0.171 ( 0.173)\tLoss 1.3409e+00 (1.0521e+00)\tAcc@1  60.16 ( 70.02)\tAcc@5  85.94 ( 91.90)\n",
            "Epoch: [71][300/391]\tTime  0.172 ( 0.173)\tLoss 1.3012e+00 (1.0519e+00)\tAcc@1  60.16 ( 70.04)\tAcc@5  87.50 ( 91.88)\n",
            "Epoch: [71][330/391]\tTime  0.174 ( 0.173)\tLoss 1.2701e+00 (1.0523e+00)\tAcc@1  64.84 ( 70.00)\tAcc@5  92.97 ( 91.87)\n",
            "Epoch: [71][360/391]\tTime  0.173 ( 0.173)\tLoss 1.1776e+00 (1.0579e+00)\tAcc@1  68.75 ( 69.80)\tAcc@5  90.62 ( 91.78)\n",
            "Epoch: [71][390/391]\tTime  0.155 ( 0.173)\tLoss 1.1192e+00 (1.0609e+00)\tAcc@1  66.25 ( 69.77)\tAcc@5  92.50 ( 91.79)\n",
            "==> Train Accuracy: Acc@1 69.768 || Acc@5 91.786\n",
            "==> Test Accuracy:  Acc@1 70.100 || Acc@5 91.680\n",
            "==> 72.22 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 72, lr: 0.020000000000000004 -----\n",
            "Epoch: [72][  0/391]\tTime  0.370 ( 0.370)\tLoss 9.3966e-01 (9.3966e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [72][ 30/391]\tTime  0.174 ( 0.179)\tLoss 1.3215e+00 (9.9915e-01)\tAcc@1  60.94 ( 70.82)\tAcc@5  90.62 ( 92.67)\n",
            "Epoch: [72][ 60/391]\tTime  0.172 ( 0.176)\tLoss 1.0365e+00 (9.9127e-01)\tAcc@1  73.44 ( 71.31)\tAcc@5  92.19 ( 92.89)\n",
            "Epoch: [72][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.0810e+00 (1.0054e+00)\tAcc@1  75.78 ( 70.93)\tAcc@5  90.62 ( 92.61)\n",
            "Epoch: [72][120/391]\tTime  0.176 ( 0.175)\tLoss 1.0025e+00 (1.0160e+00)\tAcc@1  68.75 ( 70.89)\tAcc@5  92.97 ( 92.39)\n",
            "Epoch: [72][150/391]\tTime  0.172 ( 0.174)\tLoss 1.1998e+00 (1.0182e+00)\tAcc@1  63.28 ( 70.58)\tAcc@5  91.41 ( 92.32)\n",
            "Epoch: [72][180/391]\tTime  0.171 ( 0.174)\tLoss 1.0133e+00 (1.0192e+00)\tAcc@1  63.28 ( 70.51)\tAcc@5  96.09 ( 92.28)\n",
            "Epoch: [72][210/391]\tTime  0.173 ( 0.174)\tLoss 1.2120e+00 (1.0241e+00)\tAcc@1  64.84 ( 70.44)\tAcc@5  89.84 ( 92.30)\n",
            "Epoch: [72][240/391]\tTime  0.173 ( 0.174)\tLoss 1.1708e+00 (1.0309e+00)\tAcc@1  68.75 ( 70.29)\tAcc@5  91.41 ( 92.21)\n",
            "Epoch: [72][270/391]\tTime  0.175 ( 0.174)\tLoss 1.1727e+00 (1.0406e+00)\tAcc@1  66.41 ( 70.03)\tAcc@5  93.75 ( 92.12)\n",
            "Epoch: [72][300/391]\tTime  0.175 ( 0.174)\tLoss 1.0719e+00 (1.0461e+00)\tAcc@1  71.88 ( 69.86)\tAcc@5  91.41 ( 92.03)\n",
            "Epoch: [72][330/391]\tTime  0.173 ( 0.174)\tLoss 9.2846e-01 (1.0468e+00)\tAcc@1  73.44 ( 69.86)\tAcc@5  95.31 ( 92.01)\n",
            "Epoch: [72][360/391]\tTime  0.173 ( 0.174)\tLoss 9.4766e-01 (1.0481e+00)\tAcc@1  71.09 ( 69.94)\tAcc@5  92.97 ( 91.97)\n",
            "Epoch: [72][390/391]\tTime  0.157 ( 0.174)\tLoss 1.0370e+00 (1.0516e+00)\tAcc@1  68.75 ( 69.82)\tAcc@5  93.75 ( 91.91)\n",
            "==> Train Accuracy: Acc@1 69.818 || Acc@5 91.914\n",
            "==> Test Accuracy:  Acc@1 70.360 || Acc@5 92.030\n",
            "==> 72.21 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 73, lr: 0.020000000000000004 -----\n",
            "Epoch: [73][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.2049e+00 (1.2049e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [73][ 30/391]\tTime  0.173 ( 0.176)\tLoss 1.0457e+00 (1.0270e+00)\tAcc@1  64.06 ( 70.77)\tAcc@5  92.19 ( 92.41)\n",
            "Epoch: [73][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.3244e+00 (1.0253e+00)\tAcc@1  61.72 ( 70.49)\tAcc@5  88.28 ( 92.44)\n",
            "Epoch: [73][ 90/391]\tTime  0.174 ( 0.174)\tLoss 1.0266e+00 (1.0397e+00)\tAcc@1  72.66 ( 70.12)\tAcc@5  92.97 ( 92.19)\n",
            "Epoch: [73][120/391]\tTime  0.174 ( 0.174)\tLoss 1.1683e+00 (1.0346e+00)\tAcc@1  67.19 ( 70.33)\tAcc@5  89.06 ( 92.12)\n",
            "Epoch: [73][150/391]\tTime  0.173 ( 0.174)\tLoss 1.0148e+00 (1.0314e+00)\tAcc@1  67.97 ( 70.59)\tAcc@5  91.41 ( 92.11)\n",
            "Epoch: [73][180/391]\tTime  0.173 ( 0.174)\tLoss 8.2776e-01 (1.0347e+00)\tAcc@1  76.56 ( 70.50)\tAcc@5  95.31 ( 92.15)\n",
            "Epoch: [73][210/391]\tTime  0.173 ( 0.174)\tLoss 1.0399e+00 (1.0370e+00)\tAcc@1  68.75 ( 70.36)\tAcc@5  92.19 ( 92.12)\n",
            "Epoch: [73][240/391]\tTime  0.174 ( 0.174)\tLoss 9.9291e-01 (1.0387e+00)\tAcc@1  69.53 ( 70.27)\tAcc@5  92.19 ( 92.11)\n",
            "Epoch: [73][270/391]\tTime  0.173 ( 0.174)\tLoss 9.8490e-01 (1.0419e+00)\tAcc@1  71.09 ( 70.21)\tAcc@5  95.31 ( 92.05)\n",
            "Epoch: [73][300/391]\tTime  0.172 ( 0.174)\tLoss 1.1087e+00 (1.0431e+00)\tAcc@1  67.19 ( 70.20)\tAcc@5  92.19 ( 91.99)\n",
            "Epoch: [73][330/391]\tTime  0.173 ( 0.174)\tLoss 1.0239e+00 (1.0481e+00)\tAcc@1  72.66 ( 70.08)\tAcc@5  92.97 ( 91.89)\n",
            "Epoch: [73][360/391]\tTime  0.173 ( 0.174)\tLoss 9.6292e-01 (1.0497e+00)\tAcc@1  71.09 ( 69.97)\tAcc@5  91.41 ( 91.92)\n",
            "Epoch: [73][390/391]\tTime  0.154 ( 0.174)\tLoss 1.0979e+00 (1.0509e+00)\tAcc@1  67.50 ( 69.93)\tAcc@5  90.00 ( 91.91)\n",
            "==> Train Accuracy: Acc@1 69.930 || Acc@5 91.908\n",
            "==> Test Accuracy:  Acc@1 70.790 || Acc@5 92.270\n",
            "==> 72.18 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 74, lr: 0.020000000000000004 -----\n",
            "Epoch: [74][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.0858e+00 (1.0858e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [74][ 30/391]\tTime  0.174 ( 0.177)\tLoss 9.5907e-01 (1.0028e+00)\tAcc@1  73.44 ( 72.18)\tAcc@5  92.97 ( 91.96)\n",
            "Epoch: [74][ 60/391]\tTime  0.183 ( 0.175)\tLoss 1.1390e+00 (1.0015e+00)\tAcc@1  73.44 ( 71.91)\tAcc@5  86.72 ( 92.17)\n",
            "Epoch: [74][ 90/391]\tTime  0.174 ( 0.174)\tLoss 9.0232e-01 (1.0032e+00)\tAcc@1  76.56 ( 71.88)\tAcc@5  92.97 ( 92.31)\n",
            "Epoch: [74][120/391]\tTime  0.174 ( 0.174)\tLoss 1.1092e+00 (1.0074e+00)\tAcc@1  66.41 ( 71.62)\tAcc@5  89.84 ( 92.39)\n",
            "Epoch: [74][150/391]\tTime  0.173 ( 0.174)\tLoss 1.1501e+00 (1.0148e+00)\tAcc@1  75.00 ( 71.27)\tAcc@5  87.50 ( 92.32)\n",
            "Epoch: [74][180/391]\tTime  0.174 ( 0.174)\tLoss 1.0382e+00 (1.0252e+00)\tAcc@1  73.44 ( 70.88)\tAcc@5  92.19 ( 92.26)\n",
            "Epoch: [74][210/391]\tTime  0.174 ( 0.174)\tLoss 1.1187e+00 (1.0266e+00)\tAcc@1  65.62 ( 70.83)\tAcc@5  89.84 ( 92.23)\n",
            "Epoch: [74][240/391]\tTime  0.172 ( 0.174)\tLoss 9.4465e-01 (1.0310e+00)\tAcc@1  72.66 ( 70.68)\tAcc@5  92.97 ( 92.19)\n",
            "Epoch: [74][270/391]\tTime  0.174 ( 0.174)\tLoss 9.4116e-01 (1.0331e+00)\tAcc@1  72.66 ( 70.68)\tAcc@5  92.97 ( 92.14)\n",
            "Epoch: [74][300/391]\tTime  0.175 ( 0.174)\tLoss 1.1490e+00 (1.0331e+00)\tAcc@1  67.97 ( 70.68)\tAcc@5  89.84 ( 92.19)\n",
            "Epoch: [74][330/391]\tTime  0.173 ( 0.174)\tLoss 9.1365e-01 (1.0355e+00)\tAcc@1  74.22 ( 70.67)\tAcc@5  94.53 ( 92.15)\n",
            "Epoch: [74][360/391]\tTime  0.175 ( 0.174)\tLoss 1.4877e+00 (1.0409e+00)\tAcc@1  60.94 ( 70.48)\tAcc@5  85.16 ( 92.06)\n",
            "Epoch: [74][390/391]\tTime  0.157 ( 0.174)\tLoss 1.1351e+00 (1.0439e+00)\tAcc@1  68.75 ( 70.39)\tAcc@5  87.50 ( 92.01)\n",
            "==> Train Accuracy: Acc@1 70.390 || Acc@5 92.014\n",
            "==> Test Accuracy:  Acc@1 71.010 || Acc@5 92.190\n",
            "==> 72.30 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 75, lr: 0.020000000000000004 -----\n",
            "Epoch: [75][  0/391]\tTime  0.254 ( 0.254)\tLoss 1.2135e+00 (1.2135e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [75][ 30/391]\tTime  0.174 ( 0.176)\tLoss 6.1944e-01 (9.8642e-01)\tAcc@1  81.25 ( 72.20)\tAcc@5  96.88 ( 92.31)\n",
            "Epoch: [75][ 60/391]\tTime  0.173 ( 0.175)\tLoss 9.9974e-01 (1.0090e+00)\tAcc@1  70.31 ( 71.30)\tAcc@5  93.75 ( 92.37)\n",
            "Epoch: [75][ 90/391]\tTime  0.172 ( 0.174)\tLoss 1.0847e+00 (1.0042e+00)\tAcc@1  73.44 ( 71.48)\tAcc@5  91.41 ( 92.33)\n",
            "Epoch: [75][120/391]\tTime  0.172 ( 0.174)\tLoss 8.5627e-01 (1.0014e+00)\tAcc@1  75.00 ( 71.60)\tAcc@5  96.88 ( 92.34)\n",
            "Epoch: [75][150/391]\tTime  0.174 ( 0.174)\tLoss 9.8547e-01 (1.0090e+00)\tAcc@1  69.53 ( 71.39)\tAcc@5  97.66 ( 92.30)\n",
            "Epoch: [75][180/391]\tTime  0.173 ( 0.174)\tLoss 1.0225e+00 (1.0158e+00)\tAcc@1  71.09 ( 71.12)\tAcc@5  92.19 ( 92.30)\n",
            "Epoch: [75][210/391]\tTime  0.174 ( 0.174)\tLoss 9.8530e-01 (1.0240e+00)\tAcc@1  71.09 ( 70.87)\tAcc@5  90.62 ( 92.21)\n",
            "Epoch: [75][240/391]\tTime  0.172 ( 0.174)\tLoss 9.3930e-01 (1.0291e+00)\tAcc@1  74.22 ( 70.60)\tAcc@5  94.53 ( 92.20)\n",
            "Epoch: [75][270/391]\tTime  0.174 ( 0.174)\tLoss 1.1419e+00 (1.0327e+00)\tAcc@1  64.06 ( 70.44)\tAcc@5  92.97 ( 92.14)\n",
            "Epoch: [75][300/391]\tTime  0.173 ( 0.174)\tLoss 8.4249e-01 (1.0351e+00)\tAcc@1  78.12 ( 70.36)\tAcc@5  94.53 ( 92.15)\n",
            "Epoch: [75][330/391]\tTime  0.173 ( 0.174)\tLoss 1.0872e+00 (1.0388e+00)\tAcc@1  68.75 ( 70.33)\tAcc@5  90.62 ( 92.08)\n",
            "Epoch: [75][360/391]\tTime  0.173 ( 0.174)\tLoss 1.0916e+00 (1.0426e+00)\tAcc@1  71.09 ( 70.23)\tAcc@5  90.62 ( 92.05)\n",
            "Epoch: [75][390/391]\tTime  0.157 ( 0.174)\tLoss 9.1503e-01 (1.0448e+00)\tAcc@1  70.00 ( 70.17)\tAcc@5  97.50 ( 92.05)\n",
            "==> Train Accuracy: Acc@1 70.172 || Acc@5 92.046\n",
            "==> Test Accuracy:  Acc@1 70.610 || Acc@5 92.250\n",
            "==> 72.35 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 76, lr: 0.020000000000000004 -----\n",
            "Epoch: [76][  0/391]\tTime  0.270 ( 0.270)\tLoss 1.0429e+00 (1.0429e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [76][ 30/391]\tTime  0.173 ( 0.177)\tLoss 8.6341e-01 (9.5865e-01)\tAcc@1  73.44 ( 71.80)\tAcc@5  93.75 ( 93.20)\n",
            "Epoch: [76][ 60/391]\tTime  0.172 ( 0.175)\tLoss 9.1385e-01 (9.7306e-01)\tAcc@1  74.22 ( 71.59)\tAcc@5  92.19 ( 93.05)\n",
            "Epoch: [76][ 90/391]\tTime  0.174 ( 0.175)\tLoss 8.8425e-01 (9.6740e-01)\tAcc@1  71.09 ( 71.98)\tAcc@5  94.53 ( 93.15)\n",
            "Epoch: [76][120/391]\tTime  0.173 ( 0.174)\tLoss 9.3309e-01 (9.7999e-01)\tAcc@1  73.44 ( 71.54)\tAcc@5  91.41 ( 92.96)\n",
            "Epoch: [76][150/391]\tTime  0.174 ( 0.174)\tLoss 1.0142e+00 (9.9619e-01)\tAcc@1  73.44 ( 71.25)\tAcc@5  92.97 ( 92.76)\n",
            "Epoch: [76][180/391]\tTime  0.170 ( 0.174)\tLoss 1.0754e+00 (1.0005e+00)\tAcc@1  68.75 ( 71.12)\tAcc@5  89.06 ( 92.69)\n",
            "Epoch: [76][210/391]\tTime  0.174 ( 0.174)\tLoss 8.2826e-01 (1.0097e+00)\tAcc@1  74.22 ( 70.85)\tAcc@5  95.31 ( 92.61)\n",
            "Epoch: [76][240/391]\tTime  0.175 ( 0.174)\tLoss 1.2214e+00 (1.0198e+00)\tAcc@1  69.53 ( 70.74)\tAcc@5  86.72 ( 92.51)\n",
            "Epoch: [76][270/391]\tTime  0.172 ( 0.174)\tLoss 1.2191e+00 (1.0212e+00)\tAcc@1  64.84 ( 70.63)\tAcc@5  92.19 ( 92.50)\n",
            "Epoch: [76][300/391]\tTime  0.174 ( 0.174)\tLoss 9.4174e-01 (1.0205e+00)\tAcc@1  75.00 ( 70.73)\tAcc@5  92.97 ( 92.51)\n",
            "Epoch: [76][330/391]\tTime  0.174 ( 0.174)\tLoss 1.0526e+00 (1.0252e+00)\tAcc@1  74.22 ( 70.56)\tAcc@5  89.84 ( 92.48)\n",
            "Epoch: [76][360/391]\tTime  0.175 ( 0.174)\tLoss 1.0890e+00 (1.0288e+00)\tAcc@1  67.19 ( 70.51)\tAcc@5  91.41 ( 92.43)\n",
            "Epoch: [76][390/391]\tTime  0.157 ( 0.174)\tLoss 1.2506e+00 (1.0317e+00)\tAcc@1  68.75 ( 70.45)\tAcc@5  90.00 ( 92.38)\n",
            "==> Train Accuracy: Acc@1 70.448 || Acc@5 92.376\n",
            "==> Test Accuracy:  Acc@1 68.870 || Acc@5 92.010\n",
            "==> 72.35 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 77, lr: 0.020000000000000004 -----\n",
            "Epoch: [77][  0/391]\tTime  0.254 ( 0.254)\tLoss 1.0745e+00 (1.0745e+00)\tAcc@1  71.09 ( 71.09)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [77][ 30/391]\tTime  0.172 ( 0.176)\tLoss 9.3285e-01 (9.7416e-01)\tAcc@1  74.22 ( 71.93)\tAcc@5  94.53 ( 93.42)\n",
            "Epoch: [77][ 60/391]\tTime  0.173 ( 0.174)\tLoss 9.0744e-01 (9.8982e-01)\tAcc@1  75.00 ( 72.00)\tAcc@5  94.53 ( 92.92)\n",
            "Epoch: [77][ 90/391]\tTime  0.171 ( 0.174)\tLoss 1.0677e+00 (9.9210e-01)\tAcc@1  74.22 ( 71.88)\tAcc@5  90.62 ( 92.71)\n",
            "Epoch: [77][120/391]\tTime  0.172 ( 0.174)\tLoss 1.1965e+00 (9.9513e-01)\tAcc@1  66.41 ( 71.83)\tAcc@5  89.84 ( 92.60)\n",
            "Epoch: [77][150/391]\tTime  0.172 ( 0.174)\tLoss 1.2655e+00 (1.0018e+00)\tAcc@1  64.84 ( 71.64)\tAcc@5  89.06 ( 92.45)\n",
            "Epoch: [77][180/391]\tTime  0.175 ( 0.174)\tLoss 1.0081e+00 (1.0082e+00)\tAcc@1  67.19 ( 71.39)\tAcc@5  93.75 ( 92.42)\n",
            "Epoch: [77][210/391]\tTime  0.172 ( 0.174)\tLoss 8.5254e-01 (1.0136e+00)\tAcc@1  75.00 ( 71.23)\tAcc@5  93.75 ( 92.35)\n",
            "Epoch: [77][240/391]\tTime  0.173 ( 0.174)\tLoss 1.0825e+00 (1.0211e+00)\tAcc@1  71.88 ( 71.10)\tAcc@5  92.19 ( 92.28)\n",
            "Epoch: [77][270/391]\tTime  0.174 ( 0.174)\tLoss 1.0246e+00 (1.0264e+00)\tAcc@1  71.09 ( 70.89)\tAcc@5  92.97 ( 92.22)\n",
            "Epoch: [77][300/391]\tTime  0.174 ( 0.174)\tLoss 1.1759e+00 (1.0294e+00)\tAcc@1  65.62 ( 70.78)\tAcc@5  89.84 ( 92.20)\n",
            "Epoch: [77][330/391]\tTime  0.172 ( 0.173)\tLoss 1.1459e+00 (1.0324e+00)\tAcc@1  65.62 ( 70.65)\tAcc@5  93.75 ( 92.19)\n",
            "Epoch: [77][360/391]\tTime  0.173 ( 0.173)\tLoss 1.0193e+00 (1.0352e+00)\tAcc@1  69.53 ( 70.53)\tAcc@5  91.41 ( 92.16)\n",
            "Epoch: [77][390/391]\tTime  0.157 ( 0.173)\tLoss 1.0627e+00 (1.0362e+00)\tAcc@1  66.25 ( 70.51)\tAcc@5  93.75 ( 92.17)\n",
            "==> Train Accuracy: Acc@1 70.506 || Acc@5 92.174\n",
            "==> Test Accuracy:  Acc@1 70.550 || Acc@5 91.910\n",
            "==> 72.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 78, lr: 0.020000000000000004 -----\n",
            "Epoch: [78][  0/391]\tTime  0.283 ( 0.283)\tLoss 8.0430e-01 (8.0430e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [78][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.0878e+00 (9.7071e-01)\tAcc@1  71.88 ( 72.25)\tAcc@5  90.62 ( 92.62)\n",
            "Epoch: [78][ 60/391]\tTime  0.171 ( 0.175)\tLoss 8.1971e-01 (9.7413e-01)\tAcc@1  73.44 ( 72.16)\tAcc@5  94.53 ( 92.51)\n",
            "Epoch: [78][ 90/391]\tTime  0.173 ( 0.174)\tLoss 9.9049e-01 (9.8873e-01)\tAcc@1  71.88 ( 71.70)\tAcc@5  93.75 ( 92.51)\n",
            "Epoch: [78][120/391]\tTime  0.174 ( 0.174)\tLoss 1.0532e+00 (1.0006e+00)\tAcc@1  72.66 ( 71.35)\tAcc@5  90.62 ( 92.43)\n",
            "Epoch: [78][150/391]\tTime  0.171 ( 0.174)\tLoss 8.4339e-01 (1.0048e+00)\tAcc@1  75.78 ( 71.30)\tAcc@5  94.53 ( 92.39)\n",
            "Epoch: [78][180/391]\tTime  0.173 ( 0.173)\tLoss 9.8286e-01 (1.0129e+00)\tAcc@1  71.09 ( 71.08)\tAcc@5  94.53 ( 92.35)\n",
            "Epoch: [78][210/391]\tTime  0.174 ( 0.173)\tLoss 9.2218e-01 (1.0141e+00)\tAcc@1  71.09 ( 71.07)\tAcc@5  94.53 ( 92.35)\n",
            "Epoch: [78][240/391]\tTime  0.172 ( 0.173)\tLoss 1.1588e+00 (1.0135e+00)\tAcc@1  64.06 ( 71.08)\tAcc@5  96.09 ( 92.38)\n",
            "Epoch: [78][270/391]\tTime  0.171 ( 0.173)\tLoss 1.2862e+00 (1.0205e+00)\tAcc@1  67.97 ( 70.89)\tAcc@5  89.06 ( 92.26)\n",
            "Epoch: [78][300/391]\tTime  0.174 ( 0.173)\tLoss 1.0055e+00 (1.0197e+00)\tAcc@1  70.31 ( 70.93)\tAcc@5  92.19 ( 92.21)\n",
            "Epoch: [78][330/391]\tTime  0.174 ( 0.173)\tLoss 1.0105e+00 (1.0261e+00)\tAcc@1  72.66 ( 70.75)\tAcc@5  92.19 ( 92.14)\n",
            "Epoch: [78][360/391]\tTime  0.173 ( 0.173)\tLoss 1.0253e+00 (1.0257e+00)\tAcc@1  68.75 ( 70.74)\tAcc@5  96.09 ( 92.15)\n",
            "Epoch: [78][390/391]\tTime  0.154 ( 0.173)\tLoss 1.0402e+00 (1.0260e+00)\tAcc@1  70.00 ( 70.72)\tAcc@5  91.25 ( 92.20)\n",
            "==> Train Accuracy: Acc@1 70.722 || Acc@5 92.198\n",
            "==> Test Accuracy:  Acc@1 68.770 || Acc@5 92.040\n",
            "==> 72.03 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 79, lr: 0.020000000000000004 -----\n",
            "Epoch: [79][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.0410e+00 (1.0410e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [79][ 30/391]\tTime  0.175 ( 0.176)\tLoss 8.3031e-01 (9.5883e-01)\tAcc@1  78.91 ( 73.51)\tAcc@5  94.53 ( 93.42)\n",
            "Epoch: [79][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.0868e+00 (9.5559e-01)\tAcc@1  68.75 ( 73.34)\tAcc@5  89.84 ( 93.38)\n",
            "Epoch: [79][ 90/391]\tTime  0.173 ( 0.174)\tLoss 1.1349e+00 (9.6605e-01)\tAcc@1  71.88 ( 72.80)\tAcc@5  91.41 ( 93.17)\n",
            "Epoch: [79][120/391]\tTime  0.174 ( 0.174)\tLoss 1.1408e+00 (9.8504e-01)\tAcc@1  66.41 ( 72.11)\tAcc@5  89.06 ( 92.88)\n",
            "Epoch: [79][150/391]\tTime  0.171 ( 0.174)\tLoss 1.0873e+00 (9.8696e-01)\tAcc@1  67.19 ( 71.89)\tAcc@5  92.19 ( 92.87)\n",
            "Epoch: [79][180/391]\tTime  0.172 ( 0.174)\tLoss 8.4327e-01 (9.9565e-01)\tAcc@1  77.34 ( 71.58)\tAcc@5  94.53 ( 92.77)\n",
            "Epoch: [79][210/391]\tTime  0.172 ( 0.173)\tLoss 8.6026e-01 (9.9562e-01)\tAcc@1  73.44 ( 71.55)\tAcc@5  92.19 ( 92.70)\n",
            "Epoch: [79][240/391]\tTime  0.174 ( 0.173)\tLoss 9.2044e-01 (9.9949e-01)\tAcc@1  71.88 ( 71.37)\tAcc@5  94.53 ( 92.63)\n",
            "Epoch: [79][270/391]\tTime  0.173 ( 0.173)\tLoss 8.4513e-01 (1.0043e+00)\tAcc@1  78.12 ( 71.32)\tAcc@5  94.53 ( 92.58)\n",
            "Epoch: [79][300/391]\tTime  0.172 ( 0.173)\tLoss 1.0668e+00 (1.0118e+00)\tAcc@1  74.22 ( 71.11)\tAcc@5  89.84 ( 92.46)\n",
            "Epoch: [79][330/391]\tTime  0.169 ( 0.173)\tLoss 1.0666e+00 (1.0134e+00)\tAcc@1  67.19 ( 71.08)\tAcc@5  92.19 ( 92.44)\n",
            "Epoch: [79][360/391]\tTime  0.172 ( 0.173)\tLoss 8.7607e-01 (1.0162e+00)\tAcc@1  75.00 ( 70.98)\tAcc@5  93.75 ( 92.41)\n",
            "Epoch: [79][390/391]\tTime  0.155 ( 0.173)\tLoss 1.2580e+00 (1.0182e+00)\tAcc@1  61.25 ( 70.93)\tAcc@5  91.25 ( 92.41)\n",
            "==> Train Accuracy: Acc@1 70.926 || Acc@5 92.410\n",
            "==> Test Accuracy:  Acc@1 70.320 || Acc@5 91.780\n",
            "==> 72.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 80, lr: 0.020000000000000004 -----\n",
            "Epoch: [80][  0/391]\tTime  0.265 ( 0.265)\tLoss 8.1173e-01 (8.1173e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [80][ 30/391]\tTime  0.169 ( 0.176)\tLoss 9.3209e-01 (9.9481e-01)\tAcc@1  74.22 ( 71.37)\tAcc@5  89.84 ( 92.31)\n",
            "Epoch: [80][ 60/391]\tTime  0.174 ( 0.175)\tLoss 9.4646e-01 (9.8801e-01)\tAcc@1  71.09 ( 71.90)\tAcc@5  90.62 ( 92.38)\n",
            "Epoch: [80][ 90/391]\tTime  0.168 ( 0.174)\tLoss 1.2003e+00 (9.8120e-01)\tAcc@1  64.06 ( 71.95)\tAcc@5  93.75 ( 92.60)\n",
            "Epoch: [80][120/391]\tTime  0.174 ( 0.174)\tLoss 1.1441e+00 (9.7498e-01)\tAcc@1  64.84 ( 72.17)\tAcc@5  92.97 ( 92.76)\n",
            "Epoch: [80][150/391]\tTime  0.174 ( 0.174)\tLoss 1.2608e+00 (9.8355e-01)\tAcc@1  66.41 ( 71.95)\tAcc@5  86.72 ( 92.62)\n",
            "Epoch: [80][180/391]\tTime  0.175 ( 0.174)\tLoss 1.3118e+00 (9.9133e-01)\tAcc@1  60.16 ( 71.75)\tAcc@5  89.06 ( 92.53)\n",
            "Epoch: [80][210/391]\tTime  0.175 ( 0.174)\tLoss 1.0292e+00 (9.9470e-01)\tAcc@1  71.88 ( 71.76)\tAcc@5  94.53 ( 92.52)\n",
            "Epoch: [80][240/391]\tTime  0.173 ( 0.174)\tLoss 1.0737e+00 (9.9717e-01)\tAcc@1  71.09 ( 71.62)\tAcc@5  92.97 ( 92.54)\n",
            "Epoch: [80][270/391]\tTime  0.174 ( 0.174)\tLoss 9.0691e-01 (1.0018e+00)\tAcc@1  72.66 ( 71.39)\tAcc@5  91.41 ( 92.51)\n",
            "Epoch: [80][300/391]\tTime  0.175 ( 0.174)\tLoss 1.0884e+00 (1.0012e+00)\tAcc@1  69.53 ( 71.38)\tAcc@5  92.97 ( 92.52)\n",
            "Epoch: [80][330/391]\tTime  0.173 ( 0.173)\tLoss 1.0292e+00 (1.0062e+00)\tAcc@1  70.31 ( 71.23)\tAcc@5  93.75 ( 92.52)\n",
            "Epoch: [80][360/391]\tTime  0.175 ( 0.173)\tLoss 1.1015e+00 (1.0123e+00)\tAcc@1  64.84 ( 71.03)\tAcc@5  92.19 ( 92.45)\n",
            "Epoch: [80][390/391]\tTime  0.157 ( 0.173)\tLoss 1.1201e+00 (1.0154e+00)\tAcc@1  67.50 ( 70.98)\tAcc@5  90.00 ( 92.44)\n",
            "==> Train Accuracy: Acc@1 70.982 || Acc@5 92.436\n",
            "==> Test Accuracy:  Acc@1 69.680 || Acc@5 91.470\n",
            "==> 72.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 81, lr: 0.020000000000000004 -----\n",
            "Epoch: [81][  0/391]\tTime  0.282 ( 0.282)\tLoss 9.3951e-01 (9.3951e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [81][ 30/391]\tTime  0.173 ( 0.177)\tLoss 9.7022e-01 (1.0147e+00)\tAcc@1  73.44 ( 70.99)\tAcc@5  92.97 ( 92.46)\n",
            "Epoch: [81][ 60/391]\tTime  0.168 ( 0.175)\tLoss 9.3091e-01 (1.0091e+00)\tAcc@1  73.44 ( 71.32)\tAcc@5  95.31 ( 92.56)\n",
            "Epoch: [81][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.0055e+00 (1.0059e+00)\tAcc@1  71.09 ( 71.44)\tAcc@5  92.19 ( 92.38)\n",
            "Epoch: [81][120/391]\tTime  0.172 ( 0.174)\tLoss 8.2082e-01 (1.0043e+00)\tAcc@1  75.78 ( 71.56)\tAcc@5  93.75 ( 92.43)\n",
            "Epoch: [81][150/391]\tTime  0.177 ( 0.174)\tLoss 1.0674e+00 (1.0004e+00)\tAcc@1  67.19 ( 71.51)\tAcc@5  95.31 ( 92.57)\n",
            "Epoch: [81][180/391]\tTime  0.174 ( 0.174)\tLoss 1.0462e+00 (9.9523e-01)\tAcc@1  73.44 ( 71.59)\tAcc@5  92.19 ( 92.70)\n",
            "Epoch: [81][210/391]\tTime  0.172 ( 0.174)\tLoss 1.1972e+00 (9.9456e-01)\tAcc@1  64.84 ( 71.61)\tAcc@5  91.41 ( 92.73)\n",
            "Epoch: [81][240/391]\tTime  0.175 ( 0.174)\tLoss 1.0305e+00 (9.9819e-01)\tAcc@1  62.50 ( 71.48)\tAcc@5  92.97 ( 92.73)\n",
            "Epoch: [81][270/391]\tTime  0.176 ( 0.174)\tLoss 8.8435e-01 (1.0039e+00)\tAcc@1  74.22 ( 71.28)\tAcc@5  93.75 ( 92.66)\n",
            "Epoch: [81][300/391]\tTime  0.171 ( 0.174)\tLoss 1.1178e+00 (1.0070e+00)\tAcc@1  65.62 ( 71.15)\tAcc@5  89.06 ( 92.60)\n",
            "Epoch: [81][330/391]\tTime  0.175 ( 0.174)\tLoss 8.7925e-01 (1.0103e+00)\tAcc@1  78.91 ( 71.04)\tAcc@5  94.53 ( 92.55)\n",
            "Epoch: [81][360/391]\tTime  0.175 ( 0.174)\tLoss 1.0573e+00 (1.0113e+00)\tAcc@1  68.75 ( 71.03)\tAcc@5  91.41 ( 92.54)\n",
            "Epoch: [81][390/391]\tTime  0.154 ( 0.174)\tLoss 1.2454e+00 (1.0184e+00)\tAcc@1  62.50 ( 70.87)\tAcc@5  88.75 ( 92.42)\n",
            "==> Train Accuracy: Acc@1 70.868 || Acc@5 92.418\n",
            "==> Test Accuracy:  Acc@1 69.840 || Acc@5 92.170\n",
            "==> 72.27 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 82, lr: 0.020000000000000004 -----\n",
            "Epoch: [82][  0/391]\tTime  0.270 ( 0.270)\tLoss 9.3400e-01 (9.3400e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [82][ 30/391]\tTime  0.174 ( 0.177)\tLoss 9.9150e-01 (9.6951e-01)\tAcc@1  75.00 ( 73.31)\tAcc@5  90.62 ( 93.35)\n",
            "Epoch: [82][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.0247e+00 (9.8053e-01)\tAcc@1  70.31 ( 72.55)\tAcc@5  92.19 ( 92.98)\n",
            "Epoch: [82][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.1673e+00 (9.8009e-01)\tAcc@1  66.41 ( 72.45)\tAcc@5  92.19 ( 92.95)\n",
            "Epoch: [82][120/391]\tTime  0.174 ( 0.174)\tLoss 1.0812e+00 (9.9192e-01)\tAcc@1  71.88 ( 71.93)\tAcc@5  88.28 ( 92.81)\n",
            "Epoch: [82][150/391]\tTime  0.174 ( 0.174)\tLoss 9.6653e-01 (9.8887e-01)\tAcc@1  70.31 ( 71.84)\tAcc@5  95.31 ( 92.81)\n",
            "Epoch: [82][180/391]\tTime  0.173 ( 0.174)\tLoss 9.0841e-01 (9.9113e-01)\tAcc@1  71.09 ( 71.74)\tAcc@5  93.75 ( 92.80)\n",
            "Epoch: [82][210/391]\tTime  0.175 ( 0.174)\tLoss 7.7369e-01 (9.9353e-01)\tAcc@1  78.91 ( 71.69)\tAcc@5  94.53 ( 92.75)\n",
            "Epoch: [82][240/391]\tTime  0.173 ( 0.174)\tLoss 1.1436e+00 (9.9808e-01)\tAcc@1  65.62 ( 71.53)\tAcc@5  92.19 ( 92.75)\n",
            "Epoch: [82][270/391]\tTime  0.172 ( 0.174)\tLoss 1.0868e+00 (1.0015e+00)\tAcc@1  66.41 ( 71.37)\tAcc@5  92.97 ( 92.68)\n",
            "Epoch: [82][300/391]\tTime  0.175 ( 0.174)\tLoss 1.0848e+00 (1.0032e+00)\tAcc@1  66.41 ( 71.33)\tAcc@5  94.53 ( 92.66)\n",
            "Epoch: [82][330/391]\tTime  0.174 ( 0.174)\tLoss 1.0161e+00 (1.0008e+00)\tAcc@1  71.09 ( 71.37)\tAcc@5  93.75 ( 92.71)\n",
            "Epoch: [82][360/391]\tTime  0.175 ( 0.174)\tLoss 9.2807e-01 (1.0008e+00)\tAcc@1  73.44 ( 71.28)\tAcc@5  93.75 ( 92.75)\n",
            "Epoch: [82][390/391]\tTime  0.156 ( 0.174)\tLoss 9.2262e-01 (1.0042e+00)\tAcc@1  71.25 ( 71.18)\tAcc@5  95.00 ( 92.71)\n",
            "==> Train Accuracy: Acc@1 71.182 || Acc@5 92.708\n",
            "==> Test Accuracy:  Acc@1 69.360 || Acc@5 91.940\n",
            "==> 72.38 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 83, lr: 0.020000000000000004 -----\n",
            "Epoch: [83][  0/391]\tTime  0.274 ( 0.274)\tLoss 9.2854e-01 (9.2854e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [83][ 30/391]\tTime  0.173 ( 0.177)\tLoss 7.7024e-01 (9.2745e-01)\tAcc@1  78.12 ( 73.79)\tAcc@5  96.88 ( 93.67)\n",
            "Epoch: [83][ 60/391]\tTime  0.173 ( 0.175)\tLoss 8.3989e-01 (9.4370e-01)\tAcc@1  79.69 ( 73.30)\tAcc@5  95.31 ( 93.53)\n",
            "Epoch: [83][ 90/391]\tTime  0.173 ( 0.175)\tLoss 9.8963e-01 (9.4831e-01)\tAcc@1  74.22 ( 73.14)\tAcc@5  90.62 ( 93.33)\n",
            "Epoch: [83][120/391]\tTime  0.175 ( 0.174)\tLoss 9.2765e-01 (9.4710e-01)\tAcc@1  71.88 ( 72.86)\tAcc@5  94.53 ( 93.37)\n",
            "Epoch: [83][150/391]\tTime  0.173 ( 0.174)\tLoss 8.5071e-01 (9.4720e-01)\tAcc@1  77.34 ( 72.75)\tAcc@5  96.88 ( 93.35)\n",
            "Epoch: [83][180/391]\tTime  0.173 ( 0.174)\tLoss 1.0902e+00 (9.4945e-01)\tAcc@1  66.41 ( 72.72)\tAcc@5  95.31 ( 93.24)\n",
            "Epoch: [83][210/391]\tTime  0.175 ( 0.174)\tLoss 1.1088e+00 (9.5567e-01)\tAcc@1  67.97 ( 72.51)\tAcc@5  89.84 ( 93.14)\n",
            "Epoch: [83][240/391]\tTime  0.174 ( 0.174)\tLoss 1.0280e+00 (9.6799e-01)\tAcc@1  71.09 ( 72.23)\tAcc@5  92.19 ( 92.97)\n",
            "Epoch: [83][270/391]\tTime  0.174 ( 0.174)\tLoss 9.0968e-01 (9.7093e-01)\tAcc@1  68.75 ( 72.08)\tAcc@5  97.66 ( 93.01)\n",
            "Epoch: [83][300/391]\tTime  0.173 ( 0.174)\tLoss 1.2239e+00 (9.7266e-01)\tAcc@1  72.66 ( 72.05)\tAcc@5  90.62 ( 93.00)\n",
            "Epoch: [83][330/391]\tTime  0.178 ( 0.174)\tLoss 1.1507e+00 (9.7873e-01)\tAcc@1  65.62 ( 71.96)\tAcc@5  88.28 ( 92.86)\n",
            "Epoch: [83][360/391]\tTime  0.173 ( 0.174)\tLoss 1.1349e+00 (9.8364e-01)\tAcc@1  70.31 ( 71.89)\tAcc@5  89.06 ( 92.78)\n",
            "Epoch: [83][390/391]\tTime  0.156 ( 0.174)\tLoss 1.0368e+00 (9.8810e-01)\tAcc@1  71.25 ( 71.73)\tAcc@5  88.75 ( 92.70)\n",
            "==> Train Accuracy: Acc@1 71.730 || Acc@5 92.702\n",
            "==> Test Accuracy:  Acc@1 69.120 || Acc@5 91.700\n",
            "==> 72.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 84, lr: 0.020000000000000004 -----\n",
            "Epoch: [84][  0/391]\tTime  0.275 ( 0.275)\tLoss 8.0092e-01 (8.0092e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [84][ 30/391]\tTime  0.174 ( 0.177)\tLoss 7.8210e-01 (9.0626e-01)\tAcc@1  77.34 ( 74.32)\tAcc@5  94.53 ( 93.55)\n",
            "Epoch: [84][ 60/391]\tTime  0.173 ( 0.175)\tLoss 8.7618e-01 (9.3635e-01)\tAcc@1  72.66 ( 73.00)\tAcc@5  92.97 ( 93.34)\n",
            "Epoch: [84][ 90/391]\tTime  0.172 ( 0.175)\tLoss 9.6132e-01 (9.3804e-01)\tAcc@1  71.88 ( 72.73)\tAcc@5  92.97 ( 93.46)\n",
            "Epoch: [84][120/391]\tTime  0.174 ( 0.174)\tLoss 9.8307e-01 (9.4452e-01)\tAcc@1  74.22 ( 72.68)\tAcc@5  92.97 ( 93.43)\n",
            "Epoch: [84][150/391]\tTime  0.173 ( 0.174)\tLoss 1.0828e+00 (9.5335e-01)\tAcc@1  70.31 ( 72.41)\tAcc@5  91.41 ( 93.29)\n",
            "Epoch: [84][180/391]\tTime  0.173 ( 0.174)\tLoss 8.2112e-01 (9.6216e-01)\tAcc@1  75.00 ( 72.19)\tAcc@5  96.88 ( 93.08)\n",
            "Epoch: [84][210/391]\tTime  0.175 ( 0.174)\tLoss 1.0665e+00 (9.6636e-01)\tAcc@1  71.09 ( 72.06)\tAcc@5  90.62 ( 92.99)\n",
            "Epoch: [84][240/391]\tTime  0.174 ( 0.174)\tLoss 9.9025e-01 (9.6692e-01)\tAcc@1  71.09 ( 71.99)\tAcc@5  91.41 ( 93.05)\n",
            "Epoch: [84][270/391]\tTime  0.174 ( 0.174)\tLoss 9.4274e-01 (9.6977e-01)\tAcc@1  70.31 ( 71.99)\tAcc@5  91.41 ( 93.02)\n",
            "Epoch: [84][300/391]\tTime  0.172 ( 0.174)\tLoss 1.1441e+00 (9.7183e-01)\tAcc@1  67.19 ( 71.89)\tAcc@5  92.19 ( 93.03)\n",
            "Epoch: [84][330/391]\tTime  0.172 ( 0.174)\tLoss 1.1430e+00 (9.7813e-01)\tAcc@1  67.19 ( 71.64)\tAcc@5  89.06 ( 92.98)\n",
            "Epoch: [84][360/391]\tTime  0.172 ( 0.174)\tLoss 1.2052e+00 (9.8077e-01)\tAcc@1  67.97 ( 71.63)\tAcc@5  88.28 ( 92.96)\n",
            "Epoch: [84][390/391]\tTime  0.158 ( 0.174)\tLoss 1.2371e+00 (9.8741e-01)\tAcc@1  60.00 ( 71.46)\tAcc@5  90.00 ( 92.85)\n",
            "==> Train Accuracy: Acc@1 71.464 || Acc@5 92.850\n",
            "==> Test Accuracy:  Acc@1 70.010 || Acc@5 91.700\n",
            "==> 72.19 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 85, lr: 0.020000000000000004 -----\n",
            "Epoch: [85][  0/391]\tTime  0.257 ( 0.257)\tLoss 7.6895e-01 (7.6895e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [85][ 30/391]\tTime  0.175 ( 0.176)\tLoss 9.0563e-01 (9.6889e-01)\tAcc@1  73.44 ( 72.25)\tAcc@5  92.97 ( 92.64)\n",
            "Epoch: [85][ 60/391]\tTime  0.171 ( 0.174)\tLoss 9.2617e-01 (9.6056e-01)\tAcc@1  71.88 ( 72.43)\tAcc@5  94.53 ( 92.92)\n",
            "Epoch: [85][ 90/391]\tTime  0.173 ( 0.174)\tLoss 1.0017e+00 (9.5943e-01)\tAcc@1  71.88 ( 72.50)\tAcc@5  92.19 ( 93.04)\n",
            "Epoch: [85][120/391]\tTime  0.176 ( 0.174)\tLoss 9.3840e-01 (9.5988e-01)\tAcc@1  75.00 ( 72.69)\tAcc@5  93.75 ( 93.10)\n",
            "Epoch: [85][150/391]\tTime  0.173 ( 0.174)\tLoss 9.3276e-01 (9.6306e-01)\tAcc@1  71.09 ( 72.50)\tAcc@5  94.53 ( 93.03)\n",
            "Epoch: [85][180/391]\tTime  0.173 ( 0.174)\tLoss 9.8804e-01 (9.6456e-01)\tAcc@1  69.53 ( 72.47)\tAcc@5  92.97 ( 93.03)\n",
            "Epoch: [85][210/391]\tTime  0.174 ( 0.174)\tLoss 9.6069e-01 (9.7483e-01)\tAcc@1  73.44 ( 72.17)\tAcc@5  92.97 ( 92.96)\n",
            "Epoch: [85][240/391]\tTime  0.173 ( 0.174)\tLoss 8.2590e-01 (9.7980e-01)\tAcc@1  75.78 ( 71.90)\tAcc@5  95.31 ( 92.99)\n",
            "Epoch: [85][270/391]\tTime  0.173 ( 0.174)\tLoss 8.2424e-01 (9.8149e-01)\tAcc@1  75.00 ( 71.98)\tAcc@5  93.75 ( 92.93)\n",
            "Epoch: [85][300/391]\tTime  0.174 ( 0.174)\tLoss 7.4497e-01 (9.7794e-01)\tAcc@1  76.56 ( 72.09)\tAcc@5  96.88 ( 92.96)\n",
            "Epoch: [85][330/391]\tTime  0.173 ( 0.174)\tLoss 1.2254e+00 (9.7813e-01)\tAcc@1  67.97 ( 72.10)\tAcc@5  92.97 ( 92.94)\n",
            "Epoch: [85][360/391]\tTime  0.172 ( 0.174)\tLoss 7.4858e-01 (9.8255e-01)\tAcc@1  75.78 ( 71.97)\tAcc@5  96.09 ( 92.90)\n",
            "Epoch: [85][390/391]\tTime  0.157 ( 0.174)\tLoss 9.2123e-01 (9.8686e-01)\tAcc@1  72.50 ( 71.82)\tAcc@5  93.75 ( 92.83)\n",
            "==> Train Accuracy: Acc@1 71.824 || Acc@5 92.834\n",
            "==> Test Accuracy:  Acc@1 67.920 || Acc@5 91.150\n",
            "==> 72.27 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 86, lr: 0.020000000000000004 -----\n",
            "Epoch: [86][  0/391]\tTime  0.271 ( 0.271)\tLoss 9.0584e-01 (9.0584e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [86][ 30/391]\tTime  0.173 ( 0.177)\tLoss 8.9103e-01 (9.5231e-01)\tAcc@1  71.09 ( 72.78)\tAcc@5  95.31 ( 93.50)\n",
            "Epoch: [86][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.1997e+00 (9.4933e-01)\tAcc@1  69.53 ( 72.73)\tAcc@5  88.28 ( 93.38)\n",
            "Epoch: [86][ 90/391]\tTime  0.175 ( 0.175)\tLoss 8.3965e-01 (9.2951e-01)\tAcc@1  77.34 ( 73.15)\tAcc@5  95.31 ( 93.65)\n",
            "Epoch: [86][120/391]\tTime  0.174 ( 0.175)\tLoss 8.7915e-01 (9.3704e-01)\tAcc@1  74.22 ( 73.01)\tAcc@5  96.88 ( 93.63)\n",
            "Epoch: [86][150/391]\tTime  0.173 ( 0.174)\tLoss 9.6737e-01 (9.4563e-01)\tAcc@1  72.66 ( 72.80)\tAcc@5  93.75 ( 93.40)\n",
            "Epoch: [86][180/391]\tTime  0.174 ( 0.174)\tLoss 8.2345e-01 (9.6034e-01)\tAcc@1  78.12 ( 72.50)\tAcc@5  96.88 ( 93.24)\n",
            "Epoch: [86][210/391]\tTime  0.173 ( 0.174)\tLoss 1.0228e+00 (9.6201e-01)\tAcc@1  69.53 ( 72.48)\tAcc@5  90.62 ( 93.19)\n",
            "Epoch: [86][240/391]\tTime  0.175 ( 0.174)\tLoss 9.2618e-01 (9.6687e-01)\tAcc@1  71.09 ( 72.34)\tAcc@5  92.97 ( 93.15)\n",
            "Epoch: [86][270/391]\tTime  0.175 ( 0.174)\tLoss 1.2392e+00 (9.7325e-01)\tAcc@1  65.62 ( 72.15)\tAcc@5  89.84 ( 93.08)\n",
            "Epoch: [86][300/391]\tTime  0.168 ( 0.174)\tLoss 1.0225e+00 (9.7280e-01)\tAcc@1  69.53 ( 72.19)\tAcc@5  91.41 ( 93.03)\n",
            "Epoch: [86][330/391]\tTime  0.176 ( 0.174)\tLoss 1.0289e+00 (9.7994e-01)\tAcc@1  72.66 ( 72.00)\tAcc@5  89.84 ( 92.95)\n",
            "Epoch: [86][360/391]\tTime  0.175 ( 0.174)\tLoss 1.0796e+00 (9.8521e-01)\tAcc@1  70.31 ( 71.87)\tAcc@5  91.41 ( 92.88)\n",
            "Epoch: [86][390/391]\tTime  0.153 ( 0.174)\tLoss 1.5654e+00 (9.9068e-01)\tAcc@1  60.00 ( 71.75)\tAcc@5  85.00 ( 92.80)\n",
            "==> Train Accuracy: Acc@1 71.746 || Acc@5 92.804\n",
            "==> Test Accuracy:  Acc@1 69.040 || Acc@5 91.840\n",
            "==> 72.36 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 87, lr: 0.020000000000000004 -----\n",
            "Epoch: [87][  0/391]\tTime  0.256 ( 0.256)\tLoss 6.2973e-01 (6.2973e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [87][ 30/391]\tTime  0.174 ( 0.176)\tLoss 8.8131e-01 (9.3512e-01)\tAcc@1  74.22 ( 73.49)\tAcc@5  94.53 ( 93.47)\n",
            "Epoch: [87][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.0024e+00 (9.5217e-01)\tAcc@1  75.00 ( 72.99)\tAcc@5  92.19 ( 93.26)\n",
            "Epoch: [87][ 90/391]\tTime  0.173 ( 0.174)\tLoss 9.6620e-01 (9.4515e-01)\tAcc@1  70.31 ( 72.98)\tAcc@5  90.62 ( 93.32)\n",
            "Epoch: [87][120/391]\tTime  0.171 ( 0.174)\tLoss 1.0438e+00 (9.4221e-01)\tAcc@1  75.78 ( 73.00)\tAcc@5  89.84 ( 93.30)\n",
            "Epoch: [87][150/391]\tTime  0.173 ( 0.174)\tLoss 9.5283e-01 (9.3989e-01)\tAcc@1  71.09 ( 73.08)\tAcc@5  95.31 ( 93.38)\n",
            "Epoch: [87][180/391]\tTime  0.173 ( 0.174)\tLoss 1.1390e+00 (9.4633e-01)\tAcc@1  65.62 ( 72.90)\tAcc@5  92.19 ( 93.32)\n",
            "Epoch: [87][210/391]\tTime  0.173 ( 0.174)\tLoss 1.0167e+00 (9.4824e-01)\tAcc@1  65.62 ( 72.76)\tAcc@5  92.19 ( 93.29)\n",
            "Epoch: [87][240/391]\tTime  0.173 ( 0.174)\tLoss 8.0719e-01 (9.5572e-01)\tAcc@1  81.25 ( 72.62)\tAcc@5  95.31 ( 93.22)\n",
            "Epoch: [87][270/391]\tTime  0.174 ( 0.174)\tLoss 1.0047e+00 (9.6039e-01)\tAcc@1  67.97 ( 72.47)\tAcc@5  90.62 ( 93.14)\n",
            "Epoch: [87][300/391]\tTime  0.174 ( 0.174)\tLoss 8.6109e-01 (9.6460e-01)\tAcc@1  77.34 ( 72.30)\tAcc@5  95.31 ( 93.11)\n",
            "Epoch: [87][330/391]\tTime  0.174 ( 0.173)\tLoss 1.0566e+00 (9.7083e-01)\tAcc@1  71.88 ( 72.15)\tAcc@5  92.19 ( 93.01)\n",
            "Epoch: [87][360/391]\tTime  0.173 ( 0.173)\tLoss 9.9727e-01 (9.7293e-01)\tAcc@1  75.78 ( 72.10)\tAcc@5  91.41 ( 93.00)\n",
            "Epoch: [87][390/391]\tTime  0.155 ( 0.173)\tLoss 1.1609e+00 (9.7922e-01)\tAcc@1  66.25 ( 71.91)\tAcc@5  88.75 ( 92.93)\n",
            "==> Train Accuracy: Acc@1 71.910 || Acc@5 92.930\n",
            "==> Test Accuracy:  Acc@1 69.040 || Acc@5 91.120\n",
            "==> 72.10 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 88, lr: 0.020000000000000004 -----\n",
            "Epoch: [88][  0/391]\tTime  0.274 ( 0.274)\tLoss 8.5296e-01 (8.5296e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [88][ 30/391]\tTime  0.175 ( 0.176)\tLoss 9.6045e-01 (9.0269e-01)\tAcc@1  71.09 ( 73.79)\tAcc@5  91.41 ( 93.88)\n",
            "Epoch: [88][ 60/391]\tTime  0.171 ( 0.174)\tLoss 1.0428e+00 (9.2463e-01)\tAcc@1  71.09 ( 74.00)\tAcc@5  93.75 ( 93.48)\n",
            "Epoch: [88][ 90/391]\tTime  0.171 ( 0.174)\tLoss 8.8515e-01 (9.3444e-01)\tAcc@1  73.44 ( 73.56)\tAcc@5  92.19 ( 93.29)\n",
            "Epoch: [88][120/391]\tTime  0.170 ( 0.174)\tLoss 1.0269e+00 (9.4170e-01)\tAcc@1  71.88 ( 73.31)\tAcc@5  91.41 ( 93.30)\n",
            "Epoch: [88][150/391]\tTime  0.176 ( 0.174)\tLoss 8.7995e-01 (9.4189e-01)\tAcc@1  75.00 ( 73.33)\tAcc@5  96.09 ( 93.28)\n",
            "Epoch: [88][180/391]\tTime  0.173 ( 0.173)\tLoss 8.8325e-01 (9.4312e-01)\tAcc@1  74.22 ( 73.15)\tAcc@5  93.75 ( 93.28)\n",
            "Epoch: [88][210/391]\tTime  0.173 ( 0.173)\tLoss 9.9926e-01 (9.4503e-01)\tAcc@1  75.00 ( 73.13)\tAcc@5  90.62 ( 93.21)\n",
            "Epoch: [88][240/391]\tTime  0.173 ( 0.173)\tLoss 1.1397e+00 (9.5330e-01)\tAcc@1  64.84 ( 72.87)\tAcc@5  92.97 ( 93.06)\n",
            "Epoch: [88][270/391]\tTime  0.172 ( 0.173)\tLoss 9.7296e-01 (9.5975e-01)\tAcc@1  71.09 ( 72.64)\tAcc@5  91.41 ( 92.91)\n",
            "Epoch: [88][300/391]\tTime  0.173 ( 0.173)\tLoss 9.3025e-01 (9.6285e-01)\tAcc@1  71.88 ( 72.52)\tAcc@5  92.97 ( 92.90)\n",
            "Epoch: [88][330/391]\tTime  0.175 ( 0.173)\tLoss 9.8861e-01 (9.6585e-01)\tAcc@1  70.31 ( 72.43)\tAcc@5  92.97 ( 92.86)\n",
            "Epoch: [88][360/391]\tTime  0.172 ( 0.173)\tLoss 1.0099e+00 (9.6786e-01)\tAcc@1  74.22 ( 72.33)\tAcc@5  94.53 ( 92.83)\n",
            "Epoch: [88][390/391]\tTime  0.156 ( 0.173)\tLoss 1.2126e+00 (9.7212e-01)\tAcc@1  65.00 ( 72.24)\tAcc@5  88.75 ( 92.80)\n",
            "==> Train Accuracy: Acc@1 72.240 || Acc@5 92.796\n",
            "==> Test Accuracy:  Acc@1 69.000 || Acc@5 90.970\n",
            "==> 72.06 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 89, lr: 0.020000000000000004 -----\n",
            "Epoch: [89][  0/391]\tTime  0.266 ( 0.266)\tLoss 8.0440e-01 (8.0440e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [89][ 30/391]\tTime  0.173 ( 0.176)\tLoss 7.9116e-01 (8.9991e-01)\tAcc@1  76.56 ( 74.40)\tAcc@5  95.31 ( 93.55)\n",
            "Epoch: [89][ 60/391]\tTime  0.172 ( 0.174)\tLoss 9.8692e-01 (8.9118e-01)\tAcc@1  70.31 ( 74.32)\tAcc@5  94.53 ( 93.92)\n",
            "Epoch: [89][ 90/391]\tTime  0.173 ( 0.174)\tLoss 1.0541e+00 (9.2046e-01)\tAcc@1  68.75 ( 73.64)\tAcc@5  92.19 ( 93.53)\n",
            "Epoch: [89][120/391]\tTime  0.174 ( 0.174)\tLoss 8.6863e-01 (9.2150e-01)\tAcc@1  72.66 ( 73.62)\tAcc@5  93.75 ( 93.62)\n",
            "Epoch: [89][150/391]\tTime  0.172 ( 0.174)\tLoss 1.1423e+00 (9.4116e-01)\tAcc@1  64.84 ( 73.16)\tAcc@5  94.53 ( 93.47)\n",
            "Epoch: [89][180/391]\tTime  0.172 ( 0.173)\tLoss 1.0239e+00 (9.5064e-01)\tAcc@1  67.97 ( 73.00)\tAcc@5  95.31 ( 93.35)\n",
            "Epoch: [89][210/391]\tTime  0.167 ( 0.173)\tLoss 9.5533e-01 (9.5248e-01)\tAcc@1  75.00 ( 72.93)\tAcc@5  95.31 ( 93.29)\n",
            "Epoch: [89][240/391]\tTime  0.174 ( 0.173)\tLoss 8.4821e-01 (9.5315e-01)\tAcc@1  76.56 ( 72.90)\tAcc@5  93.75 ( 93.28)\n",
            "Epoch: [89][270/391]\tTime  0.174 ( 0.173)\tLoss 1.2596e+00 (9.5564e-01)\tAcc@1  64.84 ( 72.80)\tAcc@5  92.19 ( 93.26)\n",
            "Epoch: [89][300/391]\tTime  0.174 ( 0.173)\tLoss 8.6764e-01 (9.5886e-01)\tAcc@1  73.44 ( 72.71)\tAcc@5  95.31 ( 93.23)\n",
            "Epoch: [89][330/391]\tTime  0.174 ( 0.173)\tLoss 1.0131e+00 (9.6147e-01)\tAcc@1  75.00 ( 72.63)\tAcc@5  92.97 ( 93.19)\n",
            "Epoch: [89][360/391]\tTime  0.173 ( 0.173)\tLoss 1.0486e+00 (9.6364e-01)\tAcc@1  69.53 ( 72.55)\tAcc@5  94.53 ( 93.17)\n",
            "Epoch: [89][390/391]\tTime  0.153 ( 0.173)\tLoss 1.0463e+00 (9.6573e-01)\tAcc@1  70.00 ( 72.44)\tAcc@5  87.50 ( 93.14)\n",
            "==> Train Accuracy: Acc@1 72.438 || Acc@5 93.144\n",
            "==> Test Accuracy:  Acc@1 69.000 || Acc@5 91.680\n",
            "==> 72.06 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 90, lr: 0.004000000000000001 -----\n",
            "Epoch: [90][  0/391]\tTime  0.280 ( 0.280)\tLoss 6.6395e-01 (6.6395e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [90][ 30/391]\tTime  0.176 ( 0.176)\tLoss 8.3932e-01 (8.4716e-01)\tAcc@1  77.34 ( 75.55)\tAcc@5  95.31 ( 94.71)\n",
            "Epoch: [90][ 60/391]\tTime  0.172 ( 0.175)\tLoss 6.6966e-01 (8.1053e-01)\tAcc@1  82.81 ( 77.05)\tAcc@5  96.09 ( 94.66)\n",
            "Epoch: [90][ 90/391]\tTime  0.172 ( 0.174)\tLoss 8.2645e-01 (7.9937e-01)\tAcc@1  74.22 ( 77.37)\tAcc@5  91.41 ( 94.81)\n",
            "Epoch: [90][120/391]\tTime  0.173 ( 0.174)\tLoss 8.6496e-01 (7.8604e-01)\tAcc@1  74.22 ( 77.76)\tAcc@5  92.97 ( 94.89)\n",
            "Epoch: [90][150/391]\tTime  0.171 ( 0.174)\tLoss 7.4256e-01 (7.7177e-01)\tAcc@1  79.69 ( 78.18)\tAcc@5  94.53 ( 94.98)\n",
            "Epoch: [90][180/391]\tTime  0.174 ( 0.174)\tLoss 6.1501e-01 (7.6536e-01)\tAcc@1  82.81 ( 78.33)\tAcc@5  96.88 ( 95.04)\n",
            "Epoch: [90][210/391]\tTime  0.173 ( 0.174)\tLoss 8.2305e-01 (7.5746e-01)\tAcc@1  75.78 ( 78.55)\tAcc@5  94.53 ( 95.18)\n",
            "Epoch: [90][240/391]\tTime  0.174 ( 0.173)\tLoss 7.3270e-01 (7.4791e-01)\tAcc@1  80.47 ( 78.80)\tAcc@5  96.09 ( 95.22)\n",
            "Epoch: [90][270/391]\tTime  0.174 ( 0.173)\tLoss 5.6496e-01 (7.3892e-01)\tAcc@1  85.94 ( 79.06)\tAcc@5  95.31 ( 95.33)\n",
            "Epoch: [90][300/391]\tTime  0.173 ( 0.173)\tLoss 6.1996e-01 (7.3146e-01)\tAcc@1  81.25 ( 79.24)\tAcc@5  95.31 ( 95.38)\n",
            "Epoch: [90][330/391]\tTime  0.171 ( 0.173)\tLoss 7.0998e-01 (7.3013e-01)\tAcc@1  81.25 ( 79.31)\tAcc@5  94.53 ( 95.35)\n",
            "Epoch: [90][360/391]\tTime  0.173 ( 0.173)\tLoss 5.7541e-01 (7.2739e-01)\tAcc@1  82.03 ( 79.38)\tAcc@5  99.22 ( 95.38)\n",
            "Epoch: [90][390/391]\tTime  0.155 ( 0.173)\tLoss 6.8108e-01 (7.2519e-01)\tAcc@1  78.75 ( 79.37)\tAcc@5  95.00 ( 95.40)\n",
            "==> Train Accuracy: Acc@1 79.366 || Acc@5 95.404\n",
            "==> Test Accuracy:  Acc@1 76.070 || Acc@5 94.230\n",
            "==> 72.06 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 91, lr: 0.004000000000000001 -----\n",
            "Epoch: [91][  0/391]\tTime  0.268 ( 0.268)\tLoss 5.6381e-01 (5.6381e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [91][ 30/391]\tTime  0.176 ( 0.176)\tLoss 5.8594e-01 (6.3396e-01)\tAcc@1  85.94 ( 81.63)\tAcc@5  97.66 ( 96.50)\n",
            "Epoch: [91][ 60/391]\tTime  0.172 ( 0.174)\tLoss 7.6739e-01 (6.2500e-01)\tAcc@1  75.78 ( 82.15)\tAcc@5  96.88 ( 96.55)\n",
            "Epoch: [91][ 90/391]\tTime  0.172 ( 0.174)\tLoss 7.8424e-01 (6.3497e-01)\tAcc@1  77.34 ( 81.94)\tAcc@5  95.31 ( 96.39)\n",
            "Epoch: [91][120/391]\tTime  0.176 ( 0.174)\tLoss 8.0627e-01 (6.4113e-01)\tAcc@1  79.69 ( 81.70)\tAcc@5  92.19 ( 96.16)\n",
            "Epoch: [91][150/391]\tTime  0.170 ( 0.174)\tLoss 6.1640e-01 (6.3633e-01)\tAcc@1  81.25 ( 81.93)\tAcc@5  95.31 ( 96.14)\n",
            "Epoch: [91][180/391]\tTime  0.173 ( 0.174)\tLoss 7.5735e-01 (6.3606e-01)\tAcc@1  75.78 ( 81.88)\tAcc@5  94.53 ( 96.19)\n",
            "Epoch: [91][210/391]\tTime  0.174 ( 0.174)\tLoss 5.0218e-01 (6.3178e-01)\tAcc@1  87.50 ( 81.99)\tAcc@5  98.44 ( 96.21)\n",
            "Epoch: [91][240/391]\tTime  0.174 ( 0.174)\tLoss 6.3730e-01 (6.3428e-01)\tAcc@1  84.38 ( 81.87)\tAcc@5  94.53 ( 96.18)\n",
            "Epoch: [91][270/391]\tTime  0.181 ( 0.174)\tLoss 6.0493e-01 (6.3765e-01)\tAcc@1  82.81 ( 81.78)\tAcc@5  95.31 ( 96.13)\n",
            "Epoch: [91][300/391]\tTime  0.175 ( 0.174)\tLoss 7.9187e-01 (6.3655e-01)\tAcc@1  78.91 ( 81.83)\tAcc@5  92.97 ( 96.12)\n",
            "Epoch: [91][330/391]\tTime  0.174 ( 0.174)\tLoss 8.5619e-01 (6.3594e-01)\tAcc@1  78.12 ( 81.86)\tAcc@5  93.75 ( 96.15)\n",
            "Epoch: [91][360/391]\tTime  0.172 ( 0.174)\tLoss 5.0013e-01 (6.3769e-01)\tAcc@1  84.38 ( 81.84)\tAcc@5  99.22 ( 96.13)\n",
            "Epoch: [91][390/391]\tTime  0.157 ( 0.173)\tLoss 9.3055e-01 (6.4044e-01)\tAcc@1  76.25 ( 81.75)\tAcc@5  93.75 ( 96.09)\n",
            "==> Train Accuracy: Acc@1 81.750 || Acc@5 96.088\n",
            "==> Test Accuracy:  Acc@1 76.200 || Acc@5 94.330\n",
            "==> 72.18 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 92, lr: 0.004000000000000001 -----\n",
            "Epoch: [92][  0/391]\tTime  0.279 ( 0.279)\tLoss 6.4538e-01 (6.4538e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [92][ 30/391]\tTime  0.174 ( 0.177)\tLoss 6.1068e-01 (5.7553e-01)\tAcc@1  82.81 ( 83.52)\tAcc@5  96.09 ( 96.50)\n",
            "Epoch: [92][ 60/391]\tTime  0.174 ( 0.175)\tLoss 7.5502e-01 (5.8248e-01)\tAcc@1  75.00 ( 83.11)\tAcc@5  95.31 ( 96.58)\n",
            "Epoch: [92][ 90/391]\tTime  0.172 ( 0.175)\tLoss 5.3061e-01 (5.8742e-01)\tAcc@1  83.59 ( 83.10)\tAcc@5 100.00 ( 96.60)\n",
            "Epoch: [92][120/391]\tTime  0.173 ( 0.174)\tLoss 4.6749e-01 (5.8206e-01)\tAcc@1  86.72 ( 83.21)\tAcc@5  98.44 ( 96.68)\n",
            "Epoch: [92][150/391]\tTime  0.173 ( 0.174)\tLoss 6.7706e-01 (5.8026e-01)\tAcc@1  79.69 ( 83.41)\tAcc@5  96.88 ( 96.72)\n",
            "Epoch: [92][180/391]\tTime  0.175 ( 0.174)\tLoss 7.5342e-01 (5.8348e-01)\tAcc@1  80.47 ( 83.38)\tAcc@5  95.31 ( 96.65)\n",
            "Epoch: [92][210/391]\tTime  0.172 ( 0.174)\tLoss 5.6792e-01 (5.8705e-01)\tAcc@1  84.38 ( 83.31)\tAcc@5  95.31 ( 96.56)\n",
            "Epoch: [92][240/391]\tTime  0.173 ( 0.174)\tLoss 5.8004e-01 (5.8707e-01)\tAcc@1  89.06 ( 83.35)\tAcc@5  95.31 ( 96.53)\n",
            "Epoch: [92][270/391]\tTime  0.173 ( 0.174)\tLoss 4.4483e-01 (5.8948e-01)\tAcc@1  89.84 ( 83.24)\tAcc@5  96.09 ( 96.50)\n",
            "Epoch: [92][300/391]\tTime  0.177 ( 0.174)\tLoss 7.1867e-01 (5.9066e-01)\tAcc@1  82.03 ( 83.23)\tAcc@5  94.53 ( 96.47)\n",
            "Epoch: [92][330/391]\tTime  0.173 ( 0.174)\tLoss 6.1304e-01 (5.9104e-01)\tAcc@1  85.16 ( 83.17)\tAcc@5  94.53 ( 96.47)\n",
            "Epoch: [92][360/391]\tTime  0.173 ( 0.174)\tLoss 5.0298e-01 (5.9003e-01)\tAcc@1  84.38 ( 83.19)\tAcc@5  99.22 ( 96.47)\n",
            "Epoch: [92][390/391]\tTime  0.157 ( 0.174)\tLoss 6.7735e-01 (5.9041e-01)\tAcc@1  83.75 ( 83.18)\tAcc@5  95.00 ( 96.44)\n",
            "==> Train Accuracy: Acc@1 83.178 || Acc@5 96.442\n",
            "==> Test Accuracy:  Acc@1 76.400 || Acc@5 94.600\n",
            "==> 72.39 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 93, lr: 0.004000000000000001 -----\n",
            "Epoch: [93][  0/391]\tTime  0.263 ( 0.263)\tLoss 4.6911e-01 (4.6911e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [93][ 30/391]\tTime  0.175 ( 0.177)\tLoss 5.2787e-01 (5.7907e-01)\tAcc@1  85.16 ( 83.77)\tAcc@5  96.09 ( 96.27)\n",
            "Epoch: [93][ 60/391]\tTime  0.171 ( 0.175)\tLoss 7.8092e-01 (5.7883e-01)\tAcc@1  77.34 ( 83.72)\tAcc@5  96.88 ( 96.43)\n",
            "Epoch: [93][ 90/391]\tTime  0.172 ( 0.175)\tLoss 5.7098e-01 (5.7399e-01)\tAcc@1  84.38 ( 83.84)\tAcc@5  96.09 ( 96.46)\n",
            "Epoch: [93][120/391]\tTime  0.172 ( 0.174)\tLoss 5.2924e-01 (5.7649e-01)\tAcc@1  86.72 ( 83.80)\tAcc@5  94.53 ( 96.53)\n",
            "Epoch: [93][150/391]\tTime  0.172 ( 0.174)\tLoss 5.9794e-01 (5.7304e-01)\tAcc@1  82.81 ( 84.00)\tAcc@5  98.44 ( 96.55)\n",
            "Epoch: [93][180/391]\tTime  0.175 ( 0.174)\tLoss 5.1267e-01 (5.6418e-01)\tAcc@1  84.38 ( 84.19)\tAcc@5  98.44 ( 96.64)\n",
            "Epoch: [93][210/391]\tTime  0.174 ( 0.174)\tLoss 5.9644e-01 (5.6369e-01)\tAcc@1  83.59 ( 84.26)\tAcc@5  96.88 ( 96.65)\n",
            "Epoch: [93][240/391]\tTime  0.172 ( 0.174)\tLoss 5.7698e-01 (5.6626e-01)\tAcc@1  82.81 ( 84.19)\tAcc@5  98.44 ( 96.58)\n",
            "Epoch: [93][270/391]\tTime  0.175 ( 0.174)\tLoss 4.4868e-01 (5.6927e-01)\tAcc@1  87.50 ( 84.12)\tAcc@5  97.66 ( 96.56)\n",
            "Epoch: [93][300/391]\tTime  0.171 ( 0.174)\tLoss 5.0488e-01 (5.7100e-01)\tAcc@1  83.59 ( 84.11)\tAcc@5  97.66 ( 96.56)\n",
            "Epoch: [93][330/391]\tTime  0.173 ( 0.174)\tLoss 6.0646e-01 (5.6905e-01)\tAcc@1  85.16 ( 84.16)\tAcc@5  93.75 ( 96.58)\n",
            "Epoch: [93][360/391]\tTime  0.172 ( 0.174)\tLoss 5.3108e-01 (5.7022e-01)\tAcc@1  83.59 ( 84.08)\tAcc@5  96.88 ( 96.56)\n",
            "Epoch: [93][390/391]\tTime  0.155 ( 0.174)\tLoss 5.9573e-01 (5.7181e-01)\tAcc@1  87.50 ( 84.00)\tAcc@5  92.50 ( 96.56)\n",
            "==> Train Accuracy: Acc@1 84.002 || Acc@5 96.560\n",
            "==> Test Accuracy:  Acc@1 76.270 || Acc@5 94.520\n",
            "==> 72.40 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 94, lr: 0.004000000000000001 -----\n",
            "Epoch: [94][  0/391]\tTime  0.294 ( 0.294)\tLoss 4.8203e-01 (4.8203e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [94][ 30/391]\tTime  0.172 ( 0.177)\tLoss 5.5527e-01 (5.4262e-01)\tAcc@1  85.94 ( 85.28)\tAcc@5  95.31 ( 96.77)\n",
            "Epoch: [94][ 60/391]\tTime  0.175 ( 0.176)\tLoss 6.2679e-01 (5.3770e-01)\tAcc@1  82.81 ( 85.35)\tAcc@5  96.09 ( 96.95)\n",
            "Epoch: [94][ 90/391]\tTime  0.171 ( 0.175)\tLoss 5.5826e-01 (5.4317e-01)\tAcc@1  85.94 ( 85.11)\tAcc@5  96.09 ( 96.89)\n",
            "Epoch: [94][120/391]\tTime  0.175 ( 0.175)\tLoss 7.5490e-01 (5.4900e-01)\tAcc@1  80.47 ( 84.88)\tAcc@5  94.53 ( 96.75)\n",
            "Epoch: [94][150/391]\tTime  0.171 ( 0.174)\tLoss 7.5363e-01 (5.5084e-01)\tAcc@1  82.03 ( 84.75)\tAcc@5  96.09 ( 96.77)\n",
            "Epoch: [94][180/391]\tTime  0.173 ( 0.174)\tLoss 5.7168e-01 (5.4978e-01)\tAcc@1  81.25 ( 84.68)\tAcc@5  97.66 ( 96.83)\n",
            "Epoch: [94][210/391]\tTime  0.177 ( 0.174)\tLoss 5.4464e-01 (5.5321e-01)\tAcc@1  87.50 ( 84.63)\tAcc@5  95.31 ( 96.78)\n",
            "Epoch: [94][240/391]\tTime  0.169 ( 0.174)\tLoss 6.1300e-01 (5.5285e-01)\tAcc@1  80.47 ( 84.59)\tAcc@5  97.66 ( 96.81)\n",
            "Epoch: [94][270/391]\tTime  0.173 ( 0.174)\tLoss 4.8090e-01 (5.5699e-01)\tAcc@1  86.72 ( 84.44)\tAcc@5  97.66 ( 96.74)\n",
            "Epoch: [94][300/391]\tTime  0.174 ( 0.174)\tLoss 6.0744e-01 (5.5556e-01)\tAcc@1  84.38 ( 84.46)\tAcc@5  97.66 ( 96.78)\n",
            "Epoch: [94][330/391]\tTime  0.172 ( 0.174)\tLoss 5.3350e-01 (5.5200e-01)\tAcc@1  86.72 ( 84.53)\tAcc@5  95.31 ( 96.81)\n",
            "Epoch: [94][360/391]\tTime  0.174 ( 0.174)\tLoss 5.5367e-01 (5.5185e-01)\tAcc@1  83.59 ( 84.51)\tAcc@5  96.88 ( 96.84)\n",
            "Epoch: [94][390/391]\tTime  0.156 ( 0.174)\tLoss 5.6646e-01 (5.5068e-01)\tAcc@1  83.75 ( 84.56)\tAcc@5  96.25 ( 96.85)\n",
            "==> Train Accuracy: Acc@1 84.556 || Acc@5 96.850\n",
            "==> Test Accuracy:  Acc@1 77.050 || Acc@5 94.600\n",
            "==> 72.22 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 95, lr: 0.004000000000000001 -----\n",
            "Epoch: [95][  0/391]\tTime  0.277 ( 0.277)\tLoss 5.9549e-01 (5.9549e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [95][ 30/391]\tTime  0.175 ( 0.176)\tLoss 4.3457e-01 (5.0084e-01)\tAcc@1  88.28 ( 85.96)\tAcc@5  96.88 ( 97.20)\n",
            "Epoch: [95][ 60/391]\tTime  0.172 ( 0.174)\tLoss 4.1171e-01 (5.0133e-01)\tAcc@1  85.94 ( 85.72)\tAcc@5  99.22 ( 97.09)\n",
            "Epoch: [95][ 90/391]\tTime  0.173 ( 0.174)\tLoss 4.2049e-01 (5.0628e-01)\tAcc@1  89.06 ( 85.65)\tAcc@5  96.88 ( 97.01)\n",
            "Epoch: [95][120/391]\tTime  0.175 ( 0.174)\tLoss 5.8301e-01 (5.0263e-01)\tAcc@1  82.03 ( 85.80)\tAcc@5  96.09 ( 97.04)\n",
            "Epoch: [95][150/391]\tTime  0.175 ( 0.174)\tLoss 6.3551e-01 (5.1428e-01)\tAcc@1  81.25 ( 85.45)\tAcc@5  96.88 ( 97.03)\n",
            "Epoch: [95][180/391]\tTime  0.174 ( 0.174)\tLoss 4.6523e-01 (5.1984e-01)\tAcc@1  87.50 ( 85.38)\tAcc@5  98.44 ( 96.95)\n",
            "Epoch: [95][210/391]\tTime  0.173 ( 0.173)\tLoss 4.9955e-01 (5.2360e-01)\tAcc@1  85.94 ( 85.17)\tAcc@5  97.66 ( 96.96)\n",
            "Epoch: [95][240/391]\tTime  0.171 ( 0.173)\tLoss 2.5973e-01 (5.2363e-01)\tAcc@1  92.97 ( 85.12)\tAcc@5 100.00 ( 96.98)\n",
            "Epoch: [95][270/391]\tTime  0.174 ( 0.173)\tLoss 4.4249e-01 (5.2466e-01)\tAcc@1  86.72 ( 85.12)\tAcc@5  97.66 ( 96.97)\n",
            "Epoch: [95][300/391]\tTime  0.174 ( 0.173)\tLoss 3.7502e-01 (5.2782e-01)\tAcc@1  90.62 ( 85.04)\tAcc@5  97.66 ( 96.95)\n",
            "Epoch: [95][330/391]\tTime  0.172 ( 0.173)\tLoss 7.4066e-01 (5.3355e-01)\tAcc@1  81.25 ( 84.91)\tAcc@5  93.75 ( 96.89)\n",
            "Epoch: [95][360/391]\tTime  0.177 ( 0.173)\tLoss 5.2705e-01 (5.3255e-01)\tAcc@1  86.72 ( 84.90)\tAcc@5  96.88 ( 96.93)\n",
            "Epoch: [95][390/391]\tTime  0.155 ( 0.173)\tLoss 3.9659e-01 (5.3362e-01)\tAcc@1  90.00 ( 84.87)\tAcc@5 100.00 ( 96.91)\n",
            "==> Train Accuracy: Acc@1 84.866 || Acc@5 96.912\n",
            "==> Test Accuracy:  Acc@1 76.550 || Acc@5 94.610\n",
            "==> 72.10 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 96, lr: 0.004000000000000001 -----\n",
            "Epoch: [96][  0/391]\tTime  0.269 ( 0.269)\tLoss 4.7184e-01 (4.7184e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [96][ 30/391]\tTime  0.172 ( 0.176)\tLoss 4.3682e-01 (5.4161e-01)\tAcc@1  87.50 ( 84.88)\tAcc@5  96.88 ( 96.80)\n",
            "Epoch: [96][ 60/391]\tTime  0.174 ( 0.175)\tLoss 4.9634e-01 (5.1795e-01)\tAcc@1  89.84 ( 85.46)\tAcc@5  96.09 ( 97.12)\n",
            "Epoch: [96][ 90/391]\tTime  0.174 ( 0.174)\tLoss 4.5222e-01 (5.1577e-01)\tAcc@1  85.16 ( 85.41)\tAcc@5  99.22 ( 97.11)\n",
            "Epoch: [96][120/391]\tTime  0.176 ( 0.174)\tLoss 3.8313e-01 (5.1476e-01)\tAcc@1  87.50 ( 85.33)\tAcc@5  98.44 ( 97.06)\n",
            "Epoch: [96][150/391]\tTime  0.174 ( 0.174)\tLoss 3.7951e-01 (5.1307e-01)\tAcc@1  88.28 ( 85.44)\tAcc@5  98.44 ( 97.09)\n",
            "Epoch: [96][180/391]\tTime  0.172 ( 0.174)\tLoss 5.2753e-01 (5.1595e-01)\tAcc@1  87.50 ( 85.36)\tAcc@5  96.09 ( 97.01)\n",
            "Epoch: [96][210/391]\tTime  0.174 ( 0.174)\tLoss 6.4076e-01 (5.2216e-01)\tAcc@1  78.91 ( 85.21)\tAcc@5  96.88 ( 96.98)\n",
            "Epoch: [96][240/391]\tTime  0.173 ( 0.174)\tLoss 5.3598e-01 (5.2266e-01)\tAcc@1  85.16 ( 85.17)\tAcc@5  98.44 ( 96.94)\n",
            "Epoch: [96][270/391]\tTime  0.173 ( 0.174)\tLoss 4.5280e-01 (5.1940e-01)\tAcc@1  85.94 ( 85.25)\tAcc@5  96.88 ( 97.01)\n",
            "Epoch: [96][300/391]\tTime  0.176 ( 0.174)\tLoss 6.7722e-01 (5.1754e-01)\tAcc@1  82.81 ( 85.37)\tAcc@5  93.75 ( 97.00)\n",
            "Epoch: [96][330/391]\tTime  0.171 ( 0.174)\tLoss 6.0091e-01 (5.1650e-01)\tAcc@1  81.25 ( 85.35)\tAcc@5  96.88 ( 97.07)\n",
            "Epoch: [96][360/391]\tTime  0.174 ( 0.174)\tLoss 4.9129e-01 (5.1720e-01)\tAcc@1  85.16 ( 85.36)\tAcc@5  97.66 ( 97.05)\n",
            "Epoch: [96][390/391]\tTime  0.156 ( 0.173)\tLoss 5.1499e-01 (5.1782e-01)\tAcc@1  83.75 ( 85.34)\tAcc@5  96.25 ( 97.02)\n",
            "==> Train Accuracy: Acc@1 85.340 || Acc@5 97.020\n",
            "==> Test Accuracy:  Acc@1 76.510 || Acc@5 94.410\n",
            "==> 72.17 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 97, lr: 0.004000000000000001 -----\n",
            "Epoch: [97][  0/391]\tTime  0.267 ( 0.267)\tLoss 5.4224e-01 (5.4224e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [97][ 30/391]\tTime  0.173 ( 0.176)\tLoss 3.1345e-01 (4.5839e-01)\tAcc@1  89.84 ( 86.74)\tAcc@5  99.22 ( 97.68)\n",
            "Epoch: [97][ 60/391]\tTime  0.174 ( 0.175)\tLoss 4.6237e-01 (4.7181e-01)\tAcc@1  82.81 ( 86.37)\tAcc@5  96.88 ( 97.46)\n",
            "Epoch: [97][ 90/391]\tTime  0.178 ( 0.174)\tLoss 4.1116e-01 (4.7952e-01)\tAcc@1  89.84 ( 86.17)\tAcc@5  98.44 ( 97.37)\n",
            "Epoch: [97][120/391]\tTime  0.172 ( 0.174)\tLoss 3.0619e-01 (4.8831e-01)\tAcc@1  90.62 ( 85.99)\tAcc@5  98.44 ( 97.20)\n",
            "Epoch: [97][150/391]\tTime  0.173 ( 0.174)\tLoss 5.2480e-01 (4.8323e-01)\tAcc@1  83.59 ( 86.20)\tAcc@5  96.09 ( 97.26)\n",
            "Epoch: [97][180/391]\tTime  0.174 ( 0.174)\tLoss 4.3788e-01 (4.8747e-01)\tAcc@1  89.84 ( 86.12)\tAcc@5  96.88 ( 97.26)\n",
            "Epoch: [97][210/391]\tTime  0.172 ( 0.174)\tLoss 3.2166e-01 (4.8993e-01)\tAcc@1  90.62 ( 86.12)\tAcc@5 100.00 ( 97.27)\n",
            "Epoch: [97][240/391]\tTime  0.172 ( 0.174)\tLoss 4.4022e-01 (4.9116e-01)\tAcc@1  88.28 ( 86.08)\tAcc@5  98.44 ( 97.26)\n",
            "Epoch: [97][270/391]\tTime  0.174 ( 0.174)\tLoss 4.6938e-01 (4.9323e-01)\tAcc@1  88.28 ( 86.00)\tAcc@5  98.44 ( 97.25)\n",
            "Epoch: [97][300/391]\tTime  0.174 ( 0.174)\tLoss 4.9081e-01 (4.9558e-01)\tAcc@1  83.59 ( 85.94)\tAcc@5  97.66 ( 97.20)\n",
            "Epoch: [97][330/391]\tTime  0.171 ( 0.173)\tLoss 5.9832e-01 (4.9716e-01)\tAcc@1  82.81 ( 85.90)\tAcc@5  95.31 ( 97.16)\n",
            "Epoch: [97][360/391]\tTime  0.175 ( 0.173)\tLoss 4.5959e-01 (4.9727e-01)\tAcc@1  86.72 ( 85.90)\tAcc@5  96.88 ( 97.16)\n",
            "Epoch: [97][390/391]\tTime  0.157 ( 0.173)\tLoss 4.2804e-01 (4.9825e-01)\tAcc@1  87.50 ( 85.84)\tAcc@5 100.00 ( 97.18)\n",
            "==> Train Accuracy: Acc@1 85.838 || Acc@5 97.182\n",
            "==> Test Accuracy:  Acc@1 76.500 || Acc@5 94.510\n",
            "==> 72.16 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 98, lr: 0.004000000000000001 -----\n",
            "Epoch: [98][  0/391]\tTime  0.274 ( 0.274)\tLoss 4.3794e-01 (4.3794e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [98][ 30/391]\tTime  0.176 ( 0.176)\tLoss 5.6776e-01 (4.6549e-01)\tAcc@1  81.25 ( 86.97)\tAcc@5  96.09 ( 97.51)\n",
            "Epoch: [98][ 60/391]\tTime  0.176 ( 0.175)\tLoss 5.9452e-01 (4.6716e-01)\tAcc@1  83.59 ( 86.97)\tAcc@5  96.88 ( 97.66)\n",
            "Epoch: [98][ 90/391]\tTime  0.173 ( 0.174)\tLoss 3.2088e-01 (4.6451e-01)\tAcc@1  88.28 ( 87.10)\tAcc@5 100.00 ( 97.55)\n",
            "Epoch: [98][120/391]\tTime  0.172 ( 0.174)\tLoss 4.6569e-01 (4.6865e-01)\tAcc@1  87.50 ( 87.02)\tAcc@5  98.44 ( 97.55)\n",
            "Epoch: [98][150/391]\tTime  0.173 ( 0.174)\tLoss 4.1205e-01 (4.7040e-01)\tAcc@1  91.41 ( 86.98)\tAcc@5  96.88 ( 97.53)\n",
            "Epoch: [98][180/391]\tTime  0.173 ( 0.174)\tLoss 4.4099e-01 (4.7650e-01)\tAcc@1  89.84 ( 86.81)\tAcc@5  97.66 ( 97.42)\n",
            "Epoch: [98][210/391]\tTime  0.173 ( 0.174)\tLoss 4.9020e-01 (4.7904e-01)\tAcc@1  85.16 ( 86.63)\tAcc@5  98.44 ( 97.45)\n",
            "Epoch: [98][240/391]\tTime  0.174 ( 0.174)\tLoss 6.5580e-01 (4.8144e-01)\tAcc@1  85.94 ( 86.52)\tAcc@5  96.88 ( 97.45)\n",
            "Epoch: [98][270/391]\tTime  0.174 ( 0.174)\tLoss 5.6154e-01 (4.8219e-01)\tAcc@1  82.81 ( 86.40)\tAcc@5  95.31 ( 97.48)\n",
            "Epoch: [98][300/391]\tTime  0.175 ( 0.174)\tLoss 3.9661e-01 (4.8312e-01)\tAcc@1  90.62 ( 86.39)\tAcc@5 100.00 ( 97.49)\n",
            "Epoch: [98][330/391]\tTime  0.172 ( 0.174)\tLoss 6.4848e-01 (4.8780e-01)\tAcc@1  83.59 ( 86.29)\tAcc@5  95.31 ( 97.42)\n",
            "Epoch: [98][360/391]\tTime  0.170 ( 0.174)\tLoss 6.1687e-01 (4.8792e-01)\tAcc@1  82.03 ( 86.25)\tAcc@5  96.09 ( 97.42)\n",
            "Epoch: [98][390/391]\tTime  0.155 ( 0.173)\tLoss 5.2058e-01 (4.8888e-01)\tAcc@1  87.50 ( 86.21)\tAcc@5  96.25 ( 97.41)\n",
            "==> Train Accuracy: Acc@1 86.210 || Acc@5 97.408\n",
            "==> Test Accuracy:  Acc@1 76.420 || Acc@5 94.490\n",
            "==> 72.19 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 99, lr: 0.004000000000000001 -----\n",
            "Epoch: [99][  0/391]\tTime  0.282 ( 0.282)\tLoss 5.1153e-01 (5.1153e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [99][ 30/391]\tTime  0.173 ( 0.176)\tLoss 4.7412e-01 (4.7671e-01)\tAcc@1  85.94 ( 86.29)\tAcc@5  99.22 ( 97.18)\n",
            "Epoch: [99][ 60/391]\tTime  0.170 ( 0.175)\tLoss 5.3930e-01 (4.6686e-01)\tAcc@1  86.72 ( 86.73)\tAcc@5  96.88 ( 97.55)\n",
            "Epoch: [99][ 90/391]\tTime  0.172 ( 0.174)\tLoss 3.8469e-01 (4.7009e-01)\tAcc@1  89.06 ( 86.85)\tAcc@5  98.44 ( 97.53)\n",
            "Epoch: [99][120/391]\tTime  0.173 ( 0.174)\tLoss 5.6610e-01 (4.8024e-01)\tAcc@1  82.81 ( 86.56)\tAcc@5  96.09 ( 97.39)\n",
            "Epoch: [99][150/391]\tTime  0.176 ( 0.174)\tLoss 5.1308e-01 (4.8550e-01)\tAcc@1  86.72 ( 86.33)\tAcc@5  96.88 ( 97.35)\n",
            "Epoch: [99][180/391]\tTime  0.175 ( 0.174)\tLoss 4.0431e-01 (4.8535e-01)\tAcc@1  85.94 ( 86.27)\tAcc@5  99.22 ( 97.37)\n",
            "Epoch: [99][210/391]\tTime  0.175 ( 0.174)\tLoss 5.0836e-01 (4.8274e-01)\tAcc@1  88.28 ( 86.38)\tAcc@5  96.09 ( 97.38)\n",
            "Epoch: [99][240/391]\tTime  0.176 ( 0.174)\tLoss 2.9530e-01 (4.8055e-01)\tAcc@1  92.19 ( 86.46)\tAcc@5  98.44 ( 97.42)\n",
            "Epoch: [99][270/391]\tTime  0.173 ( 0.174)\tLoss 3.7459e-01 (4.8104e-01)\tAcc@1  85.94 ( 86.47)\tAcc@5  99.22 ( 97.46)\n",
            "Epoch: [99][300/391]\tTime  0.173 ( 0.174)\tLoss 4.5626e-01 (4.8325e-01)\tAcc@1  85.16 ( 86.38)\tAcc@5  96.09 ( 97.45)\n",
            "Epoch: [99][330/391]\tTime  0.174 ( 0.174)\tLoss 4.9785e-01 (4.8378e-01)\tAcc@1  87.50 ( 86.37)\tAcc@5  96.09 ( 97.46)\n",
            "Epoch: [99][360/391]\tTime  0.173 ( 0.174)\tLoss 3.2806e-01 (4.8378e-01)\tAcc@1  92.97 ( 86.41)\tAcc@5  98.44 ( 97.42)\n",
            "Epoch: [99][390/391]\tTime  0.156 ( 0.174)\tLoss 4.0305e-01 (4.8364e-01)\tAcc@1  87.50 ( 86.40)\tAcc@5 100.00 ( 97.43)\n",
            "==> Train Accuracy: Acc@1 86.400 || Acc@5 97.430\n",
            "==> Test Accuracy:  Acc@1 76.430 || Acc@5 94.300\n",
            "==> 72.24 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 100, lr: 0.004000000000000001 -----\n",
            "Epoch: [100][  0/391]\tTime  0.282 ( 0.282)\tLoss 4.0624e-01 (4.0624e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [100][ 30/391]\tTime  0.171 ( 0.177)\tLoss 4.6111e-01 (4.6351e-01)\tAcc@1  92.97 ( 87.35)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [100][ 60/391]\tTime  0.174 ( 0.175)\tLoss 4.8589e-01 (4.7029e-01)\tAcc@1  89.06 ( 86.90)\tAcc@5  95.31 ( 97.52)\n",
            "Epoch: [100][ 90/391]\tTime  0.172 ( 0.175)\tLoss 5.4613e-01 (4.6563e-01)\tAcc@1  85.16 ( 86.88)\tAcc@5  96.88 ( 97.54)\n",
            "Epoch: [100][120/391]\tTime  0.174 ( 0.174)\tLoss 4.6031e-01 (4.6054e-01)\tAcc@1  84.38 ( 87.00)\tAcc@5  98.44 ( 97.67)\n",
            "Epoch: [100][150/391]\tTime  0.175 ( 0.174)\tLoss 3.8035e-01 (4.6683e-01)\tAcc@1  85.16 ( 86.81)\tAcc@5 100.00 ( 97.59)\n",
            "Epoch: [100][180/391]\tTime  0.175 ( 0.174)\tLoss 5.6410e-01 (4.7316e-01)\tAcc@1  82.03 ( 86.71)\tAcc@5  97.66 ( 97.53)\n",
            "Epoch: [100][210/391]\tTime  0.174 ( 0.174)\tLoss 4.2813e-01 (4.6969e-01)\tAcc@1  86.72 ( 86.77)\tAcc@5  97.66 ( 97.55)\n",
            "Epoch: [100][240/391]\tTime  0.173 ( 0.174)\tLoss 6.6163e-01 (4.7284e-01)\tAcc@1  84.38 ( 86.73)\tAcc@5  95.31 ( 97.48)\n",
            "Epoch: [100][270/391]\tTime  0.174 ( 0.174)\tLoss 5.6023e-01 (4.7524e-01)\tAcc@1  84.38 ( 86.65)\tAcc@5  93.75 ( 97.46)\n",
            "Epoch: [100][300/391]\tTime  0.174 ( 0.174)\tLoss 4.2497e-01 (4.7269e-01)\tAcc@1  89.84 ( 86.73)\tAcc@5  96.88 ( 97.47)\n",
            "Epoch: [100][330/391]\tTime  0.175 ( 0.174)\tLoss 4.9741e-01 (4.7271e-01)\tAcc@1  87.50 ( 86.74)\tAcc@5  96.09 ( 97.47)\n",
            "Epoch: [100][360/391]\tTime  0.174 ( 0.174)\tLoss 4.1723e-01 (4.7081e-01)\tAcc@1  87.50 ( 86.81)\tAcc@5  98.44 ( 97.48)\n",
            "Epoch: [100][390/391]\tTime  0.157 ( 0.174)\tLoss 6.0462e-01 (4.7180e-01)\tAcc@1  86.25 ( 86.79)\tAcc@5  95.00 ( 97.48)\n",
            "==> Train Accuracy: Acc@1 86.788 || Acc@5 97.476\n",
            "==> Test Accuracy:  Acc@1 76.450 || Acc@5 94.370\n",
            "==> 72.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 101, lr: 0.004000000000000001 -----\n",
            "Epoch: [101][  0/391]\tTime  0.262 ( 0.262)\tLoss 4.6941e-01 (4.6941e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [101][ 30/391]\tTime  0.174 ( 0.176)\tLoss 3.4880e-01 (4.4611e-01)\tAcc@1  89.84 ( 87.17)\tAcc@5  98.44 ( 97.63)\n",
            "Epoch: [101][ 60/391]\tTime  0.174 ( 0.175)\tLoss 4.8952e-01 (4.5259e-01)\tAcc@1  83.59 ( 87.40)\tAcc@5  97.66 ( 97.67)\n",
            "Epoch: [101][ 90/391]\tTime  0.171 ( 0.174)\tLoss 4.2524e-01 (4.5393e-01)\tAcc@1  86.72 ( 87.27)\tAcc@5  98.44 ( 97.66)\n",
            "Epoch: [101][120/391]\tTime  0.175 ( 0.174)\tLoss 5.0882e-01 (4.4495e-01)\tAcc@1  84.38 ( 87.52)\tAcc@5  96.88 ( 97.71)\n",
            "Epoch: [101][150/391]\tTime  0.175 ( 0.174)\tLoss 3.7944e-01 (4.4998e-01)\tAcc@1  89.84 ( 87.27)\tAcc@5  99.22 ( 97.68)\n",
            "Epoch: [101][180/391]\tTime  0.169 ( 0.174)\tLoss 4.8423e-01 (4.5773e-01)\tAcc@1  87.50 ( 87.06)\tAcc@5  97.66 ( 97.65)\n",
            "Epoch: [101][210/391]\tTime  0.172 ( 0.174)\tLoss 5.0613e-01 (4.5606e-01)\tAcc@1  85.94 ( 87.09)\tAcc@5  96.88 ( 97.66)\n",
            "Epoch: [101][240/391]\tTime  0.175 ( 0.174)\tLoss 3.9669e-01 (4.5753e-01)\tAcc@1  89.84 ( 87.06)\tAcc@5  98.44 ( 97.62)\n",
            "Epoch: [101][270/391]\tTime  0.173 ( 0.174)\tLoss 5.1199e-01 (4.6178e-01)\tAcc@1  85.94 ( 86.98)\tAcc@5  96.88 ( 97.60)\n",
            "Epoch: [101][300/391]\tTime  0.172 ( 0.174)\tLoss 5.2219e-01 (4.6391e-01)\tAcc@1  85.94 ( 87.00)\tAcc@5  96.88 ( 97.54)\n",
            "Epoch: [101][330/391]\tTime  0.174 ( 0.174)\tLoss 4.4138e-01 (4.6553e-01)\tAcc@1  86.72 ( 86.95)\tAcc@5  98.44 ( 97.53)\n",
            "Epoch: [101][360/391]\tTime  0.173 ( 0.174)\tLoss 5.5735e-01 (4.6347e-01)\tAcc@1  84.38 ( 86.99)\tAcc@5  96.09 ( 97.56)\n",
            "Epoch: [101][390/391]\tTime  0.155 ( 0.174)\tLoss 3.3244e-01 (4.6323e-01)\tAcc@1  91.25 ( 86.99)\tAcc@5 100.00 ( 97.57)\n",
            "==> Train Accuracy: Acc@1 86.990 || Acc@5 97.574\n",
            "==> Test Accuracy:  Acc@1 76.070 || Acc@5 94.340\n",
            "==> 72.28 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 102, lr: 0.004000000000000001 -----\n",
            "Epoch: [102][  0/391]\tTime  0.277 ( 0.277)\tLoss 4.3551e-01 (4.3551e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [102][ 30/391]\tTime  0.171 ( 0.176)\tLoss 3.4278e-01 (4.3157e-01)\tAcc@1  91.41 ( 87.80)\tAcc@5  96.88 ( 97.86)\n",
            "Epoch: [102][ 60/391]\tTime  0.174 ( 0.175)\tLoss 4.5014e-01 (4.4321e-01)\tAcc@1  89.06 ( 87.55)\tAcc@5  98.44 ( 97.77)\n",
            "Epoch: [102][ 90/391]\tTime  0.175 ( 0.175)\tLoss 3.1052e-01 (4.4040e-01)\tAcc@1  92.97 ( 87.71)\tAcc@5  99.22 ( 97.72)\n",
            "Epoch: [102][120/391]\tTime  0.174 ( 0.174)\tLoss 4.9251e-01 (4.3585e-01)\tAcc@1  85.16 ( 87.86)\tAcc@5  98.44 ( 97.75)\n",
            "Epoch: [102][150/391]\tTime  0.174 ( 0.174)\tLoss 2.8089e-01 (4.3786e-01)\tAcc@1  92.19 ( 87.77)\tAcc@5  97.66 ( 97.70)\n",
            "Epoch: [102][180/391]\tTime  0.173 ( 0.174)\tLoss 4.9003e-01 (4.4159e-01)\tAcc@1  88.28 ( 87.69)\tAcc@5  97.66 ( 97.63)\n",
            "Epoch: [102][210/391]\tTime  0.174 ( 0.174)\tLoss 4.2280e-01 (4.4601e-01)\tAcc@1  85.16 ( 87.42)\tAcc@5  98.44 ( 97.60)\n",
            "Epoch: [102][240/391]\tTime  0.174 ( 0.174)\tLoss 5.7439e-01 (4.4502e-01)\tAcc@1  85.16 ( 87.40)\tAcc@5  95.31 ( 97.61)\n",
            "Epoch: [102][270/391]\tTime  0.174 ( 0.174)\tLoss 5.8587e-01 (4.4726e-01)\tAcc@1  84.38 ( 87.38)\tAcc@5  96.09 ( 97.60)\n",
            "Epoch: [102][300/391]\tTime  0.174 ( 0.174)\tLoss 4.2212e-01 (4.4896e-01)\tAcc@1  87.50 ( 87.32)\tAcc@5  97.66 ( 97.59)\n",
            "Epoch: [102][330/391]\tTime  0.174 ( 0.174)\tLoss 5.5457e-01 (4.5052e-01)\tAcc@1  85.16 ( 87.25)\tAcc@5  94.53 ( 97.56)\n",
            "Epoch: [102][360/391]\tTime  0.173 ( 0.174)\tLoss 5.5423e-01 (4.5314e-01)\tAcc@1  87.50 ( 87.15)\tAcc@5  96.88 ( 97.55)\n",
            "Epoch: [102][390/391]\tTime  0.156 ( 0.174)\tLoss 3.8332e-01 (4.5363e-01)\tAcc@1  90.00 ( 87.12)\tAcc@5  97.50 ( 97.55)\n",
            "==> Train Accuracy: Acc@1 87.120 || Acc@5 97.554\n",
            "==> Test Accuracy:  Acc@1 76.200 || Acc@5 94.360\n",
            "==> 72.29 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 103, lr: 0.004000000000000001 -----\n",
            "Epoch: [103][  0/391]\tTime  0.258 ( 0.258)\tLoss 4.6350e-01 (4.6350e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [103][ 30/391]\tTime  0.176 ( 0.176)\tLoss 4.6886e-01 (4.0173e-01)\tAcc@1  86.72 ( 88.51)\tAcc@5  97.66 ( 97.96)\n",
            "Epoch: [103][ 60/391]\tTime  0.173 ( 0.175)\tLoss 4.6750e-01 (4.2361e-01)\tAcc@1  87.50 ( 88.38)\tAcc@5  94.53 ( 97.53)\n",
            "Epoch: [103][ 90/391]\tTime  0.174 ( 0.174)\tLoss 3.7915e-01 (4.1974e-01)\tAcc@1  89.06 ( 88.67)\tAcc@5  96.88 ( 97.54)\n",
            "Epoch: [103][120/391]\tTime  0.174 ( 0.174)\tLoss 3.5692e-01 (4.2646e-01)\tAcc@1  90.62 ( 88.37)\tAcc@5  98.44 ( 97.57)\n",
            "Epoch: [103][150/391]\tTime  0.176 ( 0.174)\tLoss 5.1896e-01 (4.3228e-01)\tAcc@1  83.59 ( 88.18)\tAcc@5  96.88 ( 97.53)\n",
            "Epoch: [103][180/391]\tTime  0.174 ( 0.174)\tLoss 5.4439e-01 (4.3112e-01)\tAcc@1  85.16 ( 88.19)\tAcc@5  96.88 ( 97.58)\n",
            "Epoch: [103][210/391]\tTime  0.173 ( 0.174)\tLoss 3.6500e-01 (4.3774e-01)\tAcc@1  87.50 ( 87.90)\tAcc@5  99.22 ( 97.52)\n",
            "Epoch: [103][240/391]\tTime  0.175 ( 0.174)\tLoss 3.0414e-01 (4.4344e-01)\tAcc@1  90.62 ( 87.67)\tAcc@5  98.44 ( 97.51)\n",
            "Epoch: [103][270/391]\tTime  0.174 ( 0.174)\tLoss 5.0879e-01 (4.4445e-01)\tAcc@1  86.72 ( 87.59)\tAcc@5  96.09 ( 97.50)\n",
            "Epoch: [103][300/391]\tTime  0.174 ( 0.174)\tLoss 5.5498e-01 (4.4693e-01)\tAcc@1  84.38 ( 87.51)\tAcc@5  96.88 ( 97.50)\n",
            "Epoch: [103][330/391]\tTime  0.175 ( 0.174)\tLoss 4.3236e-01 (4.4708e-01)\tAcc@1  88.28 ( 87.44)\tAcc@5  96.88 ( 97.51)\n",
            "Epoch: [103][360/391]\tTime  0.174 ( 0.174)\tLoss 5.1138e-01 (4.4694e-01)\tAcc@1  86.72 ( 87.44)\tAcc@5  96.09 ( 97.51)\n",
            "Epoch: [103][390/391]\tTime  0.155 ( 0.174)\tLoss 5.3186e-01 (4.4607e-01)\tAcc@1  86.25 ( 87.45)\tAcc@5  97.50 ( 97.52)\n",
            "==> Train Accuracy: Acc@1 87.450 || Acc@5 97.520\n",
            "==> Test Accuracy:  Acc@1 76.500 || Acc@5 94.040\n",
            "==> 72.27 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 104, lr: 0.004000000000000001 -----\n",
            "Epoch: [104][  0/391]\tTime  0.289 ( 0.289)\tLoss 4.9308e-01 (4.9308e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [104][ 30/391]\tTime  0.175 ( 0.177)\tLoss 3.5962e-01 (4.2086e-01)\tAcc@1  89.84 ( 88.33)\tAcc@5  97.66 ( 97.91)\n",
            "Epoch: [104][ 60/391]\tTime  0.175 ( 0.175)\tLoss 5.0264e-01 (4.2090e-01)\tAcc@1  85.16 ( 88.40)\tAcc@5  96.88 ( 97.84)\n",
            "Epoch: [104][ 90/391]\tTime  0.175 ( 0.175)\tLoss 2.8914e-01 (4.2098e-01)\tAcc@1  92.97 ( 88.27)\tAcc@5  97.66 ( 97.88)\n",
            "Epoch: [104][120/391]\tTime  0.175 ( 0.175)\tLoss 4.1881e-01 (4.2147e-01)\tAcc@1  89.06 ( 88.25)\tAcc@5  98.44 ( 97.93)\n",
            "Epoch: [104][150/391]\tTime  0.175 ( 0.174)\tLoss 3.2877e-01 (4.2098e-01)\tAcc@1  92.19 ( 88.34)\tAcc@5  96.88 ( 97.89)\n",
            "Epoch: [104][180/391]\tTime  0.172 ( 0.174)\tLoss 3.5987e-01 (4.2763e-01)\tAcc@1  90.62 ( 88.12)\tAcc@5  97.66 ( 97.83)\n",
            "Epoch: [104][210/391]\tTime  0.174 ( 0.174)\tLoss 3.8586e-01 (4.2475e-01)\tAcc@1  87.50 ( 88.16)\tAcc@5  98.44 ( 97.91)\n",
            "Epoch: [104][240/391]\tTime  0.171 ( 0.174)\tLoss 5.5877e-01 (4.2843e-01)\tAcc@1  85.94 ( 88.03)\tAcc@5  96.88 ( 97.90)\n",
            "Epoch: [104][270/391]\tTime  0.175 ( 0.174)\tLoss 3.7113e-01 (4.3185e-01)\tAcc@1  87.50 ( 87.89)\tAcc@5 100.00 ( 97.83)\n",
            "Epoch: [104][300/391]\tTime  0.175 ( 0.174)\tLoss 2.8223e-01 (4.3041e-01)\tAcc@1  92.19 ( 87.92)\tAcc@5 100.00 ( 97.87)\n",
            "Epoch: [104][330/391]\tTime  0.173 ( 0.174)\tLoss 3.5878e-01 (4.3214e-01)\tAcc@1  92.97 ( 87.87)\tAcc@5  97.66 ( 97.83)\n",
            "Epoch: [104][360/391]\tTime  0.174 ( 0.174)\tLoss 4.6951e-01 (4.3522e-01)\tAcc@1  90.62 ( 87.79)\tAcc@5  96.88 ( 97.74)\n",
            "Epoch: [104][390/391]\tTime  0.155 ( 0.174)\tLoss 7.3158e-01 (4.3679e-01)\tAcc@1  78.75 ( 87.71)\tAcc@5  95.00 ( 97.75)\n",
            "==> Train Accuracy: Acc@1 87.714 || Acc@5 97.746\n",
            "==> Test Accuracy:  Acc@1 76.500 || Acc@5 94.080\n",
            "==> 72.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 105, lr: 0.004000000000000001 -----\n",
            "Epoch: [105][  0/391]\tTime  0.259 ( 0.259)\tLoss 4.5240e-01 (4.5240e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [105][ 30/391]\tTime  0.173 ( 0.176)\tLoss 3.5248e-01 (3.7501e-01)\tAcc@1  90.62 ( 89.87)\tAcc@5  97.66 ( 98.11)\n",
            "Epoch: [105][ 60/391]\tTime  0.174 ( 0.175)\tLoss 4.0797e-01 (4.0481e-01)\tAcc@1  89.84 ( 88.81)\tAcc@5  98.44 ( 98.05)\n",
            "Epoch: [105][ 90/391]\tTime  0.174 ( 0.175)\tLoss 3.9530e-01 (4.1145e-01)\tAcc@1  89.06 ( 88.69)\tAcc@5  96.88 ( 97.85)\n",
            "Epoch: [105][120/391]\tTime  0.172 ( 0.174)\tLoss 5.3583e-01 (4.1297e-01)\tAcc@1  82.81 ( 88.46)\tAcc@5  96.88 ( 97.98)\n",
            "Epoch: [105][150/391]\tTime  0.173 ( 0.174)\tLoss 3.6821e-01 (4.1293e-01)\tAcc@1  89.84 ( 88.35)\tAcc@5  98.44 ( 98.01)\n",
            "Epoch: [105][180/391]\tTime  0.175 ( 0.174)\tLoss 4.2344e-01 (4.1434e-01)\tAcc@1  89.06 ( 88.28)\tAcc@5  96.88 ( 98.01)\n",
            "Epoch: [105][210/391]\tTime  0.172 ( 0.174)\tLoss 4.5403e-01 (4.1783e-01)\tAcc@1  87.50 ( 88.19)\tAcc@5  97.66 ( 97.97)\n",
            "Epoch: [105][240/391]\tTime  0.175 ( 0.174)\tLoss 3.6566e-01 (4.2047e-01)\tAcc@1  88.28 ( 88.14)\tAcc@5  98.44 ( 97.91)\n",
            "Epoch: [105][270/391]\tTime  0.176 ( 0.174)\tLoss 3.6192e-01 (4.2366e-01)\tAcc@1  87.50 ( 88.09)\tAcc@5  98.44 ( 97.91)\n",
            "Epoch: [105][300/391]\tTime  0.174 ( 0.174)\tLoss 4.7331e-01 (4.2621e-01)\tAcc@1  89.06 ( 88.01)\tAcc@5  95.31 ( 97.86)\n",
            "Epoch: [105][330/391]\tTime  0.173 ( 0.174)\tLoss 4.6020e-01 (4.2780e-01)\tAcc@1  85.94 ( 87.93)\tAcc@5  96.88 ( 97.82)\n",
            "Epoch: [105][360/391]\tTime  0.176 ( 0.174)\tLoss 3.9947e-01 (4.3068e-01)\tAcc@1  90.62 ( 87.80)\tAcc@5  97.66 ( 97.79)\n",
            "Epoch: [105][390/391]\tTime  0.156 ( 0.174)\tLoss 3.5844e-01 (4.2964e-01)\tAcc@1  86.25 ( 87.85)\tAcc@5  98.75 ( 97.80)\n",
            "==> Train Accuracy: Acc@1 87.846 || Acc@5 97.802\n",
            "==> Test Accuracy:  Acc@1 75.750 || Acc@5 94.140\n",
            "==> 72.34 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 106, lr: 0.004000000000000001 -----\n",
            "Epoch: [106][  0/391]\tTime  0.266 ( 0.266)\tLoss 3.6078e-01 (3.6078e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [106][ 30/391]\tTime  0.175 ( 0.177)\tLoss 4.4896e-01 (4.2198e-01)\tAcc@1  89.84 ( 87.98)\tAcc@5  95.31 ( 97.61)\n",
            "Epoch: [106][ 60/391]\tTime  0.173 ( 0.175)\tLoss 5.8785e-01 (4.2355e-01)\tAcc@1  80.47 ( 87.88)\tAcc@5  95.31 ( 97.71)\n",
            "Epoch: [106][ 90/391]\tTime  0.174 ( 0.175)\tLoss 3.8923e-01 (4.2107e-01)\tAcc@1  89.06 ( 87.95)\tAcc@5  97.66 ( 97.79)\n",
            "Epoch: [106][120/391]\tTime  0.174 ( 0.174)\tLoss 2.9251e-01 (4.2192e-01)\tAcc@1  89.06 ( 87.99)\tAcc@5 100.00 ( 97.79)\n",
            "Epoch: [106][150/391]\tTime  0.175 ( 0.174)\tLoss 4.9992e-01 (4.2343e-01)\tAcc@1  85.16 ( 88.03)\tAcc@5  96.88 ( 97.74)\n",
            "Epoch: [106][180/391]\tTime  0.172 ( 0.174)\tLoss 2.9572e-01 (4.2126e-01)\tAcc@1  93.75 ( 88.01)\tAcc@5  98.44 ( 97.79)\n",
            "Epoch: [106][210/391]\tTime  0.175 ( 0.174)\tLoss 4.2733e-01 (4.1851e-01)\tAcc@1  86.72 ( 88.09)\tAcc@5  98.44 ( 97.83)\n",
            "Epoch: [106][240/391]\tTime  0.174 ( 0.174)\tLoss 4.5455e-01 (4.1788e-01)\tAcc@1  85.94 ( 88.09)\tAcc@5  97.66 ( 97.88)\n",
            "Epoch: [106][270/391]\tTime  0.174 ( 0.174)\tLoss 4.2699e-01 (4.2019e-01)\tAcc@1  90.62 ( 88.04)\tAcc@5  96.09 ( 97.85)\n",
            "Epoch: [106][300/391]\tTime  0.174 ( 0.174)\tLoss 3.9704e-01 (4.2286e-01)\tAcc@1  89.06 ( 87.99)\tAcc@5  97.66 ( 97.84)\n",
            "Epoch: [106][330/391]\tTime  0.174 ( 0.174)\tLoss 3.8770e-01 (4.2469e-01)\tAcc@1  89.06 ( 87.96)\tAcc@5  98.44 ( 97.78)\n",
            "Epoch: [106][360/391]\tTime  0.172 ( 0.174)\tLoss 2.4021e-01 (4.2398e-01)\tAcc@1  94.53 ( 88.00)\tAcc@5 100.00 ( 97.81)\n",
            "Epoch: [106][390/391]\tTime  0.156 ( 0.174)\tLoss 3.6579e-01 (4.2391e-01)\tAcc@1  87.50 ( 88.01)\tAcc@5 100.00 ( 97.82)\n",
            "==> Train Accuracy: Acc@1 88.012 || Acc@5 97.818\n",
            "==> Test Accuracy:  Acc@1 76.110 || Acc@5 93.870\n",
            "==> 72.40 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 107, lr: 0.004000000000000001 -----\n",
            "Epoch: [107][  0/391]\tTime  0.281 ( 0.281)\tLoss 3.5689e-01 (3.5689e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][ 30/391]\tTime  0.173 ( 0.177)\tLoss 4.4304e-01 (3.9883e-01)\tAcc@1  85.94 ( 88.84)\tAcc@5  97.66 ( 97.78)\n",
            "Epoch: [107][ 60/391]\tTime  0.176 ( 0.175)\tLoss 3.6239e-01 (4.1016e-01)\tAcc@1  90.62 ( 88.33)\tAcc@5  98.44 ( 97.73)\n",
            "Epoch: [107][ 90/391]\tTime  0.174 ( 0.175)\tLoss 2.8564e-01 (4.0971e-01)\tAcc@1  94.53 ( 88.39)\tAcc@5 100.00 ( 97.73)\n",
            "Epoch: [107][120/391]\tTime  0.176 ( 0.175)\tLoss 3.3661e-01 (4.1324e-01)\tAcc@1  90.62 ( 88.45)\tAcc@5  99.22 ( 97.72)\n",
            "Epoch: [107][150/391]\tTime  0.173 ( 0.174)\tLoss 3.4447e-01 (4.1698e-01)\tAcc@1  85.94 ( 88.23)\tAcc@5 100.00 ( 97.73)\n",
            "Epoch: [107][180/391]\tTime  0.173 ( 0.174)\tLoss 4.6631e-01 (4.1774e-01)\tAcc@1  84.38 ( 88.19)\tAcc@5  98.44 ( 97.73)\n",
            "Epoch: [107][210/391]\tTime  0.173 ( 0.174)\tLoss 2.9570e-01 (4.1572e-01)\tAcc@1  92.19 ( 88.32)\tAcc@5  98.44 ( 97.72)\n",
            "Epoch: [107][240/391]\tTime  0.174 ( 0.174)\tLoss 5.8369e-01 (4.2122e-01)\tAcc@1  82.81 ( 88.18)\tAcc@5  99.22 ( 97.74)\n",
            "Epoch: [107][270/391]\tTime  0.173 ( 0.174)\tLoss 4.8140e-01 (4.2440e-01)\tAcc@1  88.28 ( 88.12)\tAcc@5  96.09 ( 97.69)\n",
            "Epoch: [107][300/391]\tTime  0.174 ( 0.174)\tLoss 5.7187e-01 (4.2595e-01)\tAcc@1  82.81 ( 88.08)\tAcc@5  97.66 ( 97.69)\n",
            "Epoch: [107][330/391]\tTime  0.175 ( 0.174)\tLoss 4.2066e-01 (4.2594e-01)\tAcc@1  86.72 ( 87.99)\tAcc@5  98.44 ( 97.69)\n",
            "Epoch: [107][360/391]\tTime  0.173 ( 0.174)\tLoss 3.4992e-01 (4.2311e-01)\tAcc@1  86.72 ( 88.06)\tAcc@5 100.00 ( 97.74)\n",
            "Epoch: [107][390/391]\tTime  0.156 ( 0.174)\tLoss 3.8366e-01 (4.2577e-01)\tAcc@1  88.75 ( 87.96)\tAcc@5  97.50 ( 97.73)\n",
            "==> Train Accuracy: Acc@1 87.956 || Acc@5 97.726\n",
            "==> Test Accuracy:  Acc@1 75.900 || Acc@5 93.950\n",
            "==> 72.38 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 108, lr: 0.004000000000000001 -----\n",
            "Epoch: [108][  0/391]\tTime  0.284 ( 0.284)\tLoss 3.3493e-01 (3.3493e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [108][ 30/391]\tTime  0.176 ( 0.177)\tLoss 3.8235e-01 (4.0957e-01)\tAcc@1  88.28 ( 88.43)\tAcc@5  98.44 ( 98.01)\n",
            "Epoch: [108][ 60/391]\tTime  0.177 ( 0.175)\tLoss 4.3500e-01 (4.1781e-01)\tAcc@1  88.28 ( 88.33)\tAcc@5  96.88 ( 98.03)\n",
            "Epoch: [108][ 90/391]\tTime  0.174 ( 0.175)\tLoss 3.0687e-01 (4.0616e-01)\tAcc@1  92.97 ( 88.66)\tAcc@5  96.88 ( 98.09)\n",
            "Epoch: [108][120/391]\tTime  0.172 ( 0.174)\tLoss 3.5334e-01 (4.1075e-01)\tAcc@1  90.62 ( 88.58)\tAcc@5  99.22 ( 98.01)\n",
            "Epoch: [108][150/391]\tTime  0.173 ( 0.174)\tLoss 2.9093e-01 (4.0790e-01)\tAcc@1  93.75 ( 88.63)\tAcc@5  99.22 ( 98.01)\n",
            "Epoch: [108][180/391]\tTime  0.173 ( 0.174)\tLoss 4.9933e-01 (4.0639e-01)\tAcc@1  86.72 ( 88.64)\tAcc@5  96.09 ( 98.02)\n",
            "Epoch: [108][210/391]\tTime  0.172 ( 0.174)\tLoss 3.0493e-01 (4.0643e-01)\tAcc@1  89.84 ( 88.58)\tAcc@5  99.22 ( 98.05)\n",
            "Epoch: [108][240/391]\tTime  0.175 ( 0.174)\tLoss 3.2887e-01 (4.0902e-01)\tAcc@1  90.62 ( 88.48)\tAcc@5  99.22 ( 98.01)\n",
            "Epoch: [108][270/391]\tTime  0.175 ( 0.174)\tLoss 3.7509e-01 (4.0851e-01)\tAcc@1  88.28 ( 88.47)\tAcc@5  97.66 ( 98.03)\n",
            "Epoch: [108][300/391]\tTime  0.174 ( 0.174)\tLoss 4.0972e-01 (4.1144e-01)\tAcc@1  87.50 ( 88.40)\tAcc@5  98.44 ( 97.97)\n",
            "Epoch: [108][330/391]\tTime  0.179 ( 0.174)\tLoss 3.4180e-01 (4.1567e-01)\tAcc@1  90.62 ( 88.30)\tAcc@5  98.44 ( 97.92)\n",
            "Epoch: [108][360/391]\tTime  0.175 ( 0.174)\tLoss 5.7774e-01 (4.1475e-01)\tAcc@1  85.16 ( 88.34)\tAcc@5  96.09 ( 97.94)\n",
            "Epoch: [108][390/391]\tTime  0.157 ( 0.174)\tLoss 4.4966e-01 (4.1513e-01)\tAcc@1  90.00 ( 88.37)\tAcc@5  98.75 ( 97.92)\n",
            "==> Train Accuracy: Acc@1 88.374 || Acc@5 97.924\n",
            "==> Test Accuracy:  Acc@1 75.780 || Acc@5 93.830\n",
            "==> 72.37 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 109, lr: 0.004000000000000001 -----\n",
            "Epoch: [109][  0/391]\tTime  0.261 ( 0.261)\tLoss 3.7893e-01 (3.7893e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [109][ 30/391]\tTime  0.173 ( 0.176)\tLoss 3.3829e-01 (3.8018e-01)\tAcc@1  88.28 ( 89.14)\tAcc@5  98.44 ( 98.08)\n",
            "Epoch: [109][ 60/391]\tTime  0.174 ( 0.175)\tLoss 3.0024e-01 (3.8591e-01)\tAcc@1  92.19 ( 89.11)\tAcc@5  99.22 ( 98.09)\n",
            "Epoch: [109][ 90/391]\tTime  0.174 ( 0.175)\tLoss 3.4351e-01 (3.8331e-01)\tAcc@1  90.62 ( 89.11)\tAcc@5  97.66 ( 98.16)\n",
            "Epoch: [109][120/391]\tTime  0.172 ( 0.174)\tLoss 4.2610e-01 (3.8724e-01)\tAcc@1  91.41 ( 89.01)\tAcc@5  95.31 ( 98.09)\n",
            "Epoch: [109][150/391]\tTime  0.174 ( 0.174)\tLoss 3.0391e-01 (3.8835e-01)\tAcc@1  90.62 ( 88.98)\tAcc@5  98.44 ( 98.04)\n",
            "Epoch: [109][180/391]\tTime  0.174 ( 0.174)\tLoss 3.2931e-01 (3.9265e-01)\tAcc@1  93.75 ( 88.87)\tAcc@5  99.22 ( 98.01)\n",
            "Epoch: [109][210/391]\tTime  0.175 ( 0.174)\tLoss 3.4619e-01 (3.9283e-01)\tAcc@1  89.06 ( 88.90)\tAcc@5  99.22 ( 98.05)\n",
            "Epoch: [109][240/391]\tTime  0.172 ( 0.174)\tLoss 4.0531e-01 (3.9475e-01)\tAcc@1  89.06 ( 88.85)\tAcc@5  98.44 ( 98.01)\n",
            "Epoch: [109][270/391]\tTime  0.173 ( 0.174)\tLoss 5.9671e-01 (3.9881e-01)\tAcc@1  82.03 ( 88.73)\tAcc@5  96.88 ( 97.96)\n",
            "Epoch: [109][300/391]\tTime  0.175 ( 0.174)\tLoss 4.3335e-01 (3.9996e-01)\tAcc@1  84.38 ( 88.69)\tAcc@5  99.22 ( 97.98)\n",
            "Epoch: [109][330/391]\tTime  0.174 ( 0.174)\tLoss 4.9818e-01 (4.0184e-01)\tAcc@1  89.06 ( 88.60)\tAcc@5  96.88 ( 97.99)\n",
            "Epoch: [109][360/391]\tTime  0.173 ( 0.174)\tLoss 5.0485e-01 (4.0243e-01)\tAcc@1  88.28 ( 88.56)\tAcc@5  94.53 ( 97.98)\n",
            "Epoch: [109][390/391]\tTime  0.157 ( 0.174)\tLoss 4.7370e-01 (4.0481e-01)\tAcc@1  85.00 ( 88.49)\tAcc@5  98.75 ( 97.95)\n",
            "==> Train Accuracy: Acc@1 88.486 || Acc@5 97.948\n",
            "==> Test Accuracy:  Acc@1 75.990 || Acc@5 93.670\n",
            "==> 72.30 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 110, lr: 0.004000000000000001 -----\n",
            "Epoch: [110][  0/391]\tTime  0.285 ( 0.285)\tLoss 5.4998e-01 (5.4998e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [110][ 30/391]\tTime  0.172 ( 0.177)\tLoss 3.5567e-01 (3.7811e-01)\tAcc@1  90.62 ( 89.19)\tAcc@5  98.44 ( 98.24)\n",
            "Epoch: [110][ 60/391]\tTime  0.173 ( 0.175)\tLoss 5.9114e-01 (3.9432e-01)\tAcc@1  83.59 ( 88.90)\tAcc@5  96.88 ( 98.07)\n",
            "Epoch: [110][ 90/391]\tTime  0.175 ( 0.175)\tLoss 3.2828e-01 (3.9756e-01)\tAcc@1  90.62 ( 88.99)\tAcc@5 100.00 ( 98.06)\n",
            "Epoch: [110][120/391]\tTime  0.174 ( 0.175)\tLoss 2.6244e-01 (3.9871e-01)\tAcc@1  93.75 ( 89.07)\tAcc@5 100.00 ( 98.04)\n",
            "Epoch: [110][150/391]\tTime  0.175 ( 0.174)\tLoss 5.4919e-01 (3.9933e-01)\tAcc@1  85.16 ( 88.92)\tAcc@5  96.88 ( 98.04)\n",
            "Epoch: [110][180/391]\tTime  0.176 ( 0.174)\tLoss 2.6969e-01 (3.9560e-01)\tAcc@1  95.31 ( 89.07)\tAcc@5  99.22 ( 98.07)\n",
            "Epoch: [110][210/391]\tTime  0.173 ( 0.174)\tLoss 4.8590e-01 (3.9526e-01)\tAcc@1  88.28 ( 89.07)\tAcc@5  96.88 ( 98.07)\n",
            "Epoch: [110][240/391]\tTime  0.177 ( 0.174)\tLoss 4.9514e-01 (3.9638e-01)\tAcc@1  83.59 ( 88.99)\tAcc@5  96.88 ( 98.06)\n",
            "Epoch: [110][270/391]\tTime  0.173 ( 0.174)\tLoss 3.8141e-01 (3.9827e-01)\tAcc@1  90.62 ( 88.93)\tAcc@5  98.44 ( 98.07)\n",
            "Epoch: [110][300/391]\tTime  0.174 ( 0.174)\tLoss 5.4885e-01 (3.9906e-01)\tAcc@1  82.81 ( 88.92)\tAcc@5  96.09 ( 98.04)\n",
            "Epoch: [110][330/391]\tTime  0.172 ( 0.174)\tLoss 5.7689e-01 (4.0083e-01)\tAcc@1  88.28 ( 88.86)\tAcc@5  95.31 ( 98.02)\n",
            "Epoch: [110][360/391]\tTime  0.174 ( 0.174)\tLoss 3.9377e-01 (4.0238e-01)\tAcc@1  89.06 ( 88.79)\tAcc@5  98.44 ( 98.01)\n",
            "Epoch: [110][390/391]\tTime  0.154 ( 0.174)\tLoss 3.7403e-01 (4.0203e-01)\tAcc@1  90.00 ( 88.78)\tAcc@5 100.00 ( 98.01)\n",
            "==> Train Accuracy: Acc@1 88.776 || Acc@5 98.008\n",
            "==> Test Accuracy:  Acc@1 75.950 || Acc@5 93.890\n",
            "==> 72.35 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 111, lr: 0.004000000000000001 -----\n",
            "Epoch: [111][  0/391]\tTime  0.288 ( 0.288)\tLoss 3.1450e-01 (3.1450e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [111][ 30/391]\tTime  0.172 ( 0.177)\tLoss 5.1624e-01 (3.7801e-01)\tAcc@1  85.16 ( 88.99)\tAcc@5  97.66 ( 98.19)\n",
            "Epoch: [111][ 60/391]\tTime  0.173 ( 0.175)\tLoss 3.7586e-01 (3.8044e-01)\tAcc@1  89.06 ( 89.05)\tAcc@5  98.44 ( 98.28)\n",
            "Epoch: [111][ 90/391]\tTime  0.172 ( 0.174)\tLoss 4.1709e-01 (3.8199e-01)\tAcc@1  87.50 ( 89.09)\tAcc@5  99.22 ( 98.33)\n",
            "Epoch: [111][120/391]\tTime  0.172 ( 0.174)\tLoss 3.5228e-01 (3.8453e-01)\tAcc@1  92.19 ( 88.95)\tAcc@5  97.66 ( 98.24)\n",
            "Epoch: [111][150/391]\tTime  0.172 ( 0.174)\tLoss 3.7173e-01 (3.8767e-01)\tAcc@1  91.41 ( 88.98)\tAcc@5  96.88 ( 98.14)\n",
            "Epoch: [111][180/391]\tTime  0.178 ( 0.174)\tLoss 2.8707e-01 (3.8637e-01)\tAcc@1  93.75 ( 89.08)\tAcc@5  98.44 ( 98.13)\n",
            "Epoch: [111][210/391]\tTime  0.177 ( 0.174)\tLoss 3.6299e-01 (3.9071e-01)\tAcc@1  86.72 ( 88.91)\tAcc@5  99.22 ( 98.12)\n",
            "Epoch: [111][240/391]\tTime  0.176 ( 0.174)\tLoss 3.8608e-01 (3.8959e-01)\tAcc@1  87.50 ( 88.92)\tAcc@5  97.66 ( 98.16)\n",
            "Epoch: [111][270/391]\tTime  0.174 ( 0.174)\tLoss 5.3364e-01 (3.8746e-01)\tAcc@1  84.38 ( 88.95)\tAcc@5  96.09 ( 98.20)\n",
            "Epoch: [111][300/391]\tTime  0.172 ( 0.174)\tLoss 3.7183e-01 (3.8949e-01)\tAcc@1  91.41 ( 88.93)\tAcc@5  97.66 ( 98.16)\n",
            "Epoch: [111][330/391]\tTime  0.173 ( 0.174)\tLoss 3.9220e-01 (3.9085e-01)\tAcc@1  87.50 ( 88.86)\tAcc@5  96.88 ( 98.15)\n",
            "Epoch: [111][360/391]\tTime  0.174 ( 0.174)\tLoss 3.9123e-01 (3.9287e-01)\tAcc@1  89.06 ( 88.85)\tAcc@5  96.88 ( 98.12)\n",
            "Epoch: [111][390/391]\tTime  0.158 ( 0.174)\tLoss 4.5306e-01 (3.9276e-01)\tAcc@1  86.25 ( 88.84)\tAcc@5  97.50 ( 98.11)\n",
            "==> Train Accuracy: Acc@1 88.838 || Acc@5 98.108\n",
            "==> Test Accuracy:  Acc@1 76.160 || Acc@5 94.050\n",
            "==> 72.23 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 112, lr: 0.004000000000000001 -----\n",
            "Epoch: [112][  0/391]\tTime  0.270 ( 0.270)\tLoss 3.9975e-01 (3.9975e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [112][ 30/391]\tTime  0.175 ( 0.176)\tLoss 3.7941e-01 (3.8816e-01)\tAcc@1  89.84 ( 89.16)\tAcc@5  97.66 ( 97.78)\n",
            "Epoch: [112][ 60/391]\tTime  0.173 ( 0.175)\tLoss 2.6861e-01 (3.8541e-01)\tAcc@1  92.97 ( 89.01)\tAcc@5  99.22 ( 97.94)\n",
            "Epoch: [112][ 90/391]\tTime  0.173 ( 0.174)\tLoss 4.3753e-01 (3.9246e-01)\tAcc@1  87.50 ( 89.04)\tAcc@5 100.00 ( 97.93)\n",
            "Epoch: [112][120/391]\tTime  0.174 ( 0.174)\tLoss 5.2683e-01 (3.9062e-01)\tAcc@1  85.94 ( 88.95)\tAcc@5  96.88 ( 97.99)\n",
            "Epoch: [112][150/391]\tTime  0.173 ( 0.174)\tLoss 4.6474e-01 (3.8968e-01)\tAcc@1  86.72 ( 89.00)\tAcc@5  97.66 ( 97.98)\n",
            "Epoch: [112][180/391]\tTime  0.170 ( 0.174)\tLoss 4.4211e-01 (3.8897e-01)\tAcc@1  85.94 ( 89.01)\tAcc@5  98.44 ( 98.00)\n",
            "Epoch: [112][210/391]\tTime  0.174 ( 0.174)\tLoss 4.3207e-01 (3.8972e-01)\tAcc@1  88.28 ( 88.99)\tAcc@5  97.66 ( 98.02)\n",
            "Epoch: [112][240/391]\tTime  0.170 ( 0.174)\tLoss 3.0301e-01 (3.8782e-01)\tAcc@1  90.62 ( 89.03)\tAcc@5  99.22 ( 98.05)\n",
            "Epoch: [112][270/391]\tTime  0.172 ( 0.174)\tLoss 5.3807e-01 (3.9129e-01)\tAcc@1  86.72 ( 88.90)\tAcc@5  96.09 ( 98.02)\n",
            "Epoch: [112][300/391]\tTime  0.176 ( 0.174)\tLoss 4.4257e-01 (3.9472e-01)\tAcc@1  86.72 ( 88.82)\tAcc@5  97.66 ( 98.00)\n",
            "Epoch: [112][330/391]\tTime  0.174 ( 0.174)\tLoss 3.2752e-01 (3.9504e-01)\tAcc@1  90.62 ( 88.80)\tAcc@5  98.44 ( 98.02)\n",
            "Epoch: [112][360/391]\tTime  0.174 ( 0.174)\tLoss 3.3146e-01 (3.9540e-01)\tAcc@1  92.19 ( 88.81)\tAcc@5  99.22 ( 98.01)\n",
            "Epoch: [112][390/391]\tTime  0.155 ( 0.173)\tLoss 2.6893e-01 (3.9625e-01)\tAcc@1  91.25 ( 88.79)\tAcc@5  98.75 ( 97.99)\n",
            "==> Train Accuracy: Acc@1 88.786 || Acc@5 97.992\n",
            "==> Test Accuracy:  Acc@1 75.730 || Acc@5 94.020\n",
            "==> 72.17 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 113, lr: 0.004000000000000001 -----\n",
            "Epoch: [113][  0/391]\tTime  0.306 ( 0.306)\tLoss 2.2100e-01 (2.2100e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [113][ 30/391]\tTime  0.172 ( 0.177)\tLoss 3.2146e-01 (3.6040e-01)\tAcc@1  86.72 ( 90.27)\tAcc@5  99.22 ( 98.16)\n",
            "Epoch: [113][ 60/391]\tTime  0.173 ( 0.175)\tLoss 4.2424e-01 (3.7206e-01)\tAcc@1  87.50 ( 89.54)\tAcc@5  98.44 ( 98.17)\n",
            "Epoch: [113][ 90/391]\tTime  0.174 ( 0.175)\tLoss 4.4605e-01 (3.6867e-01)\tAcc@1  90.62 ( 89.71)\tAcc@5  94.53 ( 98.14)\n",
            "Epoch: [113][120/391]\tTime  0.171 ( 0.174)\tLoss 3.1811e-01 (3.7442e-01)\tAcc@1  89.84 ( 89.38)\tAcc@5  99.22 ( 98.17)\n",
            "Epoch: [113][150/391]\tTime  0.171 ( 0.174)\tLoss 3.3543e-01 (3.7778e-01)\tAcc@1  91.41 ( 89.25)\tAcc@5  98.44 ( 98.17)\n",
            "Epoch: [113][180/391]\tTime  0.172 ( 0.174)\tLoss 3.8856e-01 (3.8037e-01)\tAcc@1  87.50 ( 89.17)\tAcc@5  97.66 ( 98.17)\n",
            "Epoch: [113][210/391]\tTime  0.175 ( 0.174)\tLoss 4.0100e-01 (3.8118e-01)\tAcc@1  89.06 ( 89.17)\tAcc@5  99.22 ( 98.16)\n",
            "Epoch: [113][240/391]\tTime  0.175 ( 0.174)\tLoss 4.2814e-01 (3.8491e-01)\tAcc@1  88.28 ( 89.12)\tAcc@5  97.66 ( 98.10)\n",
            "Epoch: [113][270/391]\tTime  0.171 ( 0.174)\tLoss 3.0970e-01 (3.8520e-01)\tAcc@1  90.62 ( 89.08)\tAcc@5  98.44 ( 98.11)\n",
            "Epoch: [113][300/391]\tTime  0.173 ( 0.174)\tLoss 4.7208e-01 (3.8955e-01)\tAcc@1  87.50 ( 88.98)\tAcc@5  96.88 ( 98.06)\n",
            "Epoch: [113][330/391]\tTime  0.174 ( 0.174)\tLoss 4.2139e-01 (3.9115e-01)\tAcc@1  88.28 ( 88.89)\tAcc@5  97.66 ( 98.06)\n",
            "Epoch: [113][360/391]\tTime  0.175 ( 0.174)\tLoss 3.0730e-01 (3.9130e-01)\tAcc@1  89.84 ( 88.90)\tAcc@5  99.22 ( 98.05)\n",
            "Epoch: [113][390/391]\tTime  0.158 ( 0.174)\tLoss 4.3310e-01 (3.9268e-01)\tAcc@1  86.25 ( 88.85)\tAcc@5  97.50 ( 98.05)\n",
            "==> Train Accuracy: Acc@1 88.852 || Acc@5 98.052\n",
            "==> Test Accuracy:  Acc@1 75.340 || Acc@5 93.700\n",
            "==> 72.28 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 114, lr: 0.004000000000000001 -----\n",
            "Epoch: [114][  0/391]\tTime  0.290 ( 0.290)\tLoss 3.8009e-01 (3.8009e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [114][ 30/391]\tTime  0.173 ( 0.177)\tLoss 2.1545e-01 (3.3713e-01)\tAcc@1  94.53 ( 90.60)\tAcc@5  98.44 ( 98.36)\n",
            "Epoch: [114][ 60/391]\tTime  0.170 ( 0.175)\tLoss 4.6459e-01 (3.6924e-01)\tAcc@1  89.06 ( 89.59)\tAcc@5  96.88 ( 98.12)\n",
            "Epoch: [114][ 90/391]\tTime  0.172 ( 0.175)\tLoss 3.1928e-01 (3.6528e-01)\tAcc@1  91.41 ( 89.82)\tAcc@5  99.22 ( 98.15)\n",
            "Epoch: [114][120/391]\tTime  0.174 ( 0.174)\tLoss 5.0892e-01 (3.7294e-01)\tAcc@1  85.94 ( 89.63)\tAcc@5  97.66 ( 98.11)\n",
            "Epoch: [114][150/391]\tTime  0.173 ( 0.174)\tLoss 4.7222e-01 (3.7589e-01)\tAcc@1  85.94 ( 89.44)\tAcc@5  95.31 ( 98.09)\n",
            "Epoch: [114][180/391]\tTime  0.174 ( 0.174)\tLoss 3.2874e-01 (3.7268e-01)\tAcc@1  89.84 ( 89.47)\tAcc@5  97.66 ( 98.13)\n",
            "Epoch: [114][210/391]\tTime  0.177 ( 0.174)\tLoss 3.7415e-01 (3.7598e-01)\tAcc@1  90.62 ( 89.39)\tAcc@5  98.44 ( 98.09)\n",
            "Epoch: [114][240/391]\tTime  0.173 ( 0.174)\tLoss 4.5333e-01 (3.7960e-01)\tAcc@1  86.72 ( 89.29)\tAcc@5  97.66 ( 98.10)\n",
            "Epoch: [114][270/391]\tTime  0.175 ( 0.174)\tLoss 4.2749e-01 (3.8211e-01)\tAcc@1  89.06 ( 89.22)\tAcc@5  96.09 ( 98.09)\n",
            "Epoch: [114][300/391]\tTime  0.172 ( 0.174)\tLoss 3.2935e-01 (3.8226e-01)\tAcc@1  89.84 ( 89.20)\tAcc@5  98.44 ( 98.08)\n",
            "Epoch: [114][330/391]\tTime  0.172 ( 0.174)\tLoss 3.6674e-01 (3.8382e-01)\tAcc@1  87.50 ( 89.16)\tAcc@5  98.44 ( 98.07)\n",
            "Epoch: [114][360/391]\tTime  0.170 ( 0.174)\tLoss 3.5451e-01 (3.8684e-01)\tAcc@1  85.16 ( 89.09)\tAcc@5  99.22 ( 98.05)\n",
            "Epoch: [114][390/391]\tTime  0.154 ( 0.174)\tLoss 3.3197e-01 (3.8682e-01)\tAcc@1  93.75 ( 89.08)\tAcc@5  98.75 ( 98.08)\n",
            "==> Train Accuracy: Acc@1 89.078 || Acc@5 98.076\n",
            "==> Test Accuracy:  Acc@1 75.500 || Acc@5 93.650\n",
            "==> 72.20 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 115, lr: 0.004000000000000001 -----\n",
            "Epoch: [115][  0/391]\tTime  0.274 ( 0.274)\tLoss 2.5118e-01 (2.5118e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [115][ 30/391]\tTime  0.172 ( 0.175)\tLoss 3.1379e-01 (3.4830e-01)\tAcc@1  91.41 ( 90.47)\tAcc@5  97.66 ( 98.14)\n",
            "Epoch: [115][ 60/391]\tTime  0.173 ( 0.173)\tLoss 4.5749e-01 (3.5663e-01)\tAcc@1  88.28 ( 90.07)\tAcc@5  99.22 ( 98.21)\n",
            "Epoch: [115][ 90/391]\tTime  0.174 ( 0.173)\tLoss 3.4785e-01 (3.6964e-01)\tAcc@1  88.28 ( 89.78)\tAcc@5  99.22 ( 98.06)\n",
            "Epoch: [115][120/391]\tTime  0.172 ( 0.173)\tLoss 4.0047e-01 (3.7308e-01)\tAcc@1  87.50 ( 89.68)\tAcc@5  98.44 ( 98.11)\n",
            "Epoch: [115][150/391]\tTime  0.172 ( 0.173)\tLoss 2.4839e-01 (3.7382e-01)\tAcc@1  92.97 ( 89.71)\tAcc@5 100.00 ( 98.17)\n",
            "Epoch: [115][180/391]\tTime  0.175 ( 0.173)\tLoss 2.7824e-01 (3.7555e-01)\tAcc@1  95.31 ( 89.64)\tAcc@5  98.44 ( 98.16)\n",
            "Epoch: [115][210/391]\tTime  0.174 ( 0.173)\tLoss 3.4309e-01 (3.7526e-01)\tAcc@1  88.28 ( 89.60)\tAcc@5  99.22 ( 98.19)\n",
            "Epoch: [115][240/391]\tTime  0.173 ( 0.173)\tLoss 3.5402e-01 (3.7920e-01)\tAcc@1  91.41 ( 89.45)\tAcc@5  99.22 ( 98.19)\n",
            "Epoch: [115][270/391]\tTime  0.176 ( 0.173)\tLoss 3.7905e-01 (3.7996e-01)\tAcc@1  91.41 ( 89.40)\tAcc@5  97.66 ( 98.15)\n",
            "Epoch: [115][300/391]\tTime  0.172 ( 0.173)\tLoss 4.7368e-01 (3.8050e-01)\tAcc@1  85.16 ( 89.36)\tAcc@5  99.22 ( 98.18)\n",
            "Epoch: [115][330/391]\tTime  0.177 ( 0.174)\tLoss 5.9133e-01 (3.8352e-01)\tAcc@1  82.81 ( 89.28)\tAcc@5  96.88 ( 98.18)\n",
            "Epoch: [115][360/391]\tTime  0.173 ( 0.174)\tLoss 4.9824e-01 (3.8406e-01)\tAcc@1  83.59 ( 89.27)\tAcc@5  97.66 ( 98.19)\n",
            "Epoch: [115][390/391]\tTime  0.156 ( 0.173)\tLoss 3.0470e-01 (3.8693e-01)\tAcc@1  91.25 ( 89.17)\tAcc@5  98.75 ( 98.16)\n",
            "==> Train Accuracy: Acc@1 89.172 || Acc@5 98.158\n",
            "==> Test Accuracy:  Acc@1 75.790 || Acc@5 93.640\n",
            "==> 72.20 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 116, lr: 0.004000000000000001 -----\n",
            "Epoch: [116][  0/391]\tTime  0.277 ( 0.277)\tLoss 3.3690e-01 (3.3690e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [116][ 30/391]\tTime  0.174 ( 0.176)\tLoss 2.9691e-01 (3.6584e-01)\tAcc@1  89.84 ( 89.29)\tAcc@5 100.00 ( 98.36)\n",
            "Epoch: [116][ 60/391]\tTime  0.174 ( 0.175)\tLoss 3.7785e-01 (3.6630e-01)\tAcc@1  87.50 ( 89.54)\tAcc@5  98.44 ( 98.25)\n",
            "Epoch: [116][ 90/391]\tTime  0.173 ( 0.174)\tLoss 3.3236e-01 (3.6932e-01)\tAcc@1  90.62 ( 89.51)\tAcc@5  96.09 ( 98.15)\n",
            "Epoch: [116][120/391]\tTime  0.174 ( 0.174)\tLoss 5.3236e-01 (3.6689e-01)\tAcc@1  87.50 ( 89.64)\tAcc@5  95.31 ( 98.20)\n",
            "Epoch: [116][150/391]\tTime  0.173 ( 0.174)\tLoss 3.1124e-01 (3.6627e-01)\tAcc@1  92.97 ( 89.68)\tAcc@5  98.44 ( 98.23)\n",
            "Epoch: [116][180/391]\tTime  0.172 ( 0.174)\tLoss 4.5356e-01 (3.6843e-01)\tAcc@1  88.28 ( 89.63)\tAcc@5  98.44 ( 98.23)\n",
            "Epoch: [116][210/391]\tTime  0.175 ( 0.174)\tLoss 3.5921e-01 (3.7210e-01)\tAcc@1  92.19 ( 89.55)\tAcc@5  97.66 ( 98.22)\n",
            "Epoch: [116][240/391]\tTime  0.171 ( 0.173)\tLoss 3.6980e-01 (3.7143e-01)\tAcc@1  91.41 ( 89.52)\tAcc@5  98.44 ( 98.25)\n",
            "Epoch: [116][270/391]\tTime  0.176 ( 0.173)\tLoss 2.8231e-01 (3.7152e-01)\tAcc@1  90.62 ( 89.53)\tAcc@5 100.00 ( 98.25)\n",
            "Epoch: [116][300/391]\tTime  0.173 ( 0.173)\tLoss 3.1002e-01 (3.7507e-01)\tAcc@1  89.84 ( 89.46)\tAcc@5 100.00 ( 98.22)\n",
            "Epoch: [116][330/391]\tTime  0.172 ( 0.173)\tLoss 4.4367e-01 (3.7722e-01)\tAcc@1  85.94 ( 89.41)\tAcc@5  98.44 ( 98.23)\n",
            "Epoch: [116][360/391]\tTime  0.174 ( 0.173)\tLoss 3.6323e-01 (3.7803e-01)\tAcc@1  90.62 ( 89.40)\tAcc@5  96.88 ( 98.23)\n",
            "Epoch: [116][390/391]\tTime  0.156 ( 0.173)\tLoss 3.7288e-01 (3.7969e-01)\tAcc@1  82.50 ( 89.32)\tAcc@5  98.75 ( 98.21)\n",
            "==> Train Accuracy: Acc@1 89.318 || Acc@5 98.214\n",
            "==> Test Accuracy:  Acc@1 75.400 || Acc@5 93.660\n",
            "==> 72.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 117, lr: 0.004000000000000001 -----\n",
            "Epoch: [117][  0/391]\tTime  0.263 ( 0.263)\tLoss 2.7517e-01 (2.7517e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [117][ 30/391]\tTime  0.180 ( 0.176)\tLoss 4.5865e-01 (3.7514e-01)\tAcc@1  85.16 ( 89.31)\tAcc@5  97.66 ( 98.29)\n",
            "Epoch: [117][ 60/391]\tTime  0.171 ( 0.174)\tLoss 2.7538e-01 (3.6264e-01)\tAcc@1  91.41 ( 89.87)\tAcc@5  99.22 ( 98.26)\n",
            "Epoch: [117][ 90/391]\tTime  0.171 ( 0.174)\tLoss 4.5572e-01 (3.6480e-01)\tAcc@1  88.28 ( 89.73)\tAcc@5  96.88 ( 98.21)\n",
            "Epoch: [117][120/391]\tTime  0.171 ( 0.174)\tLoss 3.3148e-01 (3.6968e-01)\tAcc@1  89.84 ( 89.62)\tAcc@5  99.22 ( 98.21)\n",
            "Epoch: [117][150/391]\tTime  0.174 ( 0.174)\tLoss 5.2536e-01 (3.7546e-01)\tAcc@1  85.94 ( 89.51)\tAcc@5  97.66 ( 98.17)\n",
            "Epoch: [117][180/391]\tTime  0.175 ( 0.173)\tLoss 2.8609e-01 (3.7607e-01)\tAcc@1  92.97 ( 89.49)\tAcc@5  99.22 ( 98.20)\n",
            "Epoch: [117][210/391]\tTime  0.171 ( 0.173)\tLoss 4.7786e-01 (3.7594e-01)\tAcc@1  88.28 ( 89.50)\tAcc@5  95.31 ( 98.19)\n",
            "Epoch: [117][240/391]\tTime  0.174 ( 0.173)\tLoss 4.3620e-01 (3.7731e-01)\tAcc@1  87.50 ( 89.42)\tAcc@5  97.66 ( 98.18)\n",
            "Epoch: [117][270/391]\tTime  0.173 ( 0.173)\tLoss 3.1549e-01 (3.7824e-01)\tAcc@1  89.84 ( 89.33)\tAcc@5  99.22 ( 98.17)\n",
            "Epoch: [117][300/391]\tTime  0.173 ( 0.173)\tLoss 3.2162e-01 (3.8055e-01)\tAcc@1  90.62 ( 89.23)\tAcc@5 100.00 ( 98.14)\n",
            "Epoch: [117][330/391]\tTime  0.173 ( 0.173)\tLoss 4.6865e-01 (3.8184e-01)\tAcc@1  88.28 ( 89.25)\tAcc@5  98.44 ( 98.14)\n",
            "Epoch: [117][360/391]\tTime  0.175 ( 0.173)\tLoss 4.2121e-01 (3.8130e-01)\tAcc@1  85.94 ( 89.26)\tAcc@5  98.44 ( 98.16)\n",
            "Epoch: [117][390/391]\tTime  0.156 ( 0.173)\tLoss 4.1972e-01 (3.8162e-01)\tAcc@1  92.50 ( 89.22)\tAcc@5  96.25 ( 98.15)\n",
            "==> Train Accuracy: Acc@1 89.222 || Acc@5 98.154\n",
            "==> Test Accuracy:  Acc@1 75.650 || Acc@5 93.740\n",
            "==> 72.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 118, lr: 0.004000000000000001 -----\n",
            "Epoch: [118][  0/391]\tTime  0.266 ( 0.266)\tLoss 2.3205e-01 (2.3205e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [118][ 30/391]\tTime  0.174 ( 0.176)\tLoss 2.7340e-01 (3.5743e-01)\tAcc@1  95.31 ( 90.25)\tAcc@5  97.66 ( 97.96)\n",
            "Epoch: [118][ 60/391]\tTime  0.173 ( 0.175)\tLoss 3.1440e-01 (3.6838e-01)\tAcc@1  92.19 ( 89.96)\tAcc@5  99.22 ( 98.08)\n",
            "Epoch: [118][ 90/391]\tTime  0.173 ( 0.174)\tLoss 3.3688e-01 (3.7516e-01)\tAcc@1  89.06 ( 89.53)\tAcc@5  98.44 ( 98.15)\n",
            "Epoch: [118][120/391]\tTime  0.174 ( 0.174)\tLoss 2.9531e-01 (3.6882e-01)\tAcc@1  91.41 ( 89.79)\tAcc@5  97.66 ( 98.17)\n",
            "Epoch: [118][150/391]\tTime  0.172 ( 0.174)\tLoss 6.3182e-01 (3.6809e-01)\tAcc@1  82.81 ( 89.75)\tAcc@5  96.09 ( 98.19)\n",
            "Epoch: [118][180/391]\tTime  0.173 ( 0.174)\tLoss 5.2615e-01 (3.7082e-01)\tAcc@1  89.84 ( 89.73)\tAcc@5  96.88 ( 98.16)\n",
            "Epoch: [118][210/391]\tTime  0.173 ( 0.174)\tLoss 4.3149e-01 (3.7224e-01)\tAcc@1  89.84 ( 89.64)\tAcc@5  97.66 ( 98.14)\n",
            "Epoch: [118][240/391]\tTime  0.178 ( 0.174)\tLoss 3.5421e-01 (3.7282e-01)\tAcc@1  91.41 ( 89.56)\tAcc@5  99.22 ( 98.15)\n",
            "Epoch: [118][270/391]\tTime  0.174 ( 0.174)\tLoss 3.3863e-01 (3.7316e-01)\tAcc@1  89.84 ( 89.52)\tAcc@5  97.66 ( 98.12)\n",
            "Epoch: [118][300/391]\tTime  0.175 ( 0.174)\tLoss 4.5061e-01 (3.7531e-01)\tAcc@1  87.50 ( 89.44)\tAcc@5  98.44 ( 98.12)\n",
            "Epoch: [118][330/391]\tTime  0.174 ( 0.174)\tLoss 3.6317e-01 (3.7723e-01)\tAcc@1  89.06 ( 89.34)\tAcc@5  97.66 ( 98.11)\n",
            "Epoch: [118][360/391]\tTime  0.175 ( 0.174)\tLoss 3.6675e-01 (3.8104e-01)\tAcc@1  87.50 ( 89.23)\tAcc@5  98.44 ( 98.06)\n",
            "Epoch: [118][390/391]\tTime  0.156 ( 0.174)\tLoss 3.8518e-01 (3.8259e-01)\tAcc@1  88.75 ( 89.15)\tAcc@5  98.75 ( 98.07)\n",
            "==> Train Accuracy: Acc@1 89.152 || Acc@5 98.070\n",
            "==> Test Accuracy:  Acc@1 75.360 || Acc@5 93.300\n",
            "==> 72.23 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 119, lr: 0.004000000000000001 -----\n",
            "Epoch: [119][  0/391]\tTime  0.286 ( 0.286)\tLoss 4.2330e-01 (4.2330e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [119][ 30/391]\tTime  0.172 ( 0.177)\tLoss 3.1310e-01 (3.5980e-01)\tAcc@1  92.19 ( 89.64)\tAcc@5  98.44 ( 98.34)\n",
            "Epoch: [119][ 60/391]\tTime  0.172 ( 0.175)\tLoss 4.4128e-01 (3.5867e-01)\tAcc@1  89.06 ( 89.54)\tAcc@5  97.66 ( 98.46)\n",
            "Epoch: [119][ 90/391]\tTime  0.175 ( 0.175)\tLoss 3.1993e-01 (3.6576e-01)\tAcc@1  89.84 ( 89.58)\tAcc@5  97.66 ( 98.21)\n",
            "Epoch: [119][120/391]\tTime  0.175 ( 0.174)\tLoss 3.5252e-01 (3.6389e-01)\tAcc@1  90.62 ( 89.72)\tAcc@5  99.22 ( 98.26)\n",
            "Epoch: [119][150/391]\tTime  0.171 ( 0.174)\tLoss 4.0159e-01 (3.6979e-01)\tAcc@1  86.72 ( 89.66)\tAcc@5  98.44 ( 98.18)\n",
            "Epoch: [119][180/391]\tTime  0.174 ( 0.174)\tLoss 5.8953e-01 (3.7136e-01)\tAcc@1  85.94 ( 89.69)\tAcc@5  94.53 ( 98.12)\n",
            "Epoch: [119][210/391]\tTime  0.177 ( 0.174)\tLoss 3.7827e-01 (3.6909e-01)\tAcc@1  92.19 ( 89.73)\tAcc@5  96.88 ( 98.19)\n",
            "Epoch: [119][240/391]\tTime  0.174 ( 0.174)\tLoss 3.3603e-01 (3.6911e-01)\tAcc@1  89.84 ( 89.73)\tAcc@5  99.22 ( 98.20)\n",
            "Epoch: [119][270/391]\tTime  0.175 ( 0.174)\tLoss 4.6887e-01 (3.6835e-01)\tAcc@1  85.16 ( 89.81)\tAcc@5  96.88 ( 98.26)\n",
            "Epoch: [119][300/391]\tTime  0.174 ( 0.174)\tLoss 3.8728e-01 (3.6909e-01)\tAcc@1  88.28 ( 89.77)\tAcc@5  99.22 ( 98.25)\n",
            "Epoch: [119][330/391]\tTime  0.175 ( 0.174)\tLoss 2.7755e-01 (3.6958e-01)\tAcc@1  92.97 ( 89.76)\tAcc@5  97.66 ( 98.25)\n",
            "Epoch: [119][360/391]\tTime  0.174 ( 0.174)\tLoss 4.9217e-01 (3.7167e-01)\tAcc@1  84.38 ( 89.68)\tAcc@5  96.88 ( 98.23)\n",
            "Epoch: [119][390/391]\tTime  0.158 ( 0.174)\tLoss 4.8024e-01 (3.7263e-01)\tAcc@1  85.00 ( 89.66)\tAcc@5  98.75 ( 98.24)\n",
            "==> Train Accuracy: Acc@1 89.660 || Acc@5 98.238\n",
            "==> Test Accuracy:  Acc@1 75.820 || Acc@5 93.610\n",
            "==> 72.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 120, lr: 0.0008000000000000003 -----\n",
            "Epoch: [120][  0/391]\tTime  0.271 ( 0.271)\tLoss 2.7585e-01 (2.7585e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [120][ 30/391]\tTime  0.174 ( 0.176)\tLoss 3.1476e-01 (3.2739e-01)\tAcc@1  92.19 ( 91.10)\tAcc@5  98.44 ( 98.41)\n",
            "Epoch: [120][ 60/391]\tTime  0.174 ( 0.175)\tLoss 4.2841e-01 (3.3422e-01)\tAcc@1  86.72 ( 90.61)\tAcc@5  97.66 ( 98.37)\n",
            "Epoch: [120][ 90/391]\tTime  0.173 ( 0.174)\tLoss 3.6398e-01 (3.2915e-01)\tAcc@1  89.84 ( 90.81)\tAcc@5  99.22 ( 98.38)\n",
            "Epoch: [120][120/391]\tTime  0.172 ( 0.174)\tLoss 4.0412e-01 (3.2981e-01)\tAcc@1  89.84 ( 90.86)\tAcc@5  96.88 ( 98.37)\n",
            "Epoch: [120][150/391]\tTime  0.173 ( 0.174)\tLoss 2.5369e-01 (3.2569e-01)\tAcc@1  93.75 ( 90.96)\tAcc@5 100.00 ( 98.46)\n",
            "Epoch: [120][180/391]\tTime  0.173 ( 0.174)\tLoss 3.1941e-01 (3.2743e-01)\tAcc@1  92.19 ( 90.88)\tAcc@5  99.22 ( 98.45)\n",
            "Epoch: [120][210/391]\tTime  0.172 ( 0.174)\tLoss 2.4379e-01 (3.2557e-01)\tAcc@1  92.19 ( 90.95)\tAcc@5  99.22 ( 98.45)\n",
            "Epoch: [120][240/391]\tTime  0.173 ( 0.174)\tLoss 3.5100e-01 (3.2236e-01)\tAcc@1  89.84 ( 91.04)\tAcc@5  97.66 ( 98.48)\n",
            "Epoch: [120][270/391]\tTime  0.175 ( 0.174)\tLoss 2.9439e-01 (3.1932e-01)\tAcc@1  93.75 ( 91.14)\tAcc@5  99.22 ( 98.50)\n",
            "Epoch: [120][300/391]\tTime  0.174 ( 0.173)\tLoss 2.3459e-01 (3.1762e-01)\tAcc@1  94.53 ( 91.21)\tAcc@5  98.44 ( 98.51)\n",
            "Epoch: [120][330/391]\tTime  0.174 ( 0.173)\tLoss 2.5887e-01 (3.1524e-01)\tAcc@1  93.75 ( 91.32)\tAcc@5  97.66 ( 98.56)\n",
            "Epoch: [120][360/391]\tTime  0.171 ( 0.173)\tLoss 2.6660e-01 (3.1465e-01)\tAcc@1  93.75 ( 91.33)\tAcc@5  99.22 ( 98.54)\n",
            "Epoch: [120][390/391]\tTime  0.155 ( 0.173)\tLoss 3.1205e-01 (3.1263e-01)\tAcc@1  93.75 ( 91.37)\tAcc@5  98.75 ( 98.55)\n",
            "==> Train Accuracy: Acc@1 91.374 || Acc@5 98.552\n",
            "==> Test Accuracy:  Acc@1 76.900 || Acc@5 94.030\n",
            "==> 72.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 121, lr: 0.0008000000000000003 -----\n",
            "Epoch: [121][  0/391]\tTime  0.263 ( 0.263)\tLoss 2.4690e-01 (2.4690e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [121][ 30/391]\tTime  0.172 ( 0.176)\tLoss 3.1149e-01 (2.9265e-01)\tAcc@1  92.19 ( 92.09)\tAcc@5  97.66 ( 98.46)\n",
            "Epoch: [121][ 60/391]\tTime  0.174 ( 0.174)\tLoss 3.2461e-01 (2.9430e-01)\tAcc@1  89.84 ( 91.91)\tAcc@5  96.88 ( 98.57)\n",
            "Epoch: [121][ 90/391]\tTime  0.173 ( 0.174)\tLoss 3.6915e-01 (2.9293e-01)\tAcc@1  89.06 ( 91.84)\tAcc@5  97.66 ( 98.59)\n",
            "Epoch: [121][120/391]\tTime  0.172 ( 0.174)\tLoss 1.9000e-01 (2.9501e-01)\tAcc@1  94.53 ( 91.78)\tAcc@5 100.00 ( 98.64)\n",
            "Epoch: [121][150/391]\tTime  0.175 ( 0.173)\tLoss 2.1758e-01 (2.9926e-01)\tAcc@1  92.19 ( 91.69)\tAcc@5  99.22 ( 98.53)\n",
            "Epoch: [121][180/391]\tTime  0.173 ( 0.173)\tLoss 3.0507e-01 (2.9502e-01)\tAcc@1  94.53 ( 91.81)\tAcc@5  98.44 ( 98.55)\n",
            "Epoch: [121][210/391]\tTime  0.172 ( 0.173)\tLoss 3.1968e-01 (2.9501e-01)\tAcc@1  91.41 ( 91.80)\tAcc@5  99.22 ( 98.57)\n",
            "Epoch: [121][240/391]\tTime  0.173 ( 0.173)\tLoss 2.8272e-01 (2.9336e-01)\tAcc@1  91.41 ( 91.89)\tAcc@5  98.44 ( 98.57)\n",
            "Epoch: [121][270/391]\tTime  0.172 ( 0.173)\tLoss 2.0718e-01 (2.8900e-01)\tAcc@1  91.41 ( 92.03)\tAcc@5 100.00 ( 98.61)\n",
            "Epoch: [121][300/391]\tTime  0.172 ( 0.173)\tLoss 2.8405e-01 (2.8767e-01)\tAcc@1  92.19 ( 92.09)\tAcc@5  97.66 ( 98.60)\n",
            "Epoch: [121][330/391]\tTime  0.174 ( 0.173)\tLoss 2.1023e-01 (2.8570e-01)\tAcc@1  95.31 ( 92.18)\tAcc@5 100.00 ( 98.61)\n",
            "Epoch: [121][360/391]\tTime  0.172 ( 0.173)\tLoss 1.8983e-01 (2.8405e-01)\tAcc@1  93.75 ( 92.20)\tAcc@5 100.00 ( 98.65)\n",
            "Epoch: [121][390/391]\tTime  0.159 ( 0.173)\tLoss 3.6671e-01 (2.8555e-01)\tAcc@1  88.75 ( 92.14)\tAcc@5  98.75 ( 98.66)\n",
            "==> Train Accuracy: Acc@1 92.140 || Acc@5 98.656\n",
            "==> Test Accuracy:  Acc@1 77.100 || Acc@5 93.870\n",
            "==> 72.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 122, lr: 0.0008000000000000003 -----\n",
            "Epoch: [122][  0/391]\tTime  0.257 ( 0.257)\tLoss 2.5405e-01 (2.5405e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [122][ 30/391]\tTime  0.174 ( 0.176)\tLoss 3.1927e-01 (2.7798e-01)\tAcc@1  90.62 ( 91.81)\tAcc@5  97.66 ( 98.82)\n",
            "Epoch: [122][ 60/391]\tTime  0.173 ( 0.174)\tLoss 2.2319e-01 (2.6857e-01)\tAcc@1  92.97 ( 92.47)\tAcc@5  99.22 ( 98.96)\n",
            "Epoch: [122][ 90/391]\tTime  0.174 ( 0.174)\tLoss 2.8815e-01 (2.7194e-01)\tAcc@1  92.97 ( 92.56)\tAcc@5  97.66 ( 98.88)\n",
            "Epoch: [122][120/391]\tTime  0.174 ( 0.173)\tLoss 2.3592e-01 (2.6843e-01)\tAcc@1  95.31 ( 92.69)\tAcc@5  99.22 ( 98.88)\n",
            "Epoch: [122][150/391]\tTime  0.176 ( 0.173)\tLoss 3.0996e-01 (2.6930e-01)\tAcc@1  92.19 ( 92.70)\tAcc@5  98.44 ( 98.83)\n",
            "Epoch: [122][180/391]\tTime  0.173 ( 0.173)\tLoss 1.8045e-01 (2.6702e-01)\tAcc@1  93.75 ( 92.78)\tAcc@5 100.00 ( 98.82)\n",
            "Epoch: [122][210/391]\tTime  0.175 ( 0.173)\tLoss 2.5527e-01 (2.7212e-01)\tAcc@1  91.41 ( 92.61)\tAcc@5  99.22 ( 98.77)\n",
            "Epoch: [122][240/391]\tTime  0.173 ( 0.173)\tLoss 3.0609e-01 (2.7193e-01)\tAcc@1  92.19 ( 92.62)\tAcc@5  98.44 ( 98.75)\n",
            "Epoch: [122][270/391]\tTime  0.172 ( 0.173)\tLoss 3.4010e-01 (2.7184e-01)\tAcc@1  94.53 ( 92.65)\tAcc@5  97.66 ( 98.72)\n",
            "Epoch: [122][300/391]\tTime  0.172 ( 0.173)\tLoss 3.1858e-01 (2.7144e-01)\tAcc@1  90.62 ( 92.65)\tAcc@5  98.44 ( 98.74)\n",
            "Epoch: [122][330/391]\tTime  0.175 ( 0.173)\tLoss 2.7800e-01 (2.6992e-01)\tAcc@1  91.41 ( 92.69)\tAcc@5  97.66 ( 98.75)\n",
            "Epoch: [122][360/391]\tTime  0.175 ( 0.173)\tLoss 3.2434e-01 (2.6995e-01)\tAcc@1  91.41 ( 92.70)\tAcc@5  98.44 ( 98.75)\n",
            "Epoch: [122][390/391]\tTime  0.158 ( 0.173)\tLoss 2.2425e-01 (2.6893e-01)\tAcc@1  93.75 ( 92.74)\tAcc@5  98.75 ( 98.75)\n",
            "==> Train Accuracy: Acc@1 92.742 || Acc@5 98.750\n",
            "==> Test Accuracy:  Acc@1 77.090 || Acc@5 94.060\n",
            "==> 72.04 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 123, lr: 0.0008000000000000003 -----\n",
            "Epoch: [123][  0/391]\tTime  0.267 ( 0.267)\tLoss 2.4921e-01 (2.4921e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [123][ 30/391]\tTime  0.176 ( 0.176)\tLoss 2.9206e-01 (2.6595e-01)\tAcc@1  91.41 ( 92.72)\tAcc@5  99.22 ( 98.64)\n",
            "Epoch: [123][ 60/391]\tTime  0.172 ( 0.175)\tLoss 3.6793e-01 (2.6714e-01)\tAcc@1  86.72 ( 92.71)\tAcc@5  98.44 ( 98.68)\n",
            "Epoch: [123][ 90/391]\tTime  0.175 ( 0.174)\tLoss 2.5457e-01 (2.6537e-01)\tAcc@1  92.97 ( 92.76)\tAcc@5  99.22 ( 98.75)\n",
            "Epoch: [123][120/391]\tTime  0.173 ( 0.174)\tLoss 2.4678e-01 (2.6292e-01)\tAcc@1  93.75 ( 92.85)\tAcc@5  99.22 ( 98.75)\n",
            "Epoch: [123][150/391]\tTime  0.174 ( 0.174)\tLoss 1.5774e-01 (2.6644e-01)\tAcc@1  95.31 ( 92.80)\tAcc@5  99.22 ( 98.73)\n",
            "Epoch: [123][180/391]\tTime  0.171 ( 0.174)\tLoss 3.0368e-01 (2.6311e-01)\tAcc@1  93.75 ( 92.90)\tAcc@5  98.44 ( 98.75)\n",
            "Epoch: [123][210/391]\tTime  0.172 ( 0.174)\tLoss 2.9312e-01 (2.6397e-01)\tAcc@1  91.41 ( 92.98)\tAcc@5  98.44 ( 98.72)\n",
            "Epoch: [123][240/391]\tTime  0.177 ( 0.174)\tLoss 2.0637e-01 (2.6301e-01)\tAcc@1  92.97 ( 93.05)\tAcc@5 100.00 ( 98.70)\n",
            "Epoch: [123][270/391]\tTime  0.172 ( 0.174)\tLoss 2.9558e-01 (2.6301e-01)\tAcc@1  92.19 ( 93.05)\tAcc@5  97.66 ( 98.72)\n",
            "Epoch: [123][300/391]\tTime  0.174 ( 0.174)\tLoss 2.6661e-01 (2.6355e-01)\tAcc@1  91.41 ( 93.05)\tAcc@5  99.22 ( 98.71)\n",
            "Epoch: [123][330/391]\tTime  0.174 ( 0.174)\tLoss 3.0948e-01 (2.6394e-01)\tAcc@1  93.75 ( 93.00)\tAcc@5  96.88 ( 98.72)\n",
            "Epoch: [123][360/391]\tTime  0.174 ( 0.174)\tLoss 1.6794e-01 (2.6375e-01)\tAcc@1  96.09 ( 93.02)\tAcc@5  99.22 ( 98.69)\n",
            "Epoch: [123][390/391]\tTime  0.156 ( 0.173)\tLoss 2.3908e-01 (2.6423e-01)\tAcc@1  90.00 ( 93.00)\tAcc@5 100.00 ( 98.68)\n",
            "==> Train Accuracy: Acc@1 93.000 || Acc@5 98.684\n",
            "==> Test Accuracy:  Acc@1 77.340 || Acc@5 94.080\n",
            "==> 72.18 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 124, lr: 0.0008000000000000003 -----\n",
            "Epoch: [124][  0/391]\tTime  0.258 ( 0.258)\tLoss 2.5317e-01 (2.5317e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [124][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.5839e-01 (2.5873e-01)\tAcc@1  96.09 ( 93.27)\tAcc@5 100.00 ( 98.77)\n",
            "Epoch: [124][ 60/391]\tTime  0.179 ( 0.175)\tLoss 1.8144e-01 (2.5462e-01)\tAcc@1  94.53 ( 93.38)\tAcc@5 100.00 ( 98.71)\n",
            "Epoch: [124][ 90/391]\tTime  0.174 ( 0.174)\tLoss 3.5450e-01 (2.6240e-01)\tAcc@1  90.62 ( 93.13)\tAcc@5  96.09 ( 98.70)\n",
            "Epoch: [124][120/391]\tTime  0.173 ( 0.174)\tLoss 1.7992e-01 (2.6574e-01)\tAcc@1  94.53 ( 93.02)\tAcc@5 100.00 ( 98.70)\n",
            "Epoch: [124][150/391]\tTime  0.173 ( 0.174)\tLoss 3.4803e-01 (2.6633e-01)\tAcc@1  91.41 ( 92.99)\tAcc@5  98.44 ( 98.71)\n",
            "Epoch: [124][180/391]\tTime  0.173 ( 0.174)\tLoss 3.6186e-01 (2.6572e-01)\tAcc@1  89.06 ( 92.98)\tAcc@5  97.66 ( 98.70)\n",
            "Epoch: [124][210/391]\tTime  0.173 ( 0.174)\tLoss 2.6386e-01 (2.6606e-01)\tAcc@1  93.75 ( 92.98)\tAcc@5  98.44 ( 98.70)\n",
            "Epoch: [124][240/391]\tTime  0.175 ( 0.174)\tLoss 2.5145e-01 (2.6554e-01)\tAcc@1  92.97 ( 92.95)\tAcc@5  99.22 ( 98.73)\n",
            "Epoch: [124][270/391]\tTime  0.173 ( 0.174)\tLoss 2.2255e-01 (2.6343e-01)\tAcc@1  93.75 ( 93.01)\tAcc@5  99.22 ( 98.74)\n",
            "Epoch: [124][300/391]\tTime  0.175 ( 0.174)\tLoss 3.3669e-01 (2.6285e-01)\tAcc@1  90.62 ( 93.05)\tAcc@5  97.66 ( 98.72)\n",
            "Epoch: [124][330/391]\tTime  0.174 ( 0.174)\tLoss 2.1579e-01 (2.6045e-01)\tAcc@1  93.75 ( 93.11)\tAcc@5  99.22 ( 98.76)\n",
            "Epoch: [124][360/391]\tTime  0.171 ( 0.174)\tLoss 2.7627e-01 (2.5935e-01)\tAcc@1  94.53 ( 93.13)\tAcc@5  98.44 ( 98.78)\n",
            "Epoch: [124][390/391]\tTime  0.157 ( 0.174)\tLoss 2.8530e-01 (2.5957e-01)\tAcc@1  93.75 ( 93.10)\tAcc@5  97.50 ( 98.79)\n",
            "==> Train Accuracy: Acc@1 93.102 || Acc@5 98.794\n",
            "==> Test Accuracy:  Acc@1 77.300 || Acc@5 94.190\n",
            "==> 72.19 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 125, lr: 0.0008000000000000003 -----\n",
            "Epoch: [125][  0/391]\tTime  0.250 ( 0.250)\tLoss 2.2019e-01 (2.2019e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [125][ 30/391]\tTime  0.177 ( 0.176)\tLoss 3.0739e-01 (2.5951e-01)\tAcc@1  93.75 ( 92.92)\tAcc@5  96.09 ( 98.66)\n",
            "Epoch: [125][ 60/391]\tTime  0.174 ( 0.175)\tLoss 2.0609e-01 (2.5654e-01)\tAcc@1  93.75 ( 92.87)\tAcc@5  99.22 ( 98.78)\n",
            "Epoch: [125][ 90/391]\tTime  0.173 ( 0.174)\tLoss 2.6708e-01 (2.6148e-01)\tAcc@1  92.19 ( 92.98)\tAcc@5  97.66 ( 98.70)\n",
            "Epoch: [125][120/391]\tTime  0.174 ( 0.174)\tLoss 2.4381e-01 (2.6109e-01)\tAcc@1  94.53 ( 92.98)\tAcc@5  97.66 ( 98.79)\n",
            "Epoch: [125][150/391]\tTime  0.173 ( 0.174)\tLoss 1.5488e-01 (2.5745e-01)\tAcc@1  96.09 ( 93.12)\tAcc@5 100.00 ( 98.83)\n",
            "Epoch: [125][180/391]\tTime  0.173 ( 0.174)\tLoss 2.2214e-01 (2.5707e-01)\tAcc@1  93.75 ( 93.08)\tAcc@5  97.66 ( 98.80)\n",
            "Epoch: [125][210/391]\tTime  0.174 ( 0.174)\tLoss 2.1739e-01 (2.5287e-01)\tAcc@1  94.53 ( 93.17)\tAcc@5  98.44 ( 98.83)\n",
            "Epoch: [125][240/391]\tTime  0.172 ( 0.174)\tLoss 2.3993e-01 (2.5363e-01)\tAcc@1  92.97 ( 93.18)\tAcc@5 100.00 ( 98.83)\n",
            "Epoch: [125][270/391]\tTime  0.181 ( 0.174)\tLoss 1.9058e-01 (2.5182e-01)\tAcc@1  95.31 ( 93.22)\tAcc@5  98.44 ( 98.84)\n",
            "Epoch: [125][300/391]\tTime  0.171 ( 0.174)\tLoss 2.8610e-01 (2.5286e-01)\tAcc@1  92.19 ( 93.25)\tAcc@5  98.44 ( 98.82)\n",
            "Epoch: [125][330/391]\tTime  0.174 ( 0.174)\tLoss 1.1677e-01 (2.5239e-01)\tAcc@1  96.09 ( 93.28)\tAcc@5 100.00 ( 98.80)\n",
            "Epoch: [125][360/391]\tTime  0.173 ( 0.174)\tLoss 2.1161e-01 (2.5149e-01)\tAcc@1  94.53 ( 93.30)\tAcc@5  99.22 ( 98.81)\n",
            "Epoch: [125][390/391]\tTime  0.156 ( 0.174)\tLoss 1.6285e-01 (2.5149e-01)\tAcc@1  95.00 ( 93.28)\tAcc@5 100.00 ( 98.82)\n",
            "==> Train Accuracy: Acc@1 93.278 || Acc@5 98.824\n",
            "==> Test Accuracy:  Acc@1 76.980 || Acc@5 93.780\n",
            "==> 72.20 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 126, lr: 0.0008000000000000003 -----\n",
            "Epoch: [126][  0/391]\tTime  0.281 ( 0.281)\tLoss 2.9641e-01 (2.9641e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [126][ 30/391]\tTime  0.168 ( 0.176)\tLoss 2.2928e-01 (2.4129e-01)\tAcc@1  94.53 ( 93.45)\tAcc@5  99.22 ( 99.04)\n",
            "Epoch: [126][ 60/391]\tTime  0.171 ( 0.175)\tLoss 1.7847e-01 (2.3202e-01)\tAcc@1  96.09 ( 93.67)\tAcc@5 100.00 ( 99.03)\n",
            "Epoch: [126][ 90/391]\tTime  0.174 ( 0.174)\tLoss 2.8424e-01 (2.4205e-01)\tAcc@1  92.19 ( 93.36)\tAcc@5 100.00 ( 98.98)\n",
            "Epoch: [126][120/391]\tTime  0.172 ( 0.174)\tLoss 2.1257e-01 (2.3390e-01)\tAcc@1  94.53 ( 93.62)\tAcc@5  99.22 ( 99.01)\n",
            "Epoch: [126][150/391]\tTime  0.174 ( 0.174)\tLoss 3.3450e-01 (2.3430e-01)\tAcc@1  92.19 ( 93.64)\tAcc@5  97.66 ( 98.98)\n",
            "Epoch: [126][180/391]\tTime  0.174 ( 0.174)\tLoss 1.6242e-01 (2.3510e-01)\tAcc@1  96.88 ( 93.60)\tAcc@5  99.22 ( 98.98)\n",
            "Epoch: [126][210/391]\tTime  0.174 ( 0.174)\tLoss 2.3575e-01 (2.3476e-01)\tAcc@1  94.53 ( 93.60)\tAcc@5  97.66 ( 98.97)\n",
            "Epoch: [126][240/391]\tTime  0.172 ( 0.174)\tLoss 2.7027e-01 (2.3799e-01)\tAcc@1  92.97 ( 93.57)\tAcc@5  98.44 ( 98.95)\n",
            "Epoch: [126][270/391]\tTime  0.172 ( 0.174)\tLoss 3.9013e-01 (2.3995e-01)\tAcc@1  86.72 ( 93.53)\tAcc@5  97.66 ( 98.93)\n",
            "Epoch: [126][300/391]\tTime  0.173 ( 0.174)\tLoss 3.7356e-01 (2.4242e-01)\tAcc@1  88.28 ( 93.49)\tAcc@5  98.44 ( 98.90)\n",
            "Epoch: [126][330/391]\tTime  0.173 ( 0.174)\tLoss 2.2639e-01 (2.4113e-01)\tAcc@1  92.97 ( 93.55)\tAcc@5 100.00 ( 98.91)\n",
            "Epoch: [126][360/391]\tTime  0.172 ( 0.174)\tLoss 2.0536e-01 (2.4089e-01)\tAcc@1  94.53 ( 93.57)\tAcc@5 100.00 ( 98.92)\n",
            "Epoch: [126][390/391]\tTime  0.157 ( 0.174)\tLoss 1.7921e-01 (2.4228e-01)\tAcc@1  97.50 ( 93.54)\tAcc@5 100.00 ( 98.90)\n",
            "==> Train Accuracy: Acc@1 93.540 || Acc@5 98.900\n",
            "==> Test Accuracy:  Acc@1 77.130 || Acc@5 93.840\n",
            "==> 72.23 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 127, lr: 0.0008000000000000003 -----\n",
            "Epoch: [127][  0/391]\tTime  0.254 ( 0.254)\tLoss 2.7116e-01 (2.7116e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [127][ 30/391]\tTime  0.174 ( 0.176)\tLoss 2.4152e-01 (2.4935e-01)\tAcc@1  94.53 ( 93.78)\tAcc@5  98.44 ( 98.51)\n",
            "Epoch: [127][ 60/391]\tTime  0.175 ( 0.175)\tLoss 3.0497e-01 (2.4747e-01)\tAcc@1  93.75 ( 93.70)\tAcc@5  97.66 ( 98.66)\n",
            "Epoch: [127][ 90/391]\tTime  0.176 ( 0.175)\tLoss 2.0009e-01 (2.4487e-01)\tAcc@1  92.97 ( 93.64)\tAcc@5 100.00 ( 98.78)\n",
            "Epoch: [127][120/391]\tTime  0.175 ( 0.174)\tLoss 1.2588e-01 (2.5309e-01)\tAcc@1  96.88 ( 93.34)\tAcc@5 100.00 ( 98.72)\n",
            "Epoch: [127][150/391]\tTime  0.173 ( 0.174)\tLoss 1.9069e-01 (2.5324e-01)\tAcc@1  94.53 ( 93.29)\tAcc@5  99.22 ( 98.70)\n",
            "Epoch: [127][180/391]\tTime  0.176 ( 0.174)\tLoss 1.6992e-01 (2.5032e-01)\tAcc@1  96.09 ( 93.34)\tAcc@5 100.00 ( 98.74)\n",
            "Epoch: [127][210/391]\tTime  0.173 ( 0.174)\tLoss 2.8799e-01 (2.4915e-01)\tAcc@1  91.41 ( 93.39)\tAcc@5  98.44 ( 98.76)\n",
            "Epoch: [127][240/391]\tTime  0.174 ( 0.174)\tLoss 2.4722e-01 (2.4988e-01)\tAcc@1  94.53 ( 93.36)\tAcc@5  97.66 ( 98.75)\n",
            "Epoch: [127][270/391]\tTime  0.173 ( 0.174)\tLoss 2.2428e-01 (2.4960e-01)\tAcc@1  93.75 ( 93.33)\tAcc@5  99.22 ( 98.75)\n",
            "Epoch: [127][300/391]\tTime  0.173 ( 0.174)\tLoss 3.4094e-01 (2.4932e-01)\tAcc@1  89.06 ( 93.35)\tAcc@5  96.09 ( 98.76)\n",
            "Epoch: [127][330/391]\tTime  0.174 ( 0.174)\tLoss 1.9635e-01 (2.5012e-01)\tAcc@1  94.53 ( 93.30)\tAcc@5  99.22 ( 98.76)\n",
            "Epoch: [127][360/391]\tTime  0.173 ( 0.174)\tLoss 1.8602e-01 (2.5060e-01)\tAcc@1  94.53 ( 93.32)\tAcc@5  99.22 ( 98.73)\n",
            "Epoch: [127][390/391]\tTime  0.155 ( 0.174)\tLoss 2.2935e-01 (2.5025e-01)\tAcc@1  95.00 ( 93.33)\tAcc@5  98.75 ( 98.74)\n",
            "==> Train Accuracy: Acc@1 93.326 || Acc@5 98.738\n",
            "==> Test Accuracy:  Acc@1 77.200 || Acc@5 93.920\n",
            "==> 72.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 128, lr: 0.0008000000000000003 -----\n",
            "Epoch: [128][  0/391]\tTime  0.262 ( 0.262)\tLoss 3.2759e-01 (3.2759e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [128][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.8556e-01 (2.5488e-01)\tAcc@1  94.53 ( 93.50)\tAcc@5  99.22 ( 98.46)\n",
            "Epoch: [128][ 60/391]\tTime  0.174 ( 0.175)\tLoss 2.6017e-01 (2.4920e-01)\tAcc@1  93.75 ( 93.63)\tAcc@5  99.22 ( 98.73)\n",
            "Epoch: [128][ 90/391]\tTime  0.172 ( 0.174)\tLoss 2.2192e-01 (2.4311e-01)\tAcc@1  94.53 ( 93.66)\tAcc@5 100.00 ( 98.78)\n",
            "Epoch: [128][120/391]\tTime  0.177 ( 0.174)\tLoss 1.6436e-01 (2.4039e-01)\tAcc@1  96.09 ( 93.69)\tAcc@5  99.22 ( 98.82)\n",
            "Epoch: [128][150/391]\tTime  0.174 ( 0.174)\tLoss 1.8408e-01 (2.3759e-01)\tAcc@1  96.09 ( 93.77)\tAcc@5 100.00 ( 98.88)\n",
            "Epoch: [128][180/391]\tTime  0.174 ( 0.174)\tLoss 1.8472e-01 (2.3672e-01)\tAcc@1  95.31 ( 93.77)\tAcc@5  99.22 ( 98.90)\n",
            "Epoch: [128][210/391]\tTime  0.173 ( 0.174)\tLoss 3.1221e-01 (2.3931e-01)\tAcc@1  92.19 ( 93.74)\tAcc@5  96.09 ( 98.88)\n",
            "Epoch: [128][240/391]\tTime  0.172 ( 0.174)\tLoss 2.0217e-01 (2.3874e-01)\tAcc@1  93.75 ( 93.73)\tAcc@5  99.22 ( 98.90)\n",
            "Epoch: [128][270/391]\tTime  0.174 ( 0.174)\tLoss 2.9768e-01 (2.4076e-01)\tAcc@1  90.62 ( 93.68)\tAcc@5  99.22 ( 98.90)\n",
            "Epoch: [128][300/391]\tTime  0.176 ( 0.174)\tLoss 1.5574e-01 (2.3951e-01)\tAcc@1  96.88 ( 93.73)\tAcc@5  99.22 ( 98.92)\n",
            "Epoch: [128][330/391]\tTime  0.177 ( 0.174)\tLoss 2.4491e-01 (2.3746e-01)\tAcc@1  94.53 ( 93.78)\tAcc@5  99.22 ( 98.93)\n",
            "Epoch: [128][360/391]\tTime  0.175 ( 0.174)\tLoss 2.0173e-01 (2.3810e-01)\tAcc@1  95.31 ( 93.76)\tAcc@5 100.00 ( 98.92)\n",
            "Epoch: [128][390/391]\tTime  0.155 ( 0.174)\tLoss 2.4027e-01 (2.3662e-01)\tAcc@1  95.00 ( 93.79)\tAcc@5 100.00 ( 98.94)\n",
            "==> Train Accuracy: Acc@1 93.794 || Acc@5 98.944\n",
            "==> Test Accuracy:  Acc@1 77.370 || Acc@5 94.080\n",
            "==> 72.31 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 129, lr: 0.0008000000000000003 -----\n",
            "Epoch: [129][  0/391]\tTime  0.269 ( 0.269)\tLoss 2.9541e-01 (2.9541e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [129][ 30/391]\tTime  0.177 ( 0.177)\tLoss 1.6038e-01 (2.2996e-01)\tAcc@1  96.88 ( 94.15)\tAcc@5  99.22 ( 98.89)\n",
            "Epoch: [129][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.5686e-01 (2.2398e-01)\tAcc@1  96.88 ( 94.21)\tAcc@5 100.00 ( 99.07)\n",
            "Epoch: [129][ 90/391]\tTime  0.174 ( 0.175)\tLoss 2.1566e-01 (2.2720e-01)\tAcc@1  92.97 ( 93.96)\tAcc@5  98.44 ( 99.08)\n",
            "Epoch: [129][120/391]\tTime  0.175 ( 0.174)\tLoss 1.5918e-01 (2.3046e-01)\tAcc@1  97.66 ( 93.86)\tAcc@5  99.22 ( 99.02)\n",
            "Epoch: [129][150/391]\tTime  0.173 ( 0.174)\tLoss 2.5645e-01 (2.3068e-01)\tAcc@1  91.41 ( 93.88)\tAcc@5  98.44 ( 99.06)\n",
            "Epoch: [129][180/391]\tTime  0.172 ( 0.174)\tLoss 2.6717e-01 (2.3359e-01)\tAcc@1  89.84 ( 93.77)\tAcc@5  99.22 ( 99.02)\n",
            "Epoch: [129][210/391]\tTime  0.172 ( 0.174)\tLoss 3.2870e-01 (2.3882e-01)\tAcc@1  89.06 ( 93.61)\tAcc@5  96.09 ( 98.92)\n",
            "Epoch: [129][240/391]\tTime  0.173 ( 0.174)\tLoss 2.3965e-01 (2.3886e-01)\tAcc@1  93.75 ( 93.59)\tAcc@5  98.44 ( 98.93)\n",
            "Epoch: [129][270/391]\tTime  0.173 ( 0.174)\tLoss 2.6478e-01 (2.4144e-01)\tAcc@1  92.97 ( 93.49)\tAcc@5  98.44 ( 98.91)\n",
            "Epoch: [129][300/391]\tTime  0.176 ( 0.174)\tLoss 1.6412e-01 (2.4039e-01)\tAcc@1  96.09 ( 93.52)\tAcc@5  99.22 ( 98.92)\n",
            "Epoch: [129][330/391]\tTime  0.170 ( 0.174)\tLoss 2.7834e-01 (2.3901e-01)\tAcc@1  91.41 ( 93.54)\tAcc@5  99.22 ( 98.93)\n",
            "Epoch: [129][360/391]\tTime  0.174 ( 0.174)\tLoss 3.3156e-01 (2.3975e-01)\tAcc@1  93.75 ( 93.53)\tAcc@5  97.66 ( 98.92)\n",
            "Epoch: [129][390/391]\tTime  0.155 ( 0.174)\tLoss 2.3226e-01 (2.4082e-01)\tAcc@1  93.75 ( 93.46)\tAcc@5  98.75 ( 98.93)\n",
            "==> Train Accuracy: Acc@1 93.460 || Acc@5 98.928\n",
            "==> Test Accuracy:  Acc@1 77.090 || Acc@5 94.040\n",
            "==> 72.33 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 130, lr: 0.0008000000000000003 -----\n",
            "Epoch: [130][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.7440e-01 (1.7440e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [130][ 30/391]\tTime  0.172 ( 0.177)\tLoss 1.9631e-01 (2.2335e-01)\tAcc@1  92.97 ( 93.85)\tAcc@5 100.00 ( 99.02)\n",
            "Epoch: [130][ 60/391]\tTime  0.174 ( 0.175)\tLoss 2.9008e-01 (2.2486e-01)\tAcc@1  92.97 ( 94.15)\tAcc@5  97.66 ( 98.89)\n",
            "Epoch: [130][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.4083e-01 (2.3009e-01)\tAcc@1  96.09 ( 93.90)\tAcc@5  99.22 ( 98.82)\n",
            "Epoch: [130][120/391]\tTime  0.173 ( 0.175)\tLoss 2.2024e-01 (2.2852e-01)\tAcc@1  95.31 ( 93.95)\tAcc@5  99.22 ( 98.84)\n",
            "Epoch: [130][150/391]\tTime  0.176 ( 0.174)\tLoss 1.4860e-01 (2.2724e-01)\tAcc@1  94.53 ( 94.02)\tAcc@5 100.00 ( 98.85)\n",
            "Epoch: [130][180/391]\tTime  0.177 ( 0.174)\tLoss 1.5087e-01 (2.2843e-01)\tAcc@1  96.09 ( 94.00)\tAcc@5  99.22 ( 98.86)\n",
            "Epoch: [130][210/391]\tTime  0.174 ( 0.174)\tLoss 2.7916e-01 (2.2836e-01)\tAcc@1  91.41 ( 94.01)\tAcc@5  98.44 ( 98.88)\n",
            "Epoch: [130][240/391]\tTime  0.175 ( 0.174)\tLoss 2.4605e-01 (2.2892e-01)\tAcc@1  93.75 ( 93.98)\tAcc@5  97.66 ( 98.88)\n",
            "Epoch: [130][270/391]\tTime  0.176 ( 0.174)\tLoss 2.2088e-01 (2.2836e-01)\tAcc@1  96.09 ( 93.99)\tAcc@5  99.22 ( 98.88)\n",
            "Epoch: [130][300/391]\tTime  0.174 ( 0.174)\tLoss 1.6250e-01 (2.2975e-01)\tAcc@1  95.31 ( 93.96)\tAcc@5 100.00 ( 98.87)\n",
            "Epoch: [130][330/391]\tTime  0.171 ( 0.174)\tLoss 2.1096e-01 (2.3152e-01)\tAcc@1  96.09 ( 93.91)\tAcc@5  99.22 ( 98.86)\n",
            "Epoch: [130][360/391]\tTime  0.176 ( 0.174)\tLoss 2.2154e-01 (2.3132e-01)\tAcc@1  92.97 ( 93.90)\tAcc@5  99.22 ( 98.89)\n",
            "Epoch: [130][390/391]\tTime  0.157 ( 0.174)\tLoss 1.6659e-01 (2.3235e-01)\tAcc@1  95.00 ( 93.87)\tAcc@5 100.00 ( 98.89)\n",
            "==> Train Accuracy: Acc@1 93.866 || Acc@5 98.892\n",
            "==> Test Accuracy:  Acc@1 77.230 || Acc@5 93.990\n",
            "==> 72.41 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 131, lr: 0.0008000000000000003 -----\n",
            "Epoch: [131][  0/391]\tTime  0.264 ( 0.264)\tLoss 2.6209e-01 (2.6209e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [131][ 30/391]\tTime  0.173 ( 0.177)\tLoss 2.3714e-01 (2.2281e-01)\tAcc@1  93.75 ( 94.00)\tAcc@5  98.44 ( 98.89)\n",
            "Epoch: [131][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.6937e-01 (2.2241e-01)\tAcc@1  96.09 ( 94.10)\tAcc@5  98.44 ( 98.99)\n",
            "Epoch: [131][ 90/391]\tTime  0.176 ( 0.175)\tLoss 2.6309e-01 (2.2629e-01)\tAcc@1  92.97 ( 94.18)\tAcc@5  99.22 ( 98.95)\n",
            "Epoch: [131][120/391]\tTime  0.174 ( 0.175)\tLoss 3.0072e-01 (2.3178e-01)\tAcc@1  89.06 ( 94.00)\tAcc@5  98.44 ( 98.94)\n",
            "Epoch: [131][150/391]\tTime  0.174 ( 0.174)\tLoss 2.7899e-01 (2.2933e-01)\tAcc@1  91.41 ( 94.06)\tAcc@5  98.44 ( 98.96)\n",
            "Epoch: [131][180/391]\tTime  0.175 ( 0.174)\tLoss 2.7299e-01 (2.3166e-01)\tAcc@1  92.97 ( 93.94)\tAcc@5  96.09 ( 98.94)\n",
            "Epoch: [131][210/391]\tTime  0.174 ( 0.174)\tLoss 2.9449e-01 (2.2903e-01)\tAcc@1  91.41 ( 93.99)\tAcc@5  99.22 ( 98.96)\n",
            "Epoch: [131][240/391]\tTime  0.173 ( 0.174)\tLoss 3.0549e-01 (2.2975e-01)\tAcc@1  92.19 ( 93.96)\tAcc@5  98.44 ( 98.95)\n",
            "Epoch: [131][270/391]\tTime  0.173 ( 0.174)\tLoss 2.4668e-01 (2.2878e-01)\tAcc@1  92.97 ( 94.01)\tAcc@5  99.22 ( 98.94)\n",
            "Epoch: [131][300/391]\tTime  0.175 ( 0.174)\tLoss 2.2285e-01 (2.3049e-01)\tAcc@1  95.31 ( 93.98)\tAcc@5  98.44 ( 98.93)\n",
            "Epoch: [131][330/391]\tTime  0.176 ( 0.174)\tLoss 3.2707e-01 (2.3052e-01)\tAcc@1  92.97 ( 93.95)\tAcc@5  98.44 ( 98.95)\n",
            "Epoch: [131][360/391]\tTime  0.172 ( 0.174)\tLoss 1.6999e-01 (2.2874e-01)\tAcc@1  95.31 ( 93.97)\tAcc@5 100.00 ( 98.97)\n",
            "Epoch: [131][390/391]\tTime  0.157 ( 0.174)\tLoss 3.1589e-01 (2.2946e-01)\tAcc@1  92.50 ( 93.95)\tAcc@5 100.00 ( 98.97)\n",
            "==> Train Accuracy: Acc@1 93.946 || Acc@5 98.970\n",
            "==> Test Accuracy:  Acc@1 77.190 || Acc@5 94.030\n",
            "==> 72.39 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 132, lr: 0.0008000000000000003 -----\n",
            "Epoch: [132][  0/391]\tTime  0.269 ( 0.269)\tLoss 2.2992e-01 (2.2992e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [132][ 30/391]\tTime  0.174 ( 0.177)\tLoss 2.6209e-01 (2.1752e-01)\tAcc@1  94.53 ( 94.15)\tAcc@5  97.66 ( 98.94)\n",
            "Epoch: [132][ 60/391]\tTime  0.174 ( 0.175)\tLoss 3.0597e-01 (2.2061e-01)\tAcc@1  91.41 ( 94.29)\tAcc@5  95.31 ( 98.94)\n",
            "Epoch: [132][ 90/391]\tTime  0.172 ( 0.175)\tLoss 2.2071e-01 (2.2118e-01)\tAcc@1  94.53 ( 94.24)\tAcc@5  98.44 ( 99.00)\n",
            "Epoch: [132][120/391]\tTime  0.173 ( 0.175)\tLoss 2.8331e-01 (2.2711e-01)\tAcc@1  94.53 ( 94.12)\tAcc@5  98.44 ( 98.94)\n",
            "Epoch: [132][150/391]\tTime  0.173 ( 0.174)\tLoss 1.2836e-01 (2.2559e-01)\tAcc@1  94.53 ( 94.06)\tAcc@5 100.00 ( 98.98)\n",
            "Epoch: [132][180/391]\tTime  0.176 ( 0.174)\tLoss 3.2290e-01 (2.2811e-01)\tAcc@1  91.41 ( 93.99)\tAcc@5  96.09 ( 98.95)\n",
            "Epoch: [132][210/391]\tTime  0.175 ( 0.174)\tLoss 2.4381e-01 (2.2518e-01)\tAcc@1  94.53 ( 94.08)\tAcc@5  99.22 ( 98.97)\n",
            "Epoch: [132][240/391]\tTime  0.173 ( 0.174)\tLoss 2.7837e-01 (2.2424e-01)\tAcc@1  89.84 ( 94.07)\tAcc@5 100.00 ( 99.01)\n",
            "Epoch: [132][270/391]\tTime  0.173 ( 0.174)\tLoss 1.5756e-01 (2.2288e-01)\tAcc@1  95.31 ( 94.08)\tAcc@5 100.00 ( 99.01)\n",
            "Epoch: [132][300/391]\tTime  0.174 ( 0.174)\tLoss 2.2345e-01 (2.2315e-01)\tAcc@1  92.19 ( 94.05)\tAcc@5  99.22 ( 99.01)\n",
            "Epoch: [132][330/391]\tTime  0.175 ( 0.174)\tLoss 2.3517e-01 (2.2275e-01)\tAcc@1  95.31 ( 94.07)\tAcc@5  97.66 ( 99.00)\n",
            "Epoch: [132][360/391]\tTime  0.172 ( 0.174)\tLoss 1.4858e-01 (2.2260e-01)\tAcc@1  96.09 ( 94.08)\tAcc@5  99.22 ( 99.00)\n",
            "Epoch: [132][390/391]\tTime  0.158 ( 0.174)\tLoss 2.1963e-01 (2.2323e-01)\tAcc@1  96.25 ( 94.08)\tAcc@5  98.75 ( 99.01)\n",
            "==> Train Accuracy: Acc@1 94.082 || Acc@5 99.010\n",
            "==> Test Accuracy:  Acc@1 77.490 || Acc@5 93.970\n",
            "==> 72.39 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 133, lr: 0.0008000000000000003 -----\n",
            "Epoch: [133][  0/391]\tTime  0.270 ( 0.270)\tLoss 1.9961e-01 (1.9961e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [133][ 30/391]\tTime  0.174 ( 0.176)\tLoss 2.0528e-01 (2.2419e-01)\tAcc@1  93.75 ( 93.72)\tAcc@5  99.22 ( 98.97)\n",
            "Epoch: [133][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.8640e-01 (2.2223e-01)\tAcc@1  94.53 ( 93.97)\tAcc@5  99.22 ( 99.07)\n",
            "Epoch: [133][ 90/391]\tTime  0.175 ( 0.174)\tLoss 2.0295e-01 (2.1683e-01)\tAcc@1  94.53 ( 94.20)\tAcc@5  98.44 ( 99.07)\n",
            "Epoch: [133][120/391]\tTime  0.172 ( 0.174)\tLoss 2.4408e-01 (2.2078e-01)\tAcc@1  92.97 ( 94.09)\tAcc@5  98.44 ( 99.01)\n",
            "Epoch: [133][150/391]\tTime  0.175 ( 0.174)\tLoss 1.3937e-01 (2.2073e-01)\tAcc@1  96.88 ( 94.11)\tAcc@5 100.00 ( 99.02)\n",
            "Epoch: [133][180/391]\tTime  0.173 ( 0.174)\tLoss 1.6085e-01 (2.1861e-01)\tAcc@1  95.31 ( 94.10)\tAcc@5  99.22 ( 99.04)\n",
            "Epoch: [133][210/391]\tTime  0.173 ( 0.174)\tLoss 2.6062e-01 (2.1818e-01)\tAcc@1  90.62 ( 94.08)\tAcc@5 100.00 ( 99.05)\n",
            "Epoch: [133][240/391]\tTime  0.174 ( 0.174)\tLoss 2.4716e-01 (2.1967e-01)\tAcc@1  93.75 ( 94.05)\tAcc@5  98.44 ( 99.03)\n",
            "Epoch: [133][270/391]\tTime  0.173 ( 0.174)\tLoss 2.8962e-01 (2.2248e-01)\tAcc@1  93.75 ( 93.98)\tAcc@5  96.88 ( 99.00)\n",
            "Epoch: [133][300/391]\tTime  0.173 ( 0.174)\tLoss 1.3229e-01 (2.2193e-01)\tAcc@1  97.66 ( 94.00)\tAcc@5  99.22 ( 99.00)\n",
            "Epoch: [133][330/391]\tTime  0.172 ( 0.174)\tLoss 2.4221e-01 (2.2186e-01)\tAcc@1  92.97 ( 94.00)\tAcc@5  98.44 ( 99.02)\n",
            "Epoch: [133][360/391]\tTime  0.172 ( 0.174)\tLoss 2.5728e-01 (2.2206e-01)\tAcc@1  93.75 ( 93.98)\tAcc@5  98.44 ( 99.00)\n",
            "Epoch: [133][390/391]\tTime  0.157 ( 0.174)\tLoss 3.2828e-01 (2.2059e-01)\tAcc@1  88.75 ( 94.02)\tAcc@5  98.75 ( 99.01)\n",
            "==> Train Accuracy: Acc@1 94.022 || Acc@5 99.006\n",
            "==> Test Accuracy:  Acc@1 77.340 || Acc@5 94.010\n",
            "==> 72.30 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 134, lr: 0.0008000000000000003 -----\n",
            "Epoch: [134][  0/391]\tTime  0.272 ( 0.272)\tLoss 2.3030e-01 (2.3030e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 30/391]\tTime  0.171 ( 0.176)\tLoss 1.5893e-01 (2.0635e-01)\tAcc@1  95.31 ( 94.43)\tAcc@5  99.22 ( 99.12)\n",
            "Epoch: [134][ 60/391]\tTime  0.172 ( 0.175)\tLoss 2.4299e-01 (2.1221e-01)\tAcc@1  93.75 ( 94.47)\tAcc@5  99.22 ( 99.03)\n",
            "Epoch: [134][ 90/391]\tTime  0.176 ( 0.175)\tLoss 3.0249e-01 (2.0999e-01)\tAcc@1  91.41 ( 94.39)\tAcc@5  98.44 ( 99.08)\n",
            "Epoch: [134][120/391]\tTime  0.173 ( 0.174)\tLoss 1.8664e-01 (2.0840e-01)\tAcc@1  93.75 ( 94.39)\tAcc@5 100.00 ( 99.09)\n",
            "Epoch: [134][150/391]\tTime  0.174 ( 0.174)\tLoss 2.7271e-01 (2.0960e-01)\tAcc@1  92.97 ( 94.40)\tAcc@5  99.22 ( 99.10)\n",
            "Epoch: [134][180/391]\tTime  0.174 ( 0.174)\tLoss 1.9521e-01 (2.0936e-01)\tAcc@1  94.53 ( 94.38)\tAcc@5  99.22 ( 99.14)\n",
            "Epoch: [134][210/391]\tTime  0.175 ( 0.174)\tLoss 2.8804e-01 (2.1058e-01)\tAcc@1  94.53 ( 94.38)\tAcc@5  98.44 ( 99.13)\n",
            "Epoch: [134][240/391]\tTime  0.173 ( 0.174)\tLoss 3.1829e-01 (2.1186e-01)\tAcc@1  90.62 ( 94.37)\tAcc@5  97.66 ( 99.13)\n",
            "Epoch: [134][270/391]\tTime  0.175 ( 0.174)\tLoss 8.3779e-02 (2.1140e-01)\tAcc@1  96.88 ( 94.40)\tAcc@5 100.00 ( 99.12)\n",
            "Epoch: [134][300/391]\tTime  0.175 ( 0.174)\tLoss 1.5673e-01 (2.1151e-01)\tAcc@1  96.09 ( 94.45)\tAcc@5 100.00 ( 99.14)\n",
            "Epoch: [134][330/391]\tTime  0.173 ( 0.174)\tLoss 2.3575e-01 (2.1389e-01)\tAcc@1  92.19 ( 94.37)\tAcc@5 100.00 ( 99.11)\n",
            "Epoch: [134][360/391]\tTime  0.175 ( 0.174)\tLoss 2.2211e-01 (2.1401e-01)\tAcc@1  93.75 ( 94.37)\tAcc@5  99.22 ( 99.10)\n",
            "Epoch: [134][390/391]\tTime  0.159 ( 0.174)\tLoss 1.5912e-01 (2.1426e-01)\tAcc@1  95.00 ( 94.37)\tAcc@5 100.00 ( 99.11)\n",
            "==> Train Accuracy: Acc@1 94.368 || Acc@5 99.112\n",
            "==> Test Accuracy:  Acc@1 77.120 || Acc@5 94.090\n",
            "==> 72.30 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 135, lr: 0.0008000000000000003 -----\n",
            "Epoch: [135][  0/391]\tTime  0.263 ( 0.263)\tLoss 2.1977e-01 (2.1977e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [135][ 30/391]\tTime  0.173 ( 0.176)\tLoss 1.8815e-01 (1.9993e-01)\tAcc@1  94.53 ( 94.96)\tAcc@5  99.22 ( 99.07)\n",
            "Epoch: [135][ 60/391]\tTime  0.174 ( 0.175)\tLoss 3.1438e-01 (2.0252e-01)\tAcc@1  89.06 ( 94.77)\tAcc@5  96.88 ( 99.01)\n",
            "Epoch: [135][ 90/391]\tTime  0.170 ( 0.174)\tLoss 2.7289e-01 (2.0831e-01)\tAcc@1  92.19 ( 94.59)\tAcc@5  96.88 ( 98.98)\n",
            "Epoch: [135][120/391]\tTime  0.171 ( 0.174)\tLoss 3.4019e-01 (2.1125e-01)\tAcc@1  89.84 ( 94.49)\tAcc@5  98.44 ( 99.00)\n",
            "Epoch: [135][150/391]\tTime  0.173 ( 0.174)\tLoss 1.4243e-01 (2.1271e-01)\tAcc@1  97.66 ( 94.43)\tAcc@5  99.22 ( 99.00)\n",
            "Epoch: [135][180/391]\tTime  0.176 ( 0.174)\tLoss 2.4868e-01 (2.1200e-01)\tAcc@1  95.31 ( 94.39)\tAcc@5  98.44 ( 99.03)\n",
            "Epoch: [135][210/391]\tTime  0.175 ( 0.174)\tLoss 1.9414e-01 (2.1274e-01)\tAcc@1  94.53 ( 94.32)\tAcc@5 100.00 ( 99.01)\n",
            "Epoch: [135][240/391]\tTime  0.173 ( 0.174)\tLoss 1.4686e-01 (2.1395e-01)\tAcc@1  94.53 ( 94.31)\tAcc@5  99.22 ( 99.00)\n",
            "Epoch: [135][270/391]\tTime  0.171 ( 0.174)\tLoss 1.9267e-01 (2.1259e-01)\tAcc@1  93.75 ( 94.34)\tAcc@5  98.44 ( 99.03)\n",
            "Epoch: [135][300/391]\tTime  0.174 ( 0.174)\tLoss 2.2497e-01 (2.1415e-01)\tAcc@1  94.53 ( 94.29)\tAcc@5  98.44 ( 99.04)\n",
            "Epoch: [135][330/391]\tTime  0.172 ( 0.174)\tLoss 3.5570e-01 (2.1629e-01)\tAcc@1  89.84 ( 94.21)\tAcc@5  96.88 ( 99.02)\n",
            "Epoch: [135][360/391]\tTime  0.176 ( 0.174)\tLoss 3.3742e-01 (2.1683e-01)\tAcc@1  90.62 ( 94.18)\tAcc@5  95.31 ( 99.00)\n",
            "Epoch: [135][390/391]\tTime  0.158 ( 0.174)\tLoss 1.7221e-01 (2.1479e-01)\tAcc@1  93.75 ( 94.25)\tAcc@5 100.00 ( 99.03)\n",
            "==> Train Accuracy: Acc@1 94.246 || Acc@5 99.028\n",
            "==> Test Accuracy:  Acc@1 77.140 || Acc@5 94.020\n",
            "==> 72.35 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 136, lr: 0.0008000000000000003 -----\n",
            "Epoch: [136][  0/391]\tTime  0.269 ( 0.269)\tLoss 3.2729e-01 (3.2729e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [136][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.6215e-01 (2.2316e-01)\tAcc@1  96.88 ( 94.00)\tAcc@5  99.22 ( 98.87)\n",
            "Epoch: [136][ 60/391]\tTime  0.173 ( 0.175)\tLoss 2.4541e-01 (2.1640e-01)\tAcc@1  93.75 ( 94.01)\tAcc@5  99.22 ( 98.99)\n",
            "Epoch: [136][ 90/391]\tTime  0.174 ( 0.175)\tLoss 2.3478e-01 (2.1482e-01)\tAcc@1  92.97 ( 94.23)\tAcc@5 100.00 ( 99.01)\n",
            "Epoch: [136][120/391]\tTime  0.172 ( 0.174)\tLoss 1.3820e-01 (2.1421e-01)\tAcc@1  96.09 ( 94.23)\tAcc@5  99.22 ( 98.97)\n",
            "Epoch: [136][150/391]\tTime  0.176 ( 0.174)\tLoss 2.5880e-01 (2.1345e-01)\tAcc@1  93.75 ( 94.29)\tAcc@5  97.66 ( 98.98)\n",
            "Epoch: [136][180/391]\tTime  0.174 ( 0.174)\tLoss 1.6736e-01 (2.1318e-01)\tAcc@1  96.88 ( 94.35)\tAcc@5  98.44 ( 98.97)\n",
            "Epoch: [136][210/391]\tTime  0.174 ( 0.174)\tLoss 1.7571e-01 (2.1259e-01)\tAcc@1  96.09 ( 94.37)\tAcc@5  99.22 ( 98.99)\n",
            "Epoch: [136][240/391]\tTime  0.177 ( 0.174)\tLoss 1.6034e-01 (2.1087e-01)\tAcc@1  94.53 ( 94.42)\tAcc@5  99.22 ( 99.01)\n",
            "Epoch: [136][270/391]\tTime  0.172 ( 0.174)\tLoss 1.5656e-01 (2.1084e-01)\tAcc@1  95.31 ( 94.41)\tAcc@5 100.00 ( 99.02)\n",
            "Epoch: [136][300/391]\tTime  0.174 ( 0.174)\tLoss 2.2760e-01 (2.1060e-01)\tAcc@1  93.75 ( 94.42)\tAcc@5 100.00 ( 99.04)\n",
            "Epoch: [136][330/391]\tTime  0.172 ( 0.174)\tLoss 3.8538e-01 (2.1188e-01)\tAcc@1  92.19 ( 94.35)\tAcc@5  96.09 ( 99.03)\n",
            "Epoch: [136][360/391]\tTime  0.175 ( 0.174)\tLoss 1.7173e-01 (2.1291e-01)\tAcc@1  96.09 ( 94.32)\tAcc@5 100.00 ( 99.03)\n",
            "Epoch: [136][390/391]\tTime  0.156 ( 0.174)\tLoss 3.2560e-01 (2.1419e-01)\tAcc@1  90.00 ( 94.26)\tAcc@5  97.50 ( 99.02)\n",
            "==> Train Accuracy: Acc@1 94.262 || Acc@5 99.022\n",
            "==> Test Accuracy:  Acc@1 77.340 || Acc@5 94.080\n",
            "==> 72.37 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 137, lr: 0.0008000000000000003 -----\n",
            "Epoch: [137][  0/391]\tTime  0.249 ( 0.249)\tLoss 1.4594e-01 (1.4594e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 30/391]\tTime  0.172 ( 0.176)\tLoss 2.3649e-01 (2.0587e-01)\tAcc@1  93.75 ( 94.68)\tAcc@5  99.22 ( 99.12)\n",
            "Epoch: [137][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.9129e-01 (2.0524e-01)\tAcc@1  92.19 ( 94.49)\tAcc@5 100.00 ( 99.13)\n",
            "Epoch: [137][ 90/391]\tTime  0.172 ( 0.175)\tLoss 2.3543e-01 (2.0525e-01)\tAcc@1  93.75 ( 94.54)\tAcc@5  98.44 ( 99.16)\n",
            "Epoch: [137][120/391]\tTime  0.171 ( 0.174)\tLoss 1.5391e-01 (2.1242e-01)\tAcc@1  96.09 ( 94.43)\tAcc@5  99.22 ( 99.10)\n",
            "Epoch: [137][150/391]\tTime  0.173 ( 0.174)\tLoss 1.9967e-01 (2.1269e-01)\tAcc@1  94.53 ( 94.45)\tAcc@5 100.00 ( 99.12)\n",
            "Epoch: [137][180/391]\tTime  0.171 ( 0.174)\tLoss 2.4399e-01 (2.1400e-01)\tAcc@1  92.97 ( 94.39)\tAcc@5  98.44 ( 99.12)\n",
            "Epoch: [137][210/391]\tTime  0.173 ( 0.174)\tLoss 2.4499e-01 (2.1350e-01)\tAcc@1  93.75 ( 94.42)\tAcc@5 100.00 ( 99.14)\n",
            "Epoch: [137][240/391]\tTime  0.171 ( 0.174)\tLoss 1.7917e-01 (2.1345e-01)\tAcc@1  93.75 ( 94.39)\tAcc@5 100.00 ( 99.14)\n",
            "Epoch: [137][270/391]\tTime  0.173 ( 0.174)\tLoss 1.3435e-01 (2.1434e-01)\tAcc@1  96.88 ( 94.36)\tAcc@5 100.00 ( 99.12)\n",
            "Epoch: [137][300/391]\tTime  0.173 ( 0.174)\tLoss 1.7280e-01 (2.1530e-01)\tAcc@1  92.19 ( 94.33)\tAcc@5  99.22 ( 99.12)\n",
            "Epoch: [137][330/391]\tTime  0.172 ( 0.174)\tLoss 2.4139e-01 (2.1669e-01)\tAcc@1  92.97 ( 94.26)\tAcc@5  99.22 ( 99.09)\n",
            "Epoch: [137][360/391]\tTime  0.173 ( 0.174)\tLoss 1.6932e-01 (2.1560e-01)\tAcc@1  96.88 ( 94.31)\tAcc@5  99.22 ( 99.09)\n",
            "Epoch: [137][390/391]\tTime  0.156 ( 0.174)\tLoss 1.9968e-01 (2.1526e-01)\tAcc@1  95.00 ( 94.32)\tAcc@5 100.00 ( 99.09)\n",
            "==> Train Accuracy: Acc@1 94.318 || Acc@5 99.094\n",
            "==> Test Accuracy:  Acc@1 77.030 || Acc@5 94.000\n",
            "==> 72.24 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 138, lr: 0.0008000000000000003 -----\n",
            "Epoch: [138][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.8908e-01 (1.8908e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [138][ 30/391]\tTime  0.174 ( 0.176)\tLoss 2.5181e-01 (2.2706e-01)\tAcc@1  93.75 ( 93.70)\tAcc@5  97.66 ( 98.99)\n",
            "Epoch: [138][ 60/391]\tTime  0.173 ( 0.175)\tLoss 2.0189e-01 (2.1848e-01)\tAcc@1  93.75 ( 94.13)\tAcc@5  99.22 ( 99.01)\n",
            "Epoch: [138][ 90/391]\tTime  0.174 ( 0.174)\tLoss 2.7764e-01 (2.1847e-01)\tAcc@1  89.06 ( 94.06)\tAcc@5 100.00 ( 99.02)\n",
            "Epoch: [138][120/391]\tTime  0.173 ( 0.174)\tLoss 1.3312e-01 (2.1810e-01)\tAcc@1  96.88 ( 94.12)\tAcc@5 100.00 ( 98.98)\n",
            "Epoch: [138][150/391]\tTime  0.176 ( 0.174)\tLoss 1.6801e-01 (2.1573e-01)\tAcc@1  92.97 ( 94.14)\tAcc@5 100.00 ( 99.06)\n",
            "Epoch: [138][180/391]\tTime  0.172 ( 0.174)\tLoss 2.4581e-01 (2.1465e-01)\tAcc@1  94.53 ( 94.22)\tAcc@5  98.44 ( 99.06)\n",
            "Epoch: [138][210/391]\tTime  0.173 ( 0.174)\tLoss 1.8791e-01 (2.1311e-01)\tAcc@1  96.09 ( 94.23)\tAcc@5  99.22 ( 99.06)\n",
            "Epoch: [138][240/391]\tTime  0.173 ( 0.173)\tLoss 1.5899e-01 (2.1189e-01)\tAcc@1  94.53 ( 94.27)\tAcc@5  99.22 ( 99.07)\n",
            "Epoch: [138][270/391]\tTime  0.174 ( 0.173)\tLoss 1.9341e-01 (2.1220e-01)\tAcc@1  95.31 ( 94.23)\tAcc@5 100.00 ( 99.06)\n",
            "Epoch: [138][300/391]\tTime  0.174 ( 0.173)\tLoss 1.1007e-01 (2.1181e-01)\tAcc@1  96.88 ( 94.24)\tAcc@5 100.00 ( 99.07)\n",
            "Epoch: [138][330/391]\tTime  0.173 ( 0.173)\tLoss 1.1874e-01 (2.1438e-01)\tAcc@1  96.88 ( 94.19)\tAcc@5 100.00 ( 99.05)\n",
            "Epoch: [138][360/391]\tTime  0.173 ( 0.173)\tLoss 2.2087e-01 (2.1535e-01)\tAcc@1  92.97 ( 94.19)\tAcc@5  99.22 ( 99.04)\n",
            "Epoch: [138][390/391]\tTime  0.156 ( 0.173)\tLoss 9.0859e-02 (2.1440e-01)\tAcc@1  97.50 ( 94.24)\tAcc@5 100.00 ( 99.04)\n",
            "==> Train Accuracy: Acc@1 94.244 || Acc@5 99.038\n",
            "==> Test Accuracy:  Acc@1 77.180 || Acc@5 93.930\n",
            "==> 72.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 139, lr: 0.0008000000000000003 -----\n",
            "Epoch: [139][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.3159e-01 (1.3159e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.4877e-01 (1.9567e-01)\tAcc@1  96.88 ( 95.11)\tAcc@5 100.00 ( 99.12)\n",
            "Epoch: [139][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.9095e-01 (2.0226e-01)\tAcc@1  93.75 ( 94.65)\tAcc@5  98.44 ( 99.09)\n",
            "Epoch: [139][ 90/391]\tTime  0.173 ( 0.174)\tLoss 1.8179e-01 (2.0862e-01)\tAcc@1  95.31 ( 94.58)\tAcc@5 100.00 ( 99.06)\n",
            "Epoch: [139][120/391]\tTime  0.174 ( 0.174)\tLoss 1.7175e-01 (2.0499e-01)\tAcc@1  95.31 ( 94.69)\tAcc@5  98.44 ( 99.03)\n",
            "Epoch: [139][150/391]\tTime  0.173 ( 0.174)\tLoss 1.1414e-01 (2.0392e-01)\tAcc@1  96.88 ( 94.63)\tAcc@5 100.00 ( 99.04)\n",
            "Epoch: [139][180/391]\tTime  0.172 ( 0.174)\tLoss 1.7518e-01 (2.0258e-01)\tAcc@1  94.53 ( 94.68)\tAcc@5 100.00 ( 99.04)\n",
            "Epoch: [139][210/391]\tTime  0.173 ( 0.174)\tLoss 1.9441e-01 (2.0166e-01)\tAcc@1  94.53 ( 94.68)\tAcc@5  99.22 ( 99.06)\n",
            "Epoch: [139][240/391]\tTime  0.174 ( 0.174)\tLoss 1.1222e-01 (2.0270e-01)\tAcc@1  96.88 ( 94.62)\tAcc@5 100.00 ( 99.06)\n",
            "Epoch: [139][270/391]\tTime  0.174 ( 0.174)\tLoss 1.8436e-01 (2.0387e-01)\tAcc@1  93.75 ( 94.61)\tAcc@5 100.00 ( 99.05)\n",
            "Epoch: [139][300/391]\tTime  0.173 ( 0.174)\tLoss 3.2126e-01 (2.0426e-01)\tAcc@1  91.41 ( 94.59)\tAcc@5  97.66 ( 99.05)\n",
            "Epoch: [139][330/391]\tTime  0.174 ( 0.174)\tLoss 1.7916e-01 (2.0421e-01)\tAcc@1  94.53 ( 94.59)\tAcc@5  99.22 ( 99.06)\n",
            "Epoch: [139][360/391]\tTime  0.175 ( 0.174)\tLoss 2.2006e-01 (2.0565e-01)\tAcc@1  94.53 ( 94.55)\tAcc@5  98.44 ( 99.04)\n",
            "Epoch: [139][390/391]\tTime  0.157 ( 0.173)\tLoss 4.0068e-01 (2.0536e-01)\tAcc@1  90.00 ( 94.57)\tAcc@5  97.50 ( 99.05)\n",
            "==> Train Accuracy: Acc@1 94.570 || Acc@5 99.054\n",
            "==> Test Accuracy:  Acc@1 77.460 || Acc@5 93.820\n",
            "==> 72.18 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 140, lr: 0.0008000000000000003 -----\n",
            "Epoch: [140][  0/391]\tTime  0.267 ( 0.267)\tLoss 2.6072e-01 (2.6072e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [140][ 30/391]\tTime  0.173 ( 0.176)\tLoss 1.6123e-01 (2.0523e-01)\tAcc@1  96.09 ( 94.51)\tAcc@5 100.00 ( 99.09)\n",
            "Epoch: [140][ 60/391]\tTime  0.176 ( 0.175)\tLoss 1.2287e-01 (2.0743e-01)\tAcc@1  96.88 ( 94.47)\tAcc@5 100.00 ( 99.09)\n",
            "Epoch: [140][ 90/391]\tTime  0.174 ( 0.174)\tLoss 2.1970e-01 (2.0467e-01)\tAcc@1  93.75 ( 94.57)\tAcc@5  98.44 ( 99.16)\n",
            "Epoch: [140][120/391]\tTime  0.172 ( 0.174)\tLoss 1.6748e-01 (2.0534e-01)\tAcc@1  95.31 ( 94.55)\tAcc@5 100.00 ( 99.14)\n",
            "Epoch: [140][150/391]\tTime  0.172 ( 0.174)\tLoss 1.2942e-01 (2.0333e-01)\tAcc@1  96.88 ( 94.63)\tAcc@5 100.00 ( 99.13)\n",
            "Epoch: [140][180/391]\tTime  0.175 ( 0.174)\tLoss 1.8141e-01 (2.0365e-01)\tAcc@1  96.88 ( 94.65)\tAcc@5  99.22 ( 99.11)\n",
            "Epoch: [140][210/391]\tTime  0.170 ( 0.174)\tLoss 2.2714e-01 (1.9948e-01)\tAcc@1  91.41 ( 94.75)\tAcc@5  98.44 ( 99.16)\n",
            "Epoch: [140][240/391]\tTime  0.174 ( 0.174)\tLoss 2.5361e-01 (2.0040e-01)\tAcc@1  94.53 ( 94.73)\tAcc@5  97.66 ( 99.14)\n",
            "Epoch: [140][270/391]\tTime  0.174 ( 0.174)\tLoss 1.7355e-01 (2.0327e-01)\tAcc@1  96.09 ( 94.66)\tAcc@5  98.44 ( 99.10)\n",
            "Epoch: [140][300/391]\tTime  0.169 ( 0.174)\tLoss 2.3741e-01 (2.0521e-01)\tAcc@1  93.75 ( 94.61)\tAcc@5  99.22 ( 99.07)\n",
            "Epoch: [140][330/391]\tTime  0.174 ( 0.174)\tLoss 1.9153e-01 (2.0550e-01)\tAcc@1  96.09 ( 94.58)\tAcc@5 100.00 ( 99.07)\n",
            "Epoch: [140][360/391]\tTime  0.172 ( 0.174)\tLoss 1.4724e-01 (2.0507e-01)\tAcc@1  95.31 ( 94.59)\tAcc@5  99.22 ( 99.07)\n",
            "Epoch: [140][390/391]\tTime  0.154 ( 0.174)\tLoss 3.6567e-01 (2.0483e-01)\tAcc@1  90.00 ( 94.61)\tAcc@5  98.75 ( 99.07)\n",
            "==> Train Accuracy: Acc@1 94.612 || Acc@5 99.074\n",
            "==> Test Accuracy:  Acc@1 77.200 || Acc@5 94.070\n",
            "==> 72.20 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 141, lr: 0.0008000000000000003 -----\n",
            "Epoch: [141][  0/391]\tTime  0.292 ( 0.292)\tLoss 2.6581e-01 (2.6581e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [141][ 30/391]\tTime  0.173 ( 0.177)\tLoss 2.1051e-01 (2.0193e-01)\tAcc@1  95.31 ( 94.63)\tAcc@5  98.44 ( 99.14)\n",
            "Epoch: [141][ 60/391]\tTime  0.172 ( 0.175)\tLoss 2.4233e-01 (1.9591e-01)\tAcc@1  95.31 ( 94.92)\tAcc@5  98.44 ( 99.23)\n",
            "Epoch: [141][ 90/391]\tTime  0.174 ( 0.174)\tLoss 4.0393e-01 (1.9560e-01)\tAcc@1  92.19 ( 94.85)\tAcc@5  95.31 ( 99.25)\n",
            "Epoch: [141][120/391]\tTime  0.176 ( 0.174)\tLoss 1.5135e-01 (1.9608e-01)\tAcc@1  95.31 ( 94.89)\tAcc@5 100.00 ( 99.22)\n",
            "Epoch: [141][150/391]\tTime  0.175 ( 0.174)\tLoss 1.6224e-01 (1.9488e-01)\tAcc@1  95.31 ( 94.91)\tAcc@5 100.00 ( 99.25)\n",
            "Epoch: [141][180/391]\tTime  0.172 ( 0.174)\tLoss 1.7920e-01 (1.9502e-01)\tAcc@1  96.09 ( 94.85)\tAcc@5  99.22 ( 99.24)\n",
            "Epoch: [141][210/391]\tTime  0.174 ( 0.174)\tLoss 1.6448e-01 (1.9697e-01)\tAcc@1  96.09 ( 94.78)\tAcc@5  99.22 ( 99.20)\n",
            "Epoch: [141][240/391]\tTime  0.174 ( 0.174)\tLoss 1.7941e-01 (1.9892e-01)\tAcc@1  96.88 ( 94.74)\tAcc@5  98.44 ( 99.18)\n",
            "Epoch: [141][270/391]\tTime  0.173 ( 0.174)\tLoss 1.7164e-01 (1.9962e-01)\tAcc@1  96.88 ( 94.75)\tAcc@5  99.22 ( 99.18)\n",
            "Epoch: [141][300/391]\tTime  0.173 ( 0.174)\tLoss 2.2031e-01 (1.9999e-01)\tAcc@1  95.31 ( 94.74)\tAcc@5  98.44 ( 99.16)\n",
            "Epoch: [141][330/391]\tTime  0.174 ( 0.174)\tLoss 1.3050e-01 (1.9781e-01)\tAcc@1  96.88 ( 94.79)\tAcc@5 100.00 ( 99.18)\n",
            "Epoch: [141][360/391]\tTime  0.173 ( 0.174)\tLoss 1.8201e-01 (1.9843e-01)\tAcc@1  95.31 ( 94.78)\tAcc@5 100.00 ( 99.17)\n",
            "Epoch: [141][390/391]\tTime  0.155 ( 0.173)\tLoss 2.4216e-01 (1.9959e-01)\tAcc@1  90.00 ( 94.74)\tAcc@5 100.00 ( 99.15)\n",
            "==> Train Accuracy: Acc@1 94.738 || Acc@5 99.146\n",
            "==> Test Accuracy:  Acc@1 77.110 || Acc@5 94.010\n",
            "==> 72.16 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 142, lr: 0.0008000000000000003 -----\n",
            "Epoch: [142][  0/391]\tTime  0.263 ( 0.263)\tLoss 2.1601e-01 (2.1601e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [142][ 30/391]\tTime  0.174 ( 0.176)\tLoss 9.8986e-02 (2.1428e-01)\tAcc@1  97.66 ( 94.13)\tAcc@5 100.00 ( 99.07)\n",
            "Epoch: [142][ 60/391]\tTime  0.174 ( 0.175)\tLoss 2.4455e-01 (2.0641e-01)\tAcc@1  95.31 ( 94.47)\tAcc@5  98.44 ( 99.03)\n",
            "Epoch: [142][ 90/391]\tTime  0.174 ( 0.174)\tLoss 2.0905e-01 (2.0787e-01)\tAcc@1  93.75 ( 94.45)\tAcc@5  99.22 ( 99.06)\n",
            "Epoch: [142][120/391]\tTime  0.172 ( 0.174)\tLoss 2.2992e-01 (2.0201e-01)\tAcc@1  92.19 ( 94.67)\tAcc@5  99.22 ( 99.10)\n",
            "Epoch: [142][150/391]\tTime  0.173 ( 0.174)\tLoss 3.2558e-01 (2.0255e-01)\tAcc@1  91.41 ( 94.51)\tAcc@5  98.44 ( 99.13)\n",
            "Epoch: [142][180/391]\tTime  0.173 ( 0.174)\tLoss 2.2620e-01 (2.0136e-01)\tAcc@1  94.53 ( 94.59)\tAcc@5 100.00 ( 99.14)\n",
            "Epoch: [142][210/391]\tTime  0.173 ( 0.174)\tLoss 2.6237e-01 (2.0213e-01)\tAcc@1  93.75 ( 94.60)\tAcc@5  99.22 ( 99.16)\n",
            "Epoch: [142][240/391]\tTime  0.173 ( 0.173)\tLoss 3.4096e-01 (2.0214e-01)\tAcc@1  89.84 ( 94.58)\tAcc@5  97.66 ( 99.13)\n",
            "Epoch: [142][270/391]\tTime  0.173 ( 0.173)\tLoss 1.4416e-01 (2.0238e-01)\tAcc@1  95.31 ( 94.62)\tAcc@5 100.00 ( 99.12)\n",
            "Epoch: [142][300/391]\tTime  0.173 ( 0.173)\tLoss 1.8195e-01 (2.0242e-01)\tAcc@1  95.31 ( 94.63)\tAcc@5  99.22 ( 99.12)\n",
            "Epoch: [142][330/391]\tTime  0.172 ( 0.173)\tLoss 2.2901e-01 (2.0212e-01)\tAcc@1  93.75 ( 94.65)\tAcc@5  98.44 ( 99.12)\n",
            "Epoch: [142][360/391]\tTime  0.174 ( 0.173)\tLoss 2.2865e-01 (2.0372e-01)\tAcc@1  94.53 ( 94.59)\tAcc@5  98.44 ( 99.10)\n",
            "Epoch: [142][390/391]\tTime  0.156 ( 0.173)\tLoss 2.1676e-01 (2.0328e-01)\tAcc@1  93.75 ( 94.61)\tAcc@5 100.00 ( 99.11)\n",
            "==> Train Accuracy: Acc@1 94.606 || Acc@5 99.106\n",
            "==> Test Accuracy:  Acc@1 77.290 || Acc@5 94.080\n",
            "==> 72.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 143, lr: 0.0008000000000000003 -----\n",
            "Epoch: [143][  0/391]\tTime  0.277 ( 0.277)\tLoss 2.8263e-01 (2.8263e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [143][ 30/391]\tTime  0.171 ( 0.176)\tLoss 1.2429e-01 (1.9736e-01)\tAcc@1  97.66 ( 94.86)\tAcc@5  99.22 ( 99.27)\n",
            "Epoch: [143][ 60/391]\tTime  0.174 ( 0.175)\tLoss 2.6734e-01 (2.0679e-01)\tAcc@1  93.75 ( 94.49)\tAcc@5  98.44 ( 99.18)\n",
            "Epoch: [143][ 90/391]\tTime  0.172 ( 0.174)\tLoss 2.5029e-01 (2.0826e-01)\tAcc@1  92.97 ( 94.50)\tAcc@5  99.22 ( 99.10)\n",
            "Epoch: [143][120/391]\tTime  0.174 ( 0.174)\tLoss 2.7210e-01 (2.0226e-01)\tAcc@1  92.97 ( 94.69)\tAcc@5  99.22 ( 99.17)\n",
            "Epoch: [143][150/391]\tTime  0.171 ( 0.174)\tLoss 1.8031e-01 (2.0105e-01)\tAcc@1  92.19 ( 94.84)\tAcc@5  99.22 ( 99.13)\n",
            "Epoch: [143][180/391]\tTime  0.175 ( 0.174)\tLoss 2.1019e-01 (2.0431e-01)\tAcc@1  94.53 ( 94.69)\tAcc@5 100.00 ( 99.13)\n",
            "Epoch: [143][210/391]\tTime  0.175 ( 0.174)\tLoss 9.3243e-02 (2.0326e-01)\tAcc@1  97.66 ( 94.71)\tAcc@5 100.00 ( 99.10)\n",
            "Epoch: [143][240/391]\tTime  0.173 ( 0.174)\tLoss 1.9904e-01 (2.0235e-01)\tAcc@1  94.53 ( 94.73)\tAcc@5 100.00 ( 99.09)\n",
            "Epoch: [143][270/391]\tTime  0.174 ( 0.174)\tLoss 2.2344e-01 (2.0107e-01)\tAcc@1  94.53 ( 94.75)\tAcc@5  98.44 ( 99.10)\n",
            "Epoch: [143][300/391]\tTime  0.172 ( 0.174)\tLoss 1.3551e-01 (2.0263e-01)\tAcc@1  96.09 ( 94.72)\tAcc@5 100.00 ( 99.10)\n",
            "Epoch: [143][330/391]\tTime  0.172 ( 0.174)\tLoss 2.4504e-01 (2.0316e-01)\tAcc@1  92.97 ( 94.71)\tAcc@5  98.44 ( 99.11)\n",
            "Epoch: [143][360/391]\tTime  0.173 ( 0.174)\tLoss 1.5569e-01 (2.0358e-01)\tAcc@1  94.53 ( 94.65)\tAcc@5  99.22 ( 99.11)\n",
            "Epoch: [143][390/391]\tTime  0.157 ( 0.173)\tLoss 3.2144e-01 (2.0299e-01)\tAcc@1  91.25 ( 94.66)\tAcc@5  98.75 ( 99.12)\n",
            "==> Train Accuracy: Acc@1 94.660 || Acc@5 99.120\n",
            "==> Test Accuracy:  Acc@1 77.240 || Acc@5 93.930\n",
            "==> 72.17 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 144, lr: 0.0008000000000000003 -----\n",
            "Epoch: [144][  0/391]\tTime  0.257 ( 0.257)\tLoss 1.6647e-01 (1.6647e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 30/391]\tTime  0.176 ( 0.176)\tLoss 1.4515e-01 (2.0573e-01)\tAcc@1  95.31 ( 94.30)\tAcc@5 100.00 ( 99.04)\n",
            "Epoch: [144][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.1448e-01 (2.0063e-01)\tAcc@1  96.88 ( 94.57)\tAcc@5  99.22 ( 99.09)\n",
            "Epoch: [144][ 90/391]\tTime  0.175 ( 0.174)\tLoss 1.6553e-01 (1.9617e-01)\tAcc@1  96.09 ( 94.64)\tAcc@5  99.22 ( 99.21)\n",
            "Epoch: [144][120/391]\tTime  0.172 ( 0.174)\tLoss 2.2896e-01 (1.9533e-01)\tAcc@1  94.53 ( 94.72)\tAcc@5  98.44 ( 99.22)\n",
            "Epoch: [144][150/391]\tTime  0.174 ( 0.174)\tLoss 1.9734e-01 (1.9420e-01)\tAcc@1  96.09 ( 94.75)\tAcc@5 100.00 ( 99.20)\n",
            "Epoch: [144][180/391]\tTime  0.173 ( 0.174)\tLoss 1.8949e-01 (1.9531e-01)\tAcc@1  93.75 ( 94.70)\tAcc@5 100.00 ( 99.20)\n",
            "Epoch: [144][210/391]\tTime  0.175 ( 0.174)\tLoss 1.7034e-01 (1.9528e-01)\tAcc@1  96.88 ( 94.70)\tAcc@5  99.22 ( 99.19)\n",
            "Epoch: [144][240/391]\tTime  0.171 ( 0.174)\tLoss 1.7186e-01 (1.9571e-01)\tAcc@1  96.09 ( 94.71)\tAcc@5 100.00 ( 99.21)\n",
            "Epoch: [144][270/391]\tTime  0.173 ( 0.174)\tLoss 1.8068e-01 (1.9702e-01)\tAcc@1  93.75 ( 94.65)\tAcc@5 100.00 ( 99.20)\n",
            "Epoch: [144][300/391]\tTime  0.171 ( 0.174)\tLoss 2.0812e-01 (1.9739e-01)\tAcc@1  94.53 ( 94.62)\tAcc@5  99.22 ( 99.19)\n",
            "Epoch: [144][330/391]\tTime  0.173 ( 0.174)\tLoss 1.3041e-01 (1.9675e-01)\tAcc@1  96.88 ( 94.66)\tAcc@5 100.00 ( 99.20)\n",
            "Epoch: [144][360/391]\tTime  0.175 ( 0.174)\tLoss 2.0391e-01 (1.9807e-01)\tAcc@1  95.31 ( 94.64)\tAcc@5  99.22 ( 99.18)\n",
            "Epoch: [144][390/391]\tTime  0.160 ( 0.174)\tLoss 3.4713e-01 (1.9844e-01)\tAcc@1  90.00 ( 94.65)\tAcc@5  97.50 ( 99.19)\n",
            "==> Train Accuracy: Acc@1 94.646 || Acc@5 99.186\n",
            "==> Test Accuracy:  Acc@1 77.190 || Acc@5 93.970\n",
            "==> 72.28 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 145, lr: 0.0008000000000000003 -----\n",
            "Epoch: [145][  0/391]\tTime  0.267 ( 0.267)\tLoss 2.8338e-01 (2.8338e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [145][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.9383e-01 (1.9945e-01)\tAcc@1  93.75 ( 94.58)\tAcc@5  99.22 ( 99.14)\n",
            "Epoch: [145][ 60/391]\tTime  0.174 ( 0.175)\tLoss 2.3381e-01 (1.9469e-01)\tAcc@1  92.19 ( 94.88)\tAcc@5 100.00 ( 99.24)\n",
            "Epoch: [145][ 90/391]\tTime  0.174 ( 0.175)\tLoss 2.2472e-01 (1.9532e-01)\tAcc@1  92.97 ( 94.84)\tAcc@5 100.00 ( 99.24)\n",
            "Epoch: [145][120/391]\tTime  0.174 ( 0.174)\tLoss 2.2456e-01 (1.9714e-01)\tAcc@1  93.75 ( 94.78)\tAcc@5 100.00 ( 99.23)\n",
            "Epoch: [145][150/391]\tTime  0.173 ( 0.174)\tLoss 3.1027e-01 (1.9925e-01)\tAcc@1  92.97 ( 94.76)\tAcc@5  96.88 ( 99.18)\n",
            "Epoch: [145][180/391]\tTime  0.171 ( 0.174)\tLoss 1.6276e-01 (1.9997e-01)\tAcc@1  96.09 ( 94.67)\tAcc@5  99.22 ( 99.15)\n",
            "Epoch: [145][210/391]\tTime  0.174 ( 0.174)\tLoss 1.0009e-01 (1.9847e-01)\tAcc@1  97.66 ( 94.71)\tAcc@5 100.00 ( 99.19)\n",
            "Epoch: [145][240/391]\tTime  0.173 ( 0.174)\tLoss 2.6139e-01 (1.9823e-01)\tAcc@1  92.97 ( 94.70)\tAcc@5  99.22 ( 99.21)\n",
            "Epoch: [145][270/391]\tTime  0.173 ( 0.174)\tLoss 1.5231e-01 (1.9651e-01)\tAcc@1  96.88 ( 94.76)\tAcc@5 100.00 ( 99.22)\n",
            "Epoch: [145][300/391]\tTime  0.174 ( 0.174)\tLoss 1.7987e-01 (1.9699e-01)\tAcc@1  95.31 ( 94.74)\tAcc@5  99.22 ( 99.19)\n",
            "Epoch: [145][330/391]\tTime  0.172 ( 0.174)\tLoss 3.1539e-01 (1.9670e-01)\tAcc@1  92.97 ( 94.73)\tAcc@5  98.44 ( 99.20)\n",
            "Epoch: [145][360/391]\tTime  0.175 ( 0.174)\tLoss 8.6558e-02 (1.9653e-01)\tAcc@1  98.44 ( 94.75)\tAcc@5 100.00 ( 99.19)\n",
            "Epoch: [145][390/391]\tTime  0.157 ( 0.174)\tLoss 1.3538e-01 (1.9723e-01)\tAcc@1  97.50 ( 94.75)\tAcc@5 100.00 ( 99.17)\n",
            "==> Train Accuracy: Acc@1 94.748 || Acc@5 99.172\n",
            "==> Test Accuracy:  Acc@1 77.180 || Acc@5 94.030\n",
            "==> 72.38 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 146, lr: 0.0008000000000000003 -----\n",
            "Epoch: [146][  0/391]\tTime  0.258 ( 0.258)\tLoss 1.0735e-01 (1.0735e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [146][ 30/391]\tTime  0.172 ( 0.176)\tLoss 1.8171e-01 (1.9752e-01)\tAcc@1  93.75 ( 94.86)\tAcc@5  99.22 ( 99.12)\n",
            "Epoch: [146][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.6101e-01 (1.8976e-01)\tAcc@1  96.09 ( 95.09)\tAcc@5  98.44 ( 99.15)\n",
            "Epoch: [146][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.7840e-01 (1.9057e-01)\tAcc@1  95.31 ( 95.08)\tAcc@5  99.22 ( 99.13)\n",
            "Epoch: [146][120/391]\tTime  0.177 ( 0.174)\tLoss 2.1426e-01 (1.8901e-01)\tAcc@1  93.75 ( 95.16)\tAcc@5  98.44 ( 99.15)\n",
            "Epoch: [146][150/391]\tTime  0.174 ( 0.174)\tLoss 1.4740e-01 (1.9149e-01)\tAcc@1  96.88 ( 95.10)\tAcc@5  98.44 ( 99.12)\n",
            "Epoch: [146][180/391]\tTime  0.174 ( 0.174)\tLoss 2.9689e-01 (1.9108e-01)\tAcc@1  92.97 ( 95.08)\tAcc@5  97.66 ( 99.11)\n",
            "Epoch: [146][210/391]\tTime  0.175 ( 0.174)\tLoss 1.4613e-01 (1.9179e-01)\tAcc@1  96.88 ( 95.06)\tAcc@5  99.22 ( 99.13)\n",
            "Epoch: [146][240/391]\tTime  0.172 ( 0.174)\tLoss 2.2949e-01 (1.9165e-01)\tAcc@1  94.53 ( 95.04)\tAcc@5  99.22 ( 99.14)\n",
            "Epoch: [146][270/391]\tTime  0.174 ( 0.174)\tLoss 1.1434e-01 (1.9326e-01)\tAcc@1  97.66 ( 94.97)\tAcc@5 100.00 ( 99.12)\n",
            "Epoch: [146][300/391]\tTime  0.174 ( 0.174)\tLoss 2.1880e-01 (1.9372e-01)\tAcc@1  95.31 ( 94.95)\tAcc@5 100.00 ( 99.13)\n",
            "Epoch: [146][330/391]\tTime  0.174 ( 0.174)\tLoss 2.3752e-01 (1.9203e-01)\tAcc@1  94.53 ( 95.01)\tAcc@5  96.88 ( 99.14)\n",
            "Epoch: [146][360/391]\tTime  0.173 ( 0.174)\tLoss 1.7316e-01 (1.9228e-01)\tAcc@1  95.31 ( 95.02)\tAcc@5  99.22 ( 99.13)\n",
            "Epoch: [146][390/391]\tTime  0.157 ( 0.174)\tLoss 2.0409e-01 (1.9195e-01)\tAcc@1  95.00 ( 95.03)\tAcc@5  98.75 ( 99.14)\n",
            "==> Train Accuracy: Acc@1 95.034 || Acc@5 99.136\n",
            "==> Test Accuracy:  Acc@1 77.120 || Acc@5 94.030\n",
            "==> 72.37 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 147, lr: 0.0008000000000000003 -----\n",
            "Epoch: [147][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.4099e-01 (1.4099e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][ 30/391]\tTime  0.174 ( 0.176)\tLoss 2.6157e-01 (1.8612e-01)\tAcc@1  91.41 ( 95.06)\tAcc@5  99.22 ( 99.27)\n",
            "Epoch: [147][ 60/391]\tTime  0.180 ( 0.175)\tLoss 3.9737e-01 (2.0322e-01)\tAcc@1  91.41 ( 94.54)\tAcc@5  96.09 ( 99.10)\n",
            "Epoch: [147][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.3931e-01 (1.9624e-01)\tAcc@1  96.09 ( 94.70)\tAcc@5  99.22 ( 99.15)\n",
            "Epoch: [147][120/391]\tTime  0.175 ( 0.174)\tLoss 1.3239e-01 (1.9366e-01)\tAcc@1  96.88 ( 94.80)\tAcc@5 100.00 ( 99.21)\n",
            "Epoch: [147][150/391]\tTime  0.172 ( 0.174)\tLoss 2.5233e-01 (1.9466e-01)\tAcc@1  92.19 ( 94.78)\tAcc@5  98.44 ( 99.18)\n",
            "Epoch: [147][180/391]\tTime  0.175 ( 0.174)\tLoss 3.1192e-01 (1.9481e-01)\tAcc@1  89.84 ( 94.78)\tAcc@5  98.44 ( 99.18)\n",
            "Epoch: [147][210/391]\tTime  0.177 ( 0.174)\tLoss 1.4308e-01 (1.9558e-01)\tAcc@1  96.88 ( 94.80)\tAcc@5  99.22 ( 99.16)\n",
            "Epoch: [147][240/391]\tTime  0.172 ( 0.174)\tLoss 1.0685e-01 (1.9483e-01)\tAcc@1  97.66 ( 94.83)\tAcc@5 100.00 ( 99.18)\n",
            "Epoch: [147][270/391]\tTime  0.175 ( 0.174)\tLoss 2.1711e-01 (1.9486e-01)\tAcc@1  94.53 ( 94.87)\tAcc@5 100.00 ( 99.18)\n",
            "Epoch: [147][300/391]\tTime  0.175 ( 0.174)\tLoss 2.4894e-01 (1.9389e-01)\tAcc@1  92.19 ( 94.89)\tAcc@5  98.44 ( 99.19)\n",
            "Epoch: [147][330/391]\tTime  0.172 ( 0.174)\tLoss 1.4807e-01 (1.9374e-01)\tAcc@1  96.88 ( 94.89)\tAcc@5 100.00 ( 99.19)\n",
            "Epoch: [147][360/391]\tTime  0.173 ( 0.174)\tLoss 2.0830e-01 (1.9376e-01)\tAcc@1  95.31 ( 94.87)\tAcc@5  98.44 ( 99.19)\n",
            "Epoch: [147][390/391]\tTime  0.155 ( 0.174)\tLoss 2.2151e-01 (1.9331e-01)\tAcc@1  95.00 ( 94.88)\tAcc@5 100.00 ( 99.19)\n",
            "==> Train Accuracy: Acc@1 94.882 || Acc@5 99.192\n",
            "==> Test Accuracy:  Acc@1 77.240 || Acc@5 93.930\n",
            "==> 72.33 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 148, lr: 0.0008000000000000003 -----\n",
            "Epoch: [148][  0/391]\tTime  0.279 ( 0.279)\tLoss 1.5513e-01 (1.5513e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [148][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.9940e-01 (1.9122e-01)\tAcc@1  92.19 ( 94.71)\tAcc@5  99.22 ( 99.12)\n",
            "Epoch: [148][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.4789e-01 (1.8859e-01)\tAcc@1  96.09 ( 94.81)\tAcc@5 100.00 ( 99.24)\n",
            "Epoch: [148][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.6646e-01 (1.9079e-01)\tAcc@1  96.88 ( 94.82)\tAcc@5 100.00 ( 99.19)\n",
            "Epoch: [148][120/391]\tTime  0.176 ( 0.174)\tLoss 3.0005e-01 (1.9145e-01)\tAcc@1  92.19 ( 94.80)\tAcc@5  98.44 ( 99.19)\n",
            "Epoch: [148][150/391]\tTime  0.174 ( 0.174)\tLoss 9.5292e-02 (1.8886e-01)\tAcc@1  96.88 ( 94.93)\tAcc@5 100.00 ( 99.22)\n",
            "Epoch: [148][180/391]\tTime  0.172 ( 0.174)\tLoss 2.1864e-01 (1.9169e-01)\tAcc@1  92.97 ( 94.87)\tAcc@5  99.22 ( 99.19)\n",
            "Epoch: [148][210/391]\tTime  0.174 ( 0.174)\tLoss 1.5768e-01 (1.9187e-01)\tAcc@1  96.09 ( 94.85)\tAcc@5  99.22 ( 99.19)\n",
            "Epoch: [148][240/391]\tTime  0.174 ( 0.174)\tLoss 2.1696e-01 (1.9306e-01)\tAcc@1  94.53 ( 94.84)\tAcc@5  97.66 ( 99.16)\n",
            "Epoch: [148][270/391]\tTime  0.173 ( 0.174)\tLoss 9.3601e-02 (1.9395e-01)\tAcc@1  98.44 ( 94.85)\tAcc@5  99.22 ( 99.14)\n",
            "Epoch: [148][300/391]\tTime  0.173 ( 0.174)\tLoss 2.5551e-01 (1.9380e-01)\tAcc@1  92.19 ( 94.86)\tAcc@5  98.44 ( 99.12)\n",
            "Epoch: [148][330/391]\tTime  0.171 ( 0.174)\tLoss 1.2247e-01 (1.9184e-01)\tAcc@1  95.31 ( 94.91)\tAcc@5 100.00 ( 99.15)\n",
            "Epoch: [148][360/391]\tTime  0.173 ( 0.174)\tLoss 1.6374e-01 (1.9290e-01)\tAcc@1  94.53 ( 94.90)\tAcc@5  99.22 ( 99.13)\n",
            "Epoch: [148][390/391]\tTime  0.155 ( 0.174)\tLoss 2.2474e-01 (1.9193e-01)\tAcc@1  92.50 ( 94.92)\tAcc@5  98.75 ( 99.14)\n",
            "==> Train Accuracy: Acc@1 94.922 || Acc@5 99.136\n",
            "==> Test Accuracy:  Acc@1 77.380 || Acc@5 93.890\n",
            "==> 72.28 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 149, lr: 0.0008000000000000003 -----\n",
            "Epoch: [149][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.7491e-01 (1.7491e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [149][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.8576e-01 (1.9305e-01)\tAcc@1  93.75 ( 94.71)\tAcc@5 100.00 ( 99.12)\n",
            "Epoch: [149][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.3479e-01 (1.9545e-01)\tAcc@1  96.09 ( 94.84)\tAcc@5 100.00 ( 99.01)\n",
            "Epoch: [149][ 90/391]\tTime  0.173 ( 0.174)\tLoss 2.0953e-01 (1.9648e-01)\tAcc@1  93.75 ( 94.74)\tAcc@5 100.00 ( 99.10)\n",
            "Epoch: [149][120/391]\tTime  0.173 ( 0.174)\tLoss 1.4218e-01 (1.9575e-01)\tAcc@1  95.31 ( 94.71)\tAcc@5 100.00 ( 99.13)\n",
            "Epoch: [149][150/391]\tTime  0.174 ( 0.174)\tLoss 2.3496e-01 (1.9192e-01)\tAcc@1  94.53 ( 94.91)\tAcc@5  98.44 ( 99.17)\n",
            "Epoch: [149][180/391]\tTime  0.172 ( 0.174)\tLoss 1.9830e-01 (1.9475e-01)\tAcc@1  96.09 ( 94.89)\tAcc@5  99.22 ( 99.11)\n",
            "Epoch: [149][210/391]\tTime  0.174 ( 0.174)\tLoss 1.1984e-01 (1.9141e-01)\tAcc@1  96.88 ( 95.01)\tAcc@5  99.22 ( 99.15)\n",
            "Epoch: [149][240/391]\tTime  0.168 ( 0.174)\tLoss 2.3837e-01 (1.9035e-01)\tAcc@1  91.41 ( 95.01)\tAcc@5 100.00 ( 99.16)\n",
            "Epoch: [149][270/391]\tTime  0.175 ( 0.174)\tLoss 1.2669e-01 (1.9082e-01)\tAcc@1  96.88 ( 95.04)\tAcc@5  99.22 ( 99.15)\n",
            "Epoch: [149][300/391]\tTime  0.174 ( 0.174)\tLoss 2.1751e-01 (1.9234e-01)\tAcc@1  95.31 ( 94.99)\tAcc@5 100.00 ( 99.13)\n",
            "Epoch: [149][330/391]\tTime  0.173 ( 0.174)\tLoss 2.0377e-01 (1.9259e-01)\tAcc@1  95.31 ( 94.97)\tAcc@5  98.44 ( 99.12)\n",
            "Epoch: [149][360/391]\tTime  0.173 ( 0.174)\tLoss 1.9920e-01 (1.9199e-01)\tAcc@1  92.97 ( 94.99)\tAcc@5  99.22 ( 99.14)\n",
            "Epoch: [149][390/391]\tTime  0.157 ( 0.174)\tLoss 1.8816e-01 (1.9256e-01)\tAcc@1  95.00 ( 94.96)\tAcc@5 100.00 ( 99.13)\n",
            "==> Train Accuracy: Acc@1 94.960 || Acc@5 99.130\n",
            "==> Test Accuracy:  Acc@1 77.070 || Acc@5 93.840\n",
            "==> 72.19 seconds to train this epoch\n",
            "\n",
            "Best Top-1 Accuracy: 77.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB3-eyvkZJGE"
      },
      "source": [
        "ㅍㄹ"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}