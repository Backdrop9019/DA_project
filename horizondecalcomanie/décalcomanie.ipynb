{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"décalcomanie.ipynb","provenance":[{"file_id":"18b80wpeQD1Wj6NjwZFFhZGDuMWWW1TIZ","timestamp":1620369163076},{"file_id":"1pSPNcOLDPSKONSeGALl1Jplu9ET9z-1q","timestamp":1619081668342}],"collapsed_sections":["vCVSE5-UboYl","L88afYXKMSdL","qjM3cl279Lvg","o6y3zhSfMbdC","9s8oXpzdMvol"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OSFGYaIDG6f0"},"source":["Cutout Data Augmentation.\n","\n","This code is implmented by following the official code (https://github.com/uoguelph-mlrg/Cutout)\n"]},{"cell_type":"markdown","metadata":{"id":"vCVSE5-UboYl"},"source":["##**Import all neceassary packages**"]},{"cell_type":"code","metadata":{"id":"5YBMwPsubsbX","executionInfo":{"status":"ok","timestamp":1620540016000,"user_tz":-540,"elapsed":4678,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}}},"source":["import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.optim.lr_scheduler import MultiStepLR\n","\n","from torchvision import datasets, transforms\n","\n","from tqdm.notebook import tqdm as tqdm\n","import matplotlib.pyplot as plt\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L88afYXKMSdL"},"source":["##**Model - Define ResNet Model**"]},{"cell_type":"code","metadata":{"id":"eMFSLTnkMQdq","executionInfo":{"status":"ok","timestamp":1620540016001,"user_tz":-540,"elapsed":4127,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}}},"source":["'''ResNet18/34/50/101/152 in Pytorch.'''\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18(num_classes=10):\n","    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n","\n","def ResNet34(num_classes=10):\n","    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n","\n","def ResNet50(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n","\n","def ResNet101(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n","\n","def ResNet152(num_classes=10):\n","    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n","\n","def test_resnet():\n","    net = ResNet50()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test_resnet()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjM3cl279Lvg"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"gIvuSgE49Kvu","executionInfo":{"status":"ok","timestamp":1620540016001,"user_tz":-540,"elapsed":3540,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}}},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6y3zhSfMbdC"},"source":["##**Cutout: Main Code for Applying Cutout data augmentation**"]},{"cell_type":"code","metadata":{"id":"gg5mBMBX_pzn","executionInfo":{"status":"ok","timestamp":1620525625256,"user_tz":-540,"elapsed":1706,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}}},"source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img\n","        "],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QT-ndK6vXavT"},"source":["## horizon décalcomanie\n"]},{"cell_type":"code","metadata":{"id":"gcYQbQ-xXdKT","executionInfo":{"status":"ok","timestamp":1620541543596,"user_tz":-540,"elapsed":612,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}}},"source":["class RandomHorizonDecalcomanie(torch.nn.Module):\n","\n","\n","    def __init__(self, p=0.8):\n","        super().__init__()\n","        self.p = p\n","\n","    def forward(self, img):\n","\n","        if torch.rand(1) < self.p:\n","\n","            if  torch.rand(1) < self.p:\n","              #vertical\n","              if torch.rand(1) < self.p:\n","                #left Decalcomanie\n","                  return torch.cat((img[:,:16,:32], torch.flip(img,[1])[:,16:,:32]), 1)\n","              else:\n","                #right Decalcomanie\n","                  return torch.cat(( torch.flip(img,[1])[:,:16,:32], img[:,16:,:32]), 1)\n","            else:\n","              #horizon\n","              if torch.rand(1) < self.p:\n","                #left Decalcomanie\n","                  return torch.cat((img[:,:32,:16], torch.flip(img,[2])[:,:32,16:]), 2)\n","              else:\n","                #right Decalcomanie\n","                  return torch.cat(( torch.flip(img,[2])[:,:32,:16], img[:,:32,16:]), 2)\n","\n","        return img\n","\n"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7QzOKgyhTDP","executionInfo":{"status":"ok","timestamp":1620539352539,"user_tz":-540,"elapsed":2226,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}},"outputId":"49325327-a209-4a94-e489-6bf870713a57"},"source":["x=torch.tensor([1,2,3,])\n","x[:3]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"b6qOjyp7Z00l","executionInfo":{"status":"ok","timestamp":1620541600489,"user_tz":-540,"elapsed":861,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}},"outputId":"f0f309a2-9e47-4569-d4fe-1445c5bbdc77"},"source":["x1 = train_dataset[15][0]\n","plt.subplot(121)\n","plt.imshow(x1.permute(1,2,0))\n","# x2 = torch.flip(x1,[1])\n","# plt.subplot(122)\n","# plt.imshow(x2.permute(1,2,0))\n","# plt.show()"],"execution_count":74,"outputs":[{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f52c173e150>"]},"metadata":{"tags":[]},"execution_count":74},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uNj89vnHc4U5","executionInfo":{"status":"ok","timestamp":1620539352540,"user_tz":-540,"elapsed":2215,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}},"outputId":"de081262-1175-42c2-a711-b1adb0a60668"},"source":["x1[:,:15,:].shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 15, 32])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BiSzEc_zehFF","executionInfo":{"status":"ok","timestamp":1620539352540,"user_tz":-540,"elapsed":2210,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}},"outputId":"61b9bd43-09ec-4c68-f6f2-0ad62941702a"},"source":["len(train_dataset)\n"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50000"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"zqXg8xHqcWZl","executionInfo":{"status":"ok","timestamp":1620541169627,"user_tz":-540,"elapsed":1121,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}},"outputId":"907bbcb2-fc9e-4701-8745-15c1e80e60fa"},"source":["img = train_dataset[5][0]\n","\n","plt.subplot(131)\n","plt.imshow(img.permute(1,2,0))\n","\n","plt.subplot(132)\n","\n","x =torch.cat((img[:,:16,:32], torch.flip(img,[1])[:,16:,:32]), 1)\n","plt.imshow(x.permute(1,2,0))\n","plt.subplot(133)\n","x =torch.cat(( torch.flip(img,[1])[:,:16,:32], img[:,16:,:32]), 1)\n","plt.imshow(x.permute(1,2,0))\n"],"execution_count":54,"outputs":[{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f52c12677d0>"]},"metadata":{"tags":[]},"execution_count":54},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 3 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n2SAUX9yfBU6","executionInfo":{"status":"ok","timestamp":1620539352948,"user_tz":-540,"elapsed":2606,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}},"outputId":"e0012d42-688d-4d6e-e6d8-86938ee2a0f7"},"source":["print(torch.rand(1))\n","print(torch.rand(1))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["tensor([0.5955])\n","tensor([0.6180])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enFd93fQbvJG","executionInfo":{"status":"ok","timestamp":1620539352949,"user_tz":-540,"elapsed":2602,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}},"outputId":"37e2f16d-8f4a-4514-a0f9-86aedb80af50"},"source":["x = torch.arange(8).view(2, 2, 2)\n","print(x)\n","print(torch.flip(x,[2]))\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["tensor([[[0, 1],\n","         [2, 3]],\n","\n","        [[4, 5],\n","         [6, 7]]])\n","tensor([[[1, 0],\n","         [3, 2]],\n","\n","        [[5, 4],\n","         [7, 6]]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9s8oXpzdMvol"},"source":["##**Parameter Settings**"]},{"cell_type":"code","metadata":{"id":"Pjeqawi9cNK6","executionInfo":{"status":"ok","timestamp":1620540018228,"user_tz":-540,"elapsed":787,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}}},"source":["dataset = 'cifar100' # cifar10 or cifar100\n","model = 'resnet34' # resnet18, resnet50, resnet101\n","batch_size = 128  # Input batch size for training (default: 128)\n","epochs = 150 # Number of epochs to train (default: 200)\n","learning_rate = 0.1 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","cutout = False # Apply Cutout?\n","mixup = False # Apply Mixup?\n","Decalcomanie = True # Apply Mixup?\n","n_holes = 1 # Number of holes to cut out from image\n","length = 16 # Length of the holes\n","seed = 0 # Random seed (default: 0)\n","print_freq = 30\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eXL_PBj6cVoe"},"source":["##**Load and preprocess data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dvQjH3T9caYs","executionInfo":{"status":"ok","timestamp":1620541577496,"user_tz":-540,"elapsed":2060,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}},"outputId":"1d64348c-05b4-44ef-ff4a-9aa157ba3ead"},"source":["# Image Preprocessing\n","normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n","                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n","\n","train_transform = transforms.Compose([])\n","if data_augmentation:\n","    train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n","    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n","train_transform.transforms.append(transforms.ToTensor())\n","train_transform.transforms.append(normalize)\n","if Decalcomanie:\n","    train_transform.transforms.append(RandomHorizonDecalcomanie())\n","\n","if cutout:\n","    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n","\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize\n","    ])\n","\n","if dataset == 'cifar10':\n","    num_classes = 10\n","    train_dataset = datasets.CIFAR10(root='data/',\n","                                     train=True,\n","                                     transform=train_transform,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root='data/',\n","                                    train=False,\n","                                    transform=test_transform,\n","                                    download=True)\n","elif dataset == 'cifar100':\n","    num_classes = 100\n","    train_dataset = datasets.CIFAR100(root='data/',\n","                                      train=True,\n","                                      transform=train_transform,\n","                                      download=True)\n","\n","    test_dataset = datasets.CIFAR100(root='data/',\n","                                     train=False,\n","                                     transform=test_transform,\n","                                     download=True)\n","\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           pin_memory=True,\n","                                           num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)"],"execution_count":62,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AyTkXquJIlFC"},"source":["## print image"]},{"cell_type":"code","metadata":{"id":"tukgHLt_NR8D","executionInfo":{"status":"ok","timestamp":1620498209858,"user_tz":-540,"elapsed":5207,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}}},"source":["input =  list(train_loader)[0]    \n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJ_ce67hOOFJ","executionInfo":{"status":"ok","timestamp":1620498251126,"user_tz":-540,"elapsed":595,"user":{"displayName":"‍배경호[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"03881362194087764918"}},"outputId":"7ecd5773-3bc4-4d9f-c056-967b01425996"},"source":["input[1]"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0, 46, 36, 88,  8, 53, 43, 79,  3, 91, 98, 67, 25, 11, 18, 16, 66, 81,\n","        40, 51, 60, 85, 44, 70, 93, 75, 37, 54, 67, 40, 50, 84, 42, 43,  5, 40,\n","        60, 52, 42, 50, 92, 53, 84, 65, 63, 16, 52,  2, 80,  6, 53, 10, 50, 80,\n","        57, 51, 88, 18, 61, 53, 48, 84, 26, 46,  0,  7, 47, 59, 83,  0, 45, 31,\n","        43, 37, 17, 44, 55, 13, 20, 81, 97, 67, 50,  4, 19, 47,  7, 20, 41, 93,\n","        45, 99, 11, 56, 54, 13, 86, 29, 17, 79, 83, 21, 28, 24, 84, 53, 15, 32,\n","        85, 17, 14, 13, 10, 18, 10, 50, 48, 42, 37, 49, 42, 46, 66, 18, 68, 93,\n","         8, 82])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"gITLQIAr9lAZ"},"source":["##**Main Training**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s0-lYvAp9oHA","outputId":"71ba0028-0fe4-4eac-9179-dc312eb97189"},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n"," \n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","        if mixup:\n","          input, targets_a, targets_b, lam = mixup_data(input, target)\n","\n","\n","\n","        # compute output\n","        output = model(input)\n","        if mixup:\n","          loss = mixup_criterion(criterion,output, targets_a,targets_b,lam)\n","          \n","        else:\n","          loss = criterion(output, target)\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def test(test_loader,epoch, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    model.eval()\n","    for i,(input,target) in enumerate(test_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","model = ResNet34(num_classes=num_classes).cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n","\n","scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n","\n","criterion = torch.nn.CrossEntropyLoss().cuda()\n","\n","###########################################################\n","best_acc = 0\n","for epoch in range(epochs):\n","    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n","        epoch, optimizer.param_groups[0][\"lr\"]))\n","\n","    # train for one epoch\n","    start_time = time.time()\n","    train(train_loader, epoch, model, optimizer, criterion)\n","    test_acc = test(test_loader,epoch,model)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    # learning rate scheduling\n","    scheduler.step()\n","    \n","    # Save model for best accuracy\n","    if best_acc < test_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), 'model_best.pt')\n","\n","torch.save(model.state_dict(),'model_latest.pt')\n","print(f\"Best Top-1 Accuracy: {best_acc}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","----- epoch: 0, lr: 0.1 -----\n","Epoch: [0][  0/391]\tTime  1.242 ( 1.242)\tLoss 4.7454e+00 (4.7454e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   4.69 (  4.69)\n","Epoch: [0][ 30/391]\tTime  0.159 ( 0.190)\tLoss 4.6094e+00 (5.1483e+00)\tAcc@1   0.00 (  1.46)\tAcc@5   4.69 (  6.02)\n","Epoch: [0][ 60/391]\tTime  0.160 ( 0.175)\tLoss 4.4914e+00 (4.8938e+00)\tAcc@1   3.12 (  1.65)\tAcc@5  15.62 (  6.86)\n","Epoch: [0][ 90/391]\tTime  0.158 ( 0.170)\tLoss 4.5027e+00 (4.7687e+00)\tAcc@1   2.34 (  2.00)\tAcc@5  11.72 (  8.04)\n","Epoch: [0][120/391]\tTime  0.161 ( 0.167)\tLoss 4.3688e+00 (4.6770e+00)\tAcc@1   5.47 (  2.33)\tAcc@5  15.62 (  9.47)\n","Epoch: [0][150/391]\tTime  0.161 ( 0.166)\tLoss 4.1970e+00 (4.6090e+00)\tAcc@1   4.69 (  2.56)\tAcc@5  15.62 ( 10.55)\n","Epoch: [0][180/391]\tTime  0.159 ( 0.165)\tLoss 4.1865e+00 (4.5527e+00)\tAcc@1   7.03 (  2.76)\tAcc@5  21.88 ( 11.62)\n","Epoch: [0][210/391]\tTime  0.162 ( 0.165)\tLoss 4.2443e+00 (4.5134e+00)\tAcc@1   0.78 (  2.87)\tAcc@5  14.06 ( 12.27)\n","Epoch: [0][240/391]\tTime  0.164 ( 0.164)\tLoss 4.1867e+00 (4.4787e+00)\tAcc@1   3.91 (  2.98)\tAcc@5  17.19 ( 12.93)\n","Epoch: [0][270/391]\tTime  0.165 ( 0.164)\tLoss 4.2374e+00 (4.4439e+00)\tAcc@1   4.69 (  3.18)\tAcc@5  17.97 ( 13.67)\n","Epoch: [0][300/391]\tTime  0.164 ( 0.164)\tLoss 4.0385e+00 (4.4158e+00)\tAcc@1   4.69 (  3.32)\tAcc@5  21.88 ( 14.28)\n","Epoch: [0][330/391]\tTime  0.166 ( 0.164)\tLoss 4.1736e+00 (4.3876e+00)\tAcc@1   5.47 (  3.54)\tAcc@5  19.53 ( 15.00)\n","Epoch: [0][360/391]\tTime  0.166 ( 0.164)\tLoss 4.0608e+00 (4.3616e+00)\tAcc@1   8.59 (  3.86)\tAcc@5  22.66 ( 15.76)\n","Epoch: [0][390/391]\tTime  0.701 ( 0.166)\tLoss 3.9889e+00 (4.3376e+00)\tAcc@1  10.00 (  4.03)\tAcc@5  27.50 ( 16.39)\n","==> Train Accuracy: Acc@1 4.028 || Acc@5 16.392\n","==> Test Accuracy:  Acc@1 7.400 || Acc@5 25.550\n","==> 69.12 seconds to train this epoch\n","\n","\n","----- epoch: 1, lr: 0.1 -----\n","Epoch: [1][  0/391]\tTime  0.248 ( 0.248)\tLoss 4.0808e+00 (4.0808e+00)\tAcc@1   5.47 (  5.47)\tAcc@5  20.31 ( 20.31)\n","Epoch: [1][ 30/391]\tTime  0.167 ( 0.170)\tLoss 3.9195e+00 (4.0038e+00)\tAcc@1   6.25 (  7.41)\tAcc@5  26.56 ( 26.51)\n","Epoch: [1][ 60/391]\tTime  0.168 ( 0.169)\tLoss 3.9031e+00 (4.0219e+00)\tAcc@1   9.38 (  7.34)\tAcc@5  21.88 ( 25.58)\n","Epoch: [1][ 90/391]\tTime  0.168 ( 0.169)\tLoss 3.9660e+00 (3.9980e+00)\tAcc@1  10.16 (  7.55)\tAcc@5  27.34 ( 26.23)\n","Epoch: [1][120/391]\tTime  0.170 ( 0.169)\tLoss 3.8377e+00 (3.9782e+00)\tAcc@1   8.59 (  7.85)\tAcc@5  31.25 ( 26.79)\n","Epoch: [1][150/391]\tTime  0.171 ( 0.170)\tLoss 3.9577e+00 (3.9649e+00)\tAcc@1   7.81 (  8.11)\tAcc@5  31.25 ( 27.22)\n","Epoch: [1][180/391]\tTime  0.170 ( 0.170)\tLoss 3.9453e+00 (3.9578e+00)\tAcc@1   7.81 (  8.27)\tAcc@5  30.47 ( 27.47)\n","Epoch: [1][210/391]\tTime  0.169 ( 0.170)\tLoss 3.8682e+00 (3.9458e+00)\tAcc@1  13.28 (  8.45)\tAcc@5  28.91 ( 27.68)\n","Epoch: [1][240/391]\tTime  0.170 ( 0.170)\tLoss 3.6760e+00 (3.9306e+00)\tAcc@1  13.28 (  8.59)\tAcc@5  35.94 ( 28.32)\n","Epoch: [1][270/391]\tTime  0.169 ( 0.170)\tLoss 3.9793e+00 (3.9194e+00)\tAcc@1   7.81 (  8.78)\tAcc@5  25.78 ( 28.72)\n","Epoch: [1][300/391]\tTime  0.170 ( 0.170)\tLoss 3.6892e+00 (3.9054e+00)\tAcc@1  17.19 (  9.02)\tAcc@5  41.41 ( 29.16)\n","Epoch: [1][330/391]\tTime  0.169 ( 0.170)\tLoss 3.8577e+00 (3.8974e+00)\tAcc@1   9.38 (  9.09)\tAcc@5  31.25 ( 29.47)\n","Epoch: [1][360/391]\tTime  0.168 ( 0.170)\tLoss 3.5967e+00 (3.8861e+00)\tAcc@1  14.06 (  9.28)\tAcc@5  39.84 ( 29.78)\n","Epoch: [1][390/391]\tTime  0.150 ( 0.170)\tLoss 3.7405e+00 (3.8744e+00)\tAcc@1   6.25 (  9.42)\tAcc@5  37.50 ( 30.18)\n","==> Train Accuracy: Acc@1 9.418 || Acc@5 30.182\n","==> Test Accuracy:  Acc@1 15.380 || Acc@5 40.260\n","==> 70.51 seconds to train this epoch\n","\n","\n","----- epoch: 2, lr: 0.1 -----\n","Epoch: [2][  0/391]\tTime  0.249 ( 0.249)\tLoss 3.7997e+00 (3.7997e+00)\tAcc@1  12.50 ( 12.50)\tAcc@5  32.03 ( 32.03)\n","Epoch: [2][ 30/391]\tTime  0.169 ( 0.171)\tLoss 3.6506e+00 (3.7371e+00)\tAcc@1  14.84 ( 11.54)\tAcc@5  36.72 ( 34.27)\n","Epoch: [2][ 60/391]\tTime  0.170 ( 0.170)\tLoss 3.5785e+00 (3.7165e+00)\tAcc@1  10.94 ( 11.41)\tAcc@5  32.81 ( 34.46)\n","Epoch: [2][ 90/391]\tTime  0.169 ( 0.169)\tLoss 3.5136e+00 (3.6987e+00)\tAcc@1  17.19 ( 11.55)\tAcc@5  42.97 ( 35.25)\n","Epoch: [2][120/391]\tTime  0.169 ( 0.169)\tLoss 3.6598e+00 (3.6935e+00)\tAcc@1  10.94 ( 11.76)\tAcc@5  37.50 ( 35.58)\n","Epoch: [2][150/391]\tTime  0.170 ( 0.169)\tLoss 3.6149e+00 (3.6785e+00)\tAcc@1   7.81 ( 11.97)\tAcc@5  42.97 ( 36.12)\n","Epoch: [2][180/391]\tTime  0.170 ( 0.169)\tLoss 3.6628e+00 (3.6634e+00)\tAcc@1   8.59 ( 12.23)\tAcc@5  40.62 ( 36.57)\n","Epoch: [2][210/391]\tTime  0.171 ( 0.169)\tLoss 3.5609e+00 (3.6508e+00)\tAcc@1  13.28 ( 12.60)\tAcc@5  39.84 ( 37.30)\n","Epoch: [2][240/391]\tTime  0.171 ( 0.169)\tLoss 3.4361e+00 (3.6388e+00)\tAcc@1  19.53 ( 12.86)\tAcc@5  46.88 ( 37.72)\n","Epoch: [2][270/391]\tTime  0.170 ( 0.169)\tLoss 3.1742e+00 (3.6220e+00)\tAcc@1  17.97 ( 13.18)\tAcc@5  52.34 ( 38.24)\n","Epoch: [2][300/391]\tTime  0.171 ( 0.169)\tLoss 3.5575e+00 (3.6136e+00)\tAcc@1  12.50 ( 13.36)\tAcc@5  39.06 ( 38.53)\n","Epoch: [2][330/391]\tTime  0.170 ( 0.169)\tLoss 3.5370e+00 (3.6039e+00)\tAcc@1   8.59 ( 13.57)\tAcc@5  40.62 ( 38.75)\n","Epoch: [2][360/391]\tTime  0.169 ( 0.169)\tLoss 3.4551e+00 (3.5937e+00)\tAcc@1  15.62 ( 13.84)\tAcc@5  38.28 ( 39.11)\n","Epoch: [2][390/391]\tTime  0.150 ( 0.169)\tLoss 3.5855e+00 (3.5847e+00)\tAcc@1   7.50 ( 14.02)\tAcc@5  37.50 ( 39.38)\n","==> Train Accuracy: Acc@1 14.016 || Acc@5 39.380\n","==> Test Accuracy:  Acc@1 19.070 || Acc@5 47.730\n","==> 70.40 seconds to train this epoch\n","\n","\n","----- epoch: 3, lr: 0.1 -----\n","Epoch: [3][  0/391]\tTime  0.254 ( 0.254)\tLoss 3.3589e+00 (3.3589e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  48.44 ( 48.44)\n","Epoch: [3][ 30/391]\tTime  0.171 ( 0.171)\tLoss 3.5531e+00 (3.4552e+00)\tAcc@1  19.53 ( 16.61)\tAcc@5  42.19 ( 44.10)\n","Epoch: [3][ 60/391]\tTime  0.170 ( 0.170)\tLoss 3.1701e+00 (3.4397e+00)\tAcc@1  18.75 ( 16.47)\tAcc@5  50.78 ( 44.10)\n","Epoch: [3][ 90/391]\tTime  0.171 ( 0.170)\tLoss 3.3756e+00 (3.4171e+00)\tAcc@1  21.88 ( 16.88)\tAcc@5  46.88 ( 44.23)\n","Epoch: [3][120/391]\tTime  0.170 ( 0.170)\tLoss 3.4866e+00 (3.4078e+00)\tAcc@1  15.62 ( 17.14)\tAcc@5  39.06 ( 44.45)\n","Epoch: [3][150/391]\tTime  0.170 ( 0.170)\tLoss 3.5182e+00 (3.4011e+00)\tAcc@1  17.97 ( 17.20)\tAcc@5  42.19 ( 44.72)\n","Epoch: [3][180/391]\tTime  0.168 ( 0.170)\tLoss 3.2087e+00 (3.3905e+00)\tAcc@1  22.66 ( 17.48)\tAcc@5  53.91 ( 44.85)\n","Epoch: [3][210/391]\tTime  0.169 ( 0.170)\tLoss 3.4947e+00 (3.3842e+00)\tAcc@1  21.88 ( 17.59)\tAcc@5  44.53 ( 45.05)\n","Epoch: [3][240/391]\tTime  0.170 ( 0.169)\tLoss 3.4220e+00 (3.3768e+00)\tAcc@1  17.19 ( 17.59)\tAcc@5  45.31 ( 45.36)\n","Epoch: [3][270/391]\tTime  0.168 ( 0.169)\tLoss 3.3786e+00 (3.3713e+00)\tAcc@1  21.88 ( 17.75)\tAcc@5  42.97 ( 45.53)\n","Epoch: [3][300/391]\tTime  0.169 ( 0.169)\tLoss 3.3085e+00 (3.3673e+00)\tAcc@1  17.19 ( 17.85)\tAcc@5  43.75 ( 45.68)\n","Epoch: [3][330/391]\tTime  0.170 ( 0.169)\tLoss 3.4390e+00 (3.3588e+00)\tAcc@1  17.97 ( 18.08)\tAcc@5  43.75 ( 45.90)\n","Epoch: [3][360/391]\tTime  0.169 ( 0.169)\tLoss 3.3402e+00 (3.3491e+00)\tAcc@1  24.22 ( 18.30)\tAcc@5  47.66 ( 46.22)\n","Epoch: [3][390/391]\tTime  0.152 ( 0.169)\tLoss 3.1490e+00 (3.3417e+00)\tAcc@1  23.75 ( 18.45)\tAcc@5  50.00 ( 46.43)\n","==> Train Accuracy: Acc@1 18.454 || Acc@5 46.432\n","==> Test Accuracy:  Acc@1 23.540 || Acc@5 53.840\n","==> 70.36 seconds to train this epoch\n","\n","\n","----- epoch: 4, lr: 0.1 -----\n","Epoch: [4][  0/391]\tTime  0.264 ( 0.264)\tLoss 3.1275e+00 (3.1275e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  47.66 ( 47.66)\n","Epoch: [4][ 30/391]\tTime  0.171 ( 0.171)\tLoss 3.4053e+00 (3.2005e+00)\tAcc@1  17.97 ( 21.72)\tAcc@5  45.31 ( 49.97)\n","Epoch: [4][ 60/391]\tTime  0.167 ( 0.170)\tLoss 3.1372e+00 (3.2096e+00)\tAcc@1  21.88 ( 21.06)\tAcc@5  53.91 ( 49.53)\n","Epoch: [4][ 90/391]\tTime  0.169 ( 0.170)\tLoss 3.0289e+00 (3.2058e+00)\tAcc@1  17.97 ( 21.21)\tAcc@5  56.25 ( 49.81)\n","Epoch: [4][120/391]\tTime  0.168 ( 0.170)\tLoss 2.9544e+00 (3.2012e+00)\tAcc@1  25.00 ( 21.07)\tAcc@5  53.91 ( 50.20)\n","Epoch: [4][150/391]\tTime  0.171 ( 0.170)\tLoss 3.0637e+00 (3.1901e+00)\tAcc@1  22.66 ( 21.26)\tAcc@5  56.25 ( 50.52)\n","Epoch: [4][180/391]\tTime  0.171 ( 0.170)\tLoss 3.1586e+00 (3.1853e+00)\tAcc@1  25.78 ( 21.54)\tAcc@5  53.91 ( 50.70)\n","Epoch: [4][210/391]\tTime  0.170 ( 0.170)\tLoss 3.1490e+00 (3.1761e+00)\tAcc@1  23.44 ( 21.59)\tAcc@5  50.00 ( 51.14)\n","Epoch: [4][240/391]\tTime  0.168 ( 0.170)\tLoss 3.0325e+00 (3.1684e+00)\tAcc@1  23.44 ( 21.72)\tAcc@5  55.47 ( 51.25)\n","Epoch: [4][270/391]\tTime  0.173 ( 0.170)\tLoss 2.9322e+00 (3.1635e+00)\tAcc@1  25.00 ( 21.81)\tAcc@5  56.25 ( 51.37)\n","Epoch: [4][300/391]\tTime  0.169 ( 0.170)\tLoss 3.1283e+00 (3.1572e+00)\tAcc@1  21.09 ( 21.92)\tAcc@5  49.22 ( 51.54)\n","Epoch: [4][330/391]\tTime  0.167 ( 0.170)\tLoss 2.9964e+00 (3.1540e+00)\tAcc@1  26.56 ( 21.97)\tAcc@5  56.25 ( 51.53)\n","Epoch: [4][360/391]\tTime  0.168 ( 0.170)\tLoss 3.1813e+00 (3.1489e+00)\tAcc@1  18.75 ( 22.10)\tAcc@5  45.31 ( 51.55)\n","Epoch: [4][390/391]\tTime  0.152 ( 0.169)\tLoss 3.0628e+00 (3.1401e+00)\tAcc@1  21.25 ( 22.27)\tAcc@5  56.25 ( 51.84)\n","==> Train Accuracy: Acc@1 22.274 || Acc@5 51.842\n","==> Test Accuracy:  Acc@1 27.780 || Acc@5 58.860\n","==> 70.44 seconds to train this epoch\n","\n","\n","----- epoch: 5, lr: 0.1 -----\n","Epoch: [5][  0/391]\tTime  0.259 ( 0.259)\tLoss 3.1660e+00 (3.1660e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  50.78 ( 50.78)\n","Epoch: [5][ 30/391]\tTime  0.170 ( 0.172)\tLoss 3.0894e+00 (3.0029e+00)\tAcc@1  25.00 ( 24.87)\tAcc@5  51.56 ( 54.94)\n","Epoch: [5][ 60/391]\tTime  0.168 ( 0.171)\tLoss 3.1845e+00 (2.9966e+00)\tAcc@1  17.97 ( 24.88)\tAcc@5  53.12 ( 55.34)\n","Epoch: [5][ 90/391]\tTime  0.170 ( 0.170)\tLoss 3.2684e+00 (2.9928e+00)\tAcc@1  21.88 ( 24.84)\tAcc@5  43.75 ( 55.55)\n","Epoch: [5][120/391]\tTime  0.168 ( 0.170)\tLoss 2.7340e+00 (2.9951e+00)\tAcc@1  30.47 ( 24.89)\tAcc@5  58.59 ( 55.40)\n","Epoch: [5][150/391]\tTime  0.169 ( 0.170)\tLoss 2.7876e+00 (2.9874e+00)\tAcc@1  32.03 ( 25.12)\tAcc@5  60.94 ( 55.58)\n","Epoch: [5][180/391]\tTime  0.171 ( 0.170)\tLoss 3.1226e+00 (2.9819e+00)\tAcc@1  22.66 ( 25.32)\tAcc@5  52.34 ( 55.82)\n","Epoch: [5][210/391]\tTime  0.170 ( 0.170)\tLoss 2.9980e+00 (2.9780e+00)\tAcc@1  25.00 ( 25.44)\tAcc@5  57.03 ( 55.90)\n","Epoch: [5][240/391]\tTime  0.168 ( 0.170)\tLoss 3.0087e+00 (2.9713e+00)\tAcc@1  22.66 ( 25.59)\tAcc@5  50.78 ( 56.11)\n","Epoch: [5][270/391]\tTime  0.170 ( 0.170)\tLoss 2.9543e+00 (2.9710e+00)\tAcc@1  25.78 ( 25.60)\tAcc@5  59.38 ( 56.18)\n","Epoch: [5][300/391]\tTime  0.169 ( 0.170)\tLoss 2.9203e+00 (2.9658e+00)\tAcc@1  22.66 ( 25.67)\tAcc@5  53.91 ( 56.30)\n","Epoch: [5][330/391]\tTime  0.170 ( 0.170)\tLoss 3.0308e+00 (2.9613e+00)\tAcc@1  22.66 ( 25.83)\tAcc@5  51.56 ( 56.40)\n","Epoch: [5][360/391]\tTime  0.169 ( 0.169)\tLoss 3.0106e+00 (2.9570e+00)\tAcc@1  23.44 ( 25.96)\tAcc@5  53.91 ( 56.51)\n","Epoch: [5][390/391]\tTime  0.152 ( 0.169)\tLoss 2.9736e+00 (2.9509e+00)\tAcc@1  25.00 ( 26.11)\tAcc@5  61.25 ( 56.69)\n","==> Train Accuracy: Acc@1 26.106 || Acc@5 56.686\n","==> Test Accuracy:  Acc@1 30.150 || Acc@5 61.960\n","==> 70.39 seconds to train this epoch\n","\n","\n","----- epoch: 6, lr: 0.1 -----\n","Epoch: [6][  0/391]\tTime  0.274 ( 0.274)\tLoss 2.9383e+00 (2.9383e+00)\tAcc@1  21.88 ( 21.88)\tAcc@5  57.03 ( 57.03)\n","Epoch: [6][ 30/391]\tTime  0.171 ( 0.172)\tLoss 2.8653e+00 (2.8185e+00)\tAcc@1  32.03 ( 28.63)\tAcc@5  57.03 ( 59.98)\n","Epoch: [6][ 60/391]\tTime  0.169 ( 0.170)\tLoss 2.8907e+00 (2.7981e+00)\tAcc@1  26.56 ( 29.28)\tAcc@5  63.28 ( 60.80)\n","Epoch: [6][ 90/391]\tTime  0.168 ( 0.170)\tLoss 2.9181e+00 (2.8035e+00)\tAcc@1  33.59 ( 28.97)\tAcc@5  55.47 ( 60.80)\n","Epoch: [6][120/391]\tTime  0.170 ( 0.170)\tLoss 2.9191e+00 (2.8034e+00)\tAcc@1  20.31 ( 28.74)\tAcc@5  56.25 ( 60.66)\n","Epoch: [6][150/391]\tTime  0.171 ( 0.170)\tLoss 2.6246e+00 (2.7972e+00)\tAcc@1  25.00 ( 28.76)\tAcc@5  69.53 ( 60.75)\n","Epoch: [6][180/391]\tTime  0.168 ( 0.169)\tLoss 2.5073e+00 (2.7928e+00)\tAcc@1  34.38 ( 28.92)\tAcc@5  63.28 ( 60.91)\n","Epoch: [6][210/391]\tTime  0.171 ( 0.169)\tLoss 2.8976e+00 (2.7948e+00)\tAcc@1  26.56 ( 28.88)\tAcc@5  60.16 ( 60.79)\n","Epoch: [6][240/391]\tTime  0.168 ( 0.169)\tLoss 2.5970e+00 (2.7922e+00)\tAcc@1  32.03 ( 29.01)\tAcc@5  61.72 ( 60.83)\n","Epoch: [6][270/391]\tTime  0.168 ( 0.169)\tLoss 2.4918e+00 (2.7831e+00)\tAcc@1  32.81 ( 29.16)\tAcc@5  67.19 ( 61.12)\n","Epoch: [6][300/391]\tTime  0.169 ( 0.169)\tLoss 2.5486e+00 (2.7806e+00)\tAcc@1  35.16 ( 29.20)\tAcc@5  65.62 ( 61.16)\n","Epoch: [6][330/391]\tTime  0.169 ( 0.169)\tLoss 2.5780e+00 (2.7748e+00)\tAcc@1  33.59 ( 29.30)\tAcc@5  65.62 ( 61.33)\n","Epoch: [6][360/391]\tTime  0.169 ( 0.169)\tLoss 2.6640e+00 (2.7715e+00)\tAcc@1  26.56 ( 29.40)\tAcc@5  67.97 ( 61.39)\n","Epoch: [6][390/391]\tTime  0.152 ( 0.169)\tLoss 2.5399e+00 (2.7652e+00)\tAcc@1  28.75 ( 29.50)\tAcc@5  68.75 ( 61.55)\n","==> Train Accuracy: Acc@1 29.504 || Acc@5 61.552\n","==> Test Accuracy:  Acc@1 33.830 || Acc@5 67.070\n","==> 70.33 seconds to train this epoch\n","\n","\n","----- epoch: 7, lr: 0.1 -----\n","Epoch: [7][  0/391]\tTime  0.257 ( 0.257)\tLoss 2.6264e+00 (2.6264e+00)\tAcc@1  30.47 ( 30.47)\tAcc@5  64.84 ( 64.84)\n","Epoch: [7][ 30/391]\tTime  0.170 ( 0.171)\tLoss 2.9136e+00 (2.6399e+00)\tAcc@1  30.47 ( 32.59)\tAcc@5  62.50 ( 64.39)\n","Epoch: [7][ 60/391]\tTime  0.169 ( 0.170)\tLoss 2.6729e+00 (2.6403e+00)\tAcc@1  29.69 ( 32.52)\tAcc@5  63.28 ( 64.11)\n","Epoch: [7][ 90/391]\tTime  0.170 ( 0.170)\tLoss 2.5260e+00 (2.6512e+00)\tAcc@1  35.94 ( 31.82)\tAcc@5  65.62 ( 63.87)\n","Epoch: [7][120/391]\tTime  0.170 ( 0.170)\tLoss 3.0226e+00 (2.6500e+00)\tAcc@1  26.56 ( 31.77)\tAcc@5  50.00 ( 63.83)\n","Epoch: [7][150/391]\tTime  0.169 ( 0.170)\tLoss 2.5188e+00 (2.6443e+00)\tAcc@1  38.28 ( 31.99)\tAcc@5  67.19 ( 63.91)\n","Epoch: [7][180/391]\tTime  0.169 ( 0.170)\tLoss 2.6623e+00 (2.6411e+00)\tAcc@1  29.69 ( 32.07)\tAcc@5  62.50 ( 63.92)\n","Epoch: [7][210/391]\tTime  0.169 ( 0.169)\tLoss 2.6808e+00 (2.6394e+00)\tAcc@1  25.78 ( 32.04)\tAcc@5  62.50 ( 63.91)\n","Epoch: [7][240/391]\tTime  0.170 ( 0.169)\tLoss 2.7192e+00 (2.6361e+00)\tAcc@1  28.12 ( 32.15)\tAcc@5  66.41 ( 64.05)\n","Epoch: [7][270/391]\tTime  0.169 ( 0.169)\tLoss 2.8271e+00 (2.6321e+00)\tAcc@1  26.56 ( 32.26)\tAcc@5  60.16 ( 64.16)\n","Epoch: [7][300/391]\tTime  0.170 ( 0.169)\tLoss 2.5498e+00 (2.6267e+00)\tAcc@1  28.12 ( 32.46)\tAcc@5  67.97 ( 64.32)\n","Epoch: [7][330/391]\tTime  0.169 ( 0.169)\tLoss 2.5158e+00 (2.6269e+00)\tAcc@1  38.28 ( 32.49)\tAcc@5  65.62 ( 64.37)\n","Epoch: [7][360/391]\tTime  0.168 ( 0.169)\tLoss 2.6677e+00 (2.6228e+00)\tAcc@1  28.91 ( 32.57)\tAcc@5  61.72 ( 64.38)\n","Epoch: [7][390/391]\tTime  0.150 ( 0.169)\tLoss 2.6092e+00 (2.6243e+00)\tAcc@1  28.75 ( 32.56)\tAcc@5  60.00 ( 64.35)\n","==> Train Accuracy: Acc@1 32.558 || Acc@5 64.354\n","==> Test Accuracy:  Acc@1 33.410 || Acc@5 66.820\n","==> 70.31 seconds to train this epoch\n","\n","\n","----- epoch: 8, lr: 0.1 -----\n","Epoch: [8][  0/391]\tTime  0.259 ( 0.259)\tLoss 2.6100e+00 (2.6100e+00)\tAcc@1  30.47 ( 30.47)\tAcc@5  63.28 ( 63.28)\n","Epoch: [8][ 30/391]\tTime  0.168 ( 0.172)\tLoss 2.3323e+00 (2.5072e+00)\tAcc@1  38.28 ( 34.70)\tAcc@5  71.09 ( 67.72)\n","Epoch: [8][ 60/391]\tTime  0.169 ( 0.170)\tLoss 2.4516e+00 (2.5213e+00)\tAcc@1  38.28 ( 34.40)\tAcc@5  65.62 ( 67.07)\n","Epoch: [8][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.5259e+00 (2.5297e+00)\tAcc@1  32.81 ( 34.42)\tAcc@5  71.09 ( 66.84)\n","Epoch: [8][120/391]\tTime  0.169 ( 0.170)\tLoss 2.7472e+00 (2.5309e+00)\tAcc@1  29.69 ( 34.54)\tAcc@5  59.38 ( 66.55)\n","Epoch: [8][150/391]\tTime  0.170 ( 0.170)\tLoss 2.5045e+00 (2.5256e+00)\tAcc@1  29.69 ( 34.58)\tAcc@5  71.09 ( 66.79)\n","Epoch: [8][180/391]\tTime  0.170 ( 0.169)\tLoss 2.6460e+00 (2.5373e+00)\tAcc@1  34.38 ( 34.22)\tAcc@5  66.41 ( 66.48)\n","Epoch: [8][210/391]\tTime  0.168 ( 0.169)\tLoss 2.4252e+00 (2.5317e+00)\tAcc@1  37.50 ( 34.32)\tAcc@5  71.09 ( 66.70)\n","Epoch: [8][240/391]\tTime  0.169 ( 0.169)\tLoss 2.1531e+00 (2.5286e+00)\tAcc@1  39.84 ( 34.41)\tAcc@5  74.22 ( 66.76)\n","Epoch: [8][270/391]\tTime  0.171 ( 0.169)\tLoss 2.1943e+00 (2.5223e+00)\tAcc@1  43.75 ( 34.58)\tAcc@5  72.66 ( 66.90)\n","Epoch: [8][300/391]\tTime  0.170 ( 0.169)\tLoss 2.3675e+00 (2.5223e+00)\tAcc@1  37.50 ( 34.58)\tAcc@5  68.75 ( 66.89)\n","Epoch: [8][330/391]\tTime  0.170 ( 0.169)\tLoss 2.4246e+00 (2.5180e+00)\tAcc@1  38.28 ( 34.69)\tAcc@5  71.09 ( 67.00)\n","Epoch: [8][360/391]\tTime  0.170 ( 0.169)\tLoss 2.6374e+00 (2.5213e+00)\tAcc@1  37.50 ( 34.56)\tAcc@5  60.94 ( 66.93)\n","Epoch: [8][390/391]\tTime  0.151 ( 0.169)\tLoss 2.4484e+00 (2.5177e+00)\tAcc@1  28.75 ( 34.60)\tAcc@5  63.75 ( 66.99)\n","==> Train Accuracy: Acc@1 34.598 || Acc@5 66.986\n","==> Test Accuracy:  Acc@1 42.300 || Acc@5 75.170\n","==> 70.32 seconds to train this epoch\n","\n","\n","----- epoch: 9, lr: 0.1 -----\n","Epoch: [9][  0/391]\tTime  0.263 ( 0.263)\tLoss 2.2211e+00 (2.2211e+00)\tAcc@1  35.94 ( 35.94)\tAcc@5  77.34 ( 77.34)\n","Epoch: [9][ 30/391]\tTime  0.169 ( 0.171)\tLoss 2.4568e+00 (2.3801e+00)\tAcc@1  38.28 ( 36.97)\tAcc@5  68.75 ( 70.26)\n","Epoch: [9][ 60/391]\tTime  0.168 ( 0.170)\tLoss 2.2996e+00 (2.3990e+00)\tAcc@1  39.06 ( 36.71)\tAcc@5  67.97 ( 69.84)\n","Epoch: [9][ 90/391]\tTime  0.170 ( 0.170)\tLoss 2.5188e+00 (2.4187e+00)\tAcc@1  36.72 ( 36.43)\tAcc@5  67.97 ( 69.59)\n","Epoch: [9][120/391]\tTime  0.169 ( 0.170)\tLoss 2.6169e+00 (2.4194e+00)\tAcc@1  32.81 ( 36.61)\tAcc@5  68.75 ( 69.52)\n","Epoch: [9][150/391]\tTime  0.171 ( 0.169)\tLoss 2.4956e+00 (2.4180e+00)\tAcc@1  23.44 ( 36.52)\tAcc@5  72.66 ( 69.54)\n","Epoch: [9][180/391]\tTime  0.168 ( 0.169)\tLoss 2.4434e+00 (2.4229e+00)\tAcc@1  35.94 ( 36.43)\tAcc@5  69.53 ( 69.37)\n","Epoch: [9][210/391]\tTime  0.168 ( 0.169)\tLoss 2.4374e+00 (2.4257e+00)\tAcc@1  37.50 ( 36.44)\tAcc@5  67.19 ( 69.22)\n","Epoch: [9][240/391]\tTime  0.171 ( 0.169)\tLoss 2.2657e+00 (2.4257e+00)\tAcc@1  44.53 ( 36.51)\tAcc@5  71.09 ( 69.13)\n","Epoch: [9][270/391]\tTime  0.169 ( 0.169)\tLoss 2.3133e+00 (2.4224e+00)\tAcc@1  35.16 ( 36.64)\tAcc@5  73.44 ( 69.18)\n","Epoch: [9][300/391]\tTime  0.170 ( 0.169)\tLoss 2.5445e+00 (2.4270e+00)\tAcc@1  36.72 ( 36.63)\tAcc@5  67.97 ( 69.08)\n","Epoch: [9][330/391]\tTime  0.170 ( 0.169)\tLoss 2.5130e+00 (2.4241e+00)\tAcc@1  30.47 ( 36.68)\tAcc@5  67.97 ( 69.15)\n","Epoch: [9][360/391]\tTime  0.169 ( 0.169)\tLoss 2.3137e+00 (2.4236e+00)\tAcc@1  35.16 ( 36.61)\tAcc@5  73.44 ( 69.14)\n","Epoch: [9][390/391]\tTime  0.150 ( 0.169)\tLoss 2.5204e+00 (2.4223e+00)\tAcc@1  35.00 ( 36.65)\tAcc@5  63.75 ( 69.15)\n","==> Train Accuracy: Acc@1 36.654 || Acc@5 69.150\n","==> Test Accuracy:  Acc@1 40.640 || Acc@5 73.780\n","==> 70.25 seconds to train this epoch\n","\n","\n","----- epoch: 10, lr: 0.1 -----\n","Epoch: [10][  0/391]\tTime  0.258 ( 0.258)\tLoss 2.4697e+00 (2.4697e+00)\tAcc@1  38.28 ( 38.28)\tAcc@5  66.41 ( 66.41)\n","Epoch: [10][ 30/391]\tTime  0.171 ( 0.171)\tLoss 2.4838e+00 (2.3470e+00)\tAcc@1  38.28 ( 38.61)\tAcc@5  69.53 ( 71.80)\n","Epoch: [10][ 60/391]\tTime  0.169 ( 0.170)\tLoss 2.2348e+00 (2.3591e+00)\tAcc@1  40.62 ( 38.36)\tAcc@5  71.09 ( 71.13)\n","Epoch: [10][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.4234e+00 (2.3498e+00)\tAcc@1  35.94 ( 38.36)\tAcc@5  67.19 ( 70.92)\n","Epoch: [10][120/391]\tTime  0.165 ( 0.170)\tLoss 2.1251e+00 (2.3572e+00)\tAcc@1  45.31 ( 38.29)\tAcc@5  75.00 ( 70.59)\n","Epoch: [10][150/391]\tTime  0.167 ( 0.169)\tLoss 2.5369e+00 (2.3551e+00)\tAcc@1  35.94 ( 38.37)\tAcc@5  70.31 ( 70.60)\n","Epoch: [10][180/391]\tTime  0.168 ( 0.169)\tLoss 2.4302e+00 (2.3552e+00)\tAcc@1  39.84 ( 38.39)\tAcc@5  65.62 ( 70.61)\n","Epoch: [10][210/391]\tTime  0.169 ( 0.169)\tLoss 2.3704e+00 (2.3519e+00)\tAcc@1  43.75 ( 38.60)\tAcc@5  68.75 ( 70.57)\n","Epoch: [10][240/391]\tTime  0.170 ( 0.169)\tLoss 2.3887e+00 (2.3471e+00)\tAcc@1  37.50 ( 38.64)\tAcc@5  71.09 ( 70.67)\n","Epoch: [10][270/391]\tTime  0.170 ( 0.169)\tLoss 2.2285e+00 (2.3460e+00)\tAcc@1  49.22 ( 38.64)\tAcc@5  75.78 ( 70.77)\n","Epoch: [10][300/391]\tTime  0.169 ( 0.169)\tLoss 2.4628e+00 (2.3419e+00)\tAcc@1  39.06 ( 38.62)\tAcc@5  72.66 ( 70.91)\n","Epoch: [10][330/391]\tTime  0.170 ( 0.169)\tLoss 2.2479e+00 (2.3400e+00)\tAcc@1  40.62 ( 38.65)\tAcc@5  73.44 ( 70.95)\n","Epoch: [10][360/391]\tTime  0.170 ( 0.169)\tLoss 2.3061e+00 (2.3373e+00)\tAcc@1  35.94 ( 38.75)\tAcc@5  70.31 ( 70.95)\n","Epoch: [10][390/391]\tTime  0.149 ( 0.169)\tLoss 2.7237e+00 (2.3387e+00)\tAcc@1  36.25 ( 38.65)\tAcc@5  66.25 ( 70.93)\n","==> Train Accuracy: Acc@1 38.646 || Acc@5 70.930\n","==> Test Accuracy:  Acc@1 43.620 || Acc@5 76.180\n","==> 70.32 seconds to train this epoch\n","\n","\n","----- epoch: 11, lr: 0.1 -----\n","Epoch: [11][  0/391]\tTime  0.292 ( 0.292)\tLoss 2.3188e+00 (2.3188e+00)\tAcc@1  38.28 ( 38.28)\tAcc@5  74.22 ( 74.22)\n","Epoch: [11][ 30/391]\tTime  0.169 ( 0.172)\tLoss 2.3097e+00 (2.2888e+00)\tAcc@1  41.41 ( 40.02)\tAcc@5  66.41 ( 72.10)\n","Epoch: [11][ 60/391]\tTime  0.169 ( 0.171)\tLoss 2.3897e+00 (2.2842e+00)\tAcc@1  39.84 ( 40.43)\tAcc@5  68.75 ( 72.03)\n","Epoch: [11][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.2419e+00 (2.2888e+00)\tAcc@1  48.44 ( 40.02)\tAcc@5  69.53 ( 71.87)\n","Epoch: [11][120/391]\tTime  0.169 ( 0.170)\tLoss 2.1641e+00 (2.2833e+00)\tAcc@1  40.62 ( 40.05)\tAcc@5  73.44 ( 72.06)\n","Epoch: [11][150/391]\tTime  0.170 ( 0.170)\tLoss 2.1651e+00 (2.2842e+00)\tAcc@1  42.19 ( 40.07)\tAcc@5  67.19 ( 71.98)\n","Epoch: [11][180/391]\tTime  0.169 ( 0.170)\tLoss 2.2524e+00 (2.2885e+00)\tAcc@1  40.62 ( 40.00)\tAcc@5  70.31 ( 71.81)\n","Epoch: [11][210/391]\tTime  0.170 ( 0.170)\tLoss 2.5340e+00 (2.2856e+00)\tAcc@1  33.59 ( 40.01)\tAcc@5  67.19 ( 71.89)\n","Epoch: [11][240/391]\tTime  0.168 ( 0.170)\tLoss 2.3325e+00 (2.2833e+00)\tAcc@1  35.94 ( 40.04)\tAcc@5  68.75 ( 71.90)\n","Epoch: [11][270/391]\tTime  0.169 ( 0.170)\tLoss 2.4485e+00 (2.2871e+00)\tAcc@1  40.62 ( 39.99)\tAcc@5  62.50 ( 71.85)\n","Epoch: [11][300/391]\tTime  0.170 ( 0.170)\tLoss 2.3546e+00 (2.2859e+00)\tAcc@1  39.84 ( 40.06)\tAcc@5  69.53 ( 71.84)\n","Epoch: [11][330/391]\tTime  0.170 ( 0.169)\tLoss 2.5237e+00 (2.2901e+00)\tAcc@1  35.16 ( 39.89)\tAcc@5  66.41 ( 71.84)\n","Epoch: [11][360/391]\tTime  0.170 ( 0.169)\tLoss 2.1921e+00 (2.2857e+00)\tAcc@1  42.97 ( 40.03)\tAcc@5  72.66 ( 71.98)\n","Epoch: [11][390/391]\tTime  0.152 ( 0.169)\tLoss 2.4735e+00 (2.2850e+00)\tAcc@1  33.75 ( 40.02)\tAcc@5  70.00 ( 71.99)\n","==> Train Accuracy: Acc@1 40.016 || Acc@5 71.992\n","==> Test Accuracy:  Acc@1 46.020 || Acc@5 77.810\n","==> 70.39 seconds to train this epoch\n","\n","\n","----- epoch: 12, lr: 0.1 -----\n","Epoch: [12][  0/391]\tTime  0.252 ( 0.252)\tLoss 2.1888e+00 (2.1888e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  67.97 ( 67.97)\n","Epoch: [12][ 30/391]\tTime  0.170 ( 0.172)\tLoss 2.3134e+00 (2.2315e+00)\tAcc@1  41.41 ( 41.05)\tAcc@5  68.75 ( 73.29)\n","Epoch: [12][ 60/391]\tTime  0.170 ( 0.170)\tLoss 2.6004e+00 (2.2311e+00)\tAcc@1  31.25 ( 41.46)\tAcc@5  66.41 ( 73.22)\n","Epoch: [12][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.3056e+00 (2.2224e+00)\tAcc@1  39.06 ( 41.37)\tAcc@5  76.56 ( 73.51)\n","Epoch: [12][120/391]\tTime  0.168 ( 0.170)\tLoss 2.1317e+00 (2.2209e+00)\tAcc@1  41.41 ( 41.44)\tAcc@5  77.34 ( 73.48)\n","Epoch: [12][150/391]\tTime  0.168 ( 0.170)\tLoss 2.0429e+00 (2.2131e+00)\tAcc@1  48.44 ( 41.70)\tAcc@5  75.78 ( 73.61)\n","Epoch: [12][180/391]\tTime  0.168 ( 0.170)\tLoss 2.0454e+00 (2.2156e+00)\tAcc@1  42.97 ( 41.43)\tAcc@5  77.34 ( 73.48)\n","Epoch: [12][210/391]\tTime  0.169 ( 0.169)\tLoss 2.0611e+00 (2.2194e+00)\tAcc@1  42.97 ( 41.47)\tAcc@5  73.44 ( 73.39)\n","Epoch: [12][240/391]\tTime  0.169 ( 0.169)\tLoss 2.3839e+00 (2.2206e+00)\tAcc@1  42.97 ( 41.50)\tAcc@5  67.97 ( 73.35)\n","Epoch: [12][270/391]\tTime  0.170 ( 0.169)\tLoss 2.4409e+00 (2.2221e+00)\tAcc@1  32.03 ( 41.53)\tAcc@5  70.31 ( 73.31)\n","Epoch: [12][300/391]\tTime  0.170 ( 0.169)\tLoss 2.2861e+00 (2.2268e+00)\tAcc@1  41.41 ( 41.47)\tAcc@5  71.88 ( 73.25)\n","Epoch: [12][330/391]\tTime  0.168 ( 0.169)\tLoss 2.4582e+00 (2.2271e+00)\tAcc@1  34.38 ( 41.39)\tAcc@5  63.28 ( 73.27)\n","Epoch: [12][360/391]\tTime  0.170 ( 0.169)\tLoss 2.4127e+00 (2.2288e+00)\tAcc@1  39.06 ( 41.31)\tAcc@5  68.75 ( 73.21)\n","Epoch: [12][390/391]\tTime  0.151 ( 0.169)\tLoss 2.0774e+00 (2.2278e+00)\tAcc@1  38.75 ( 41.36)\tAcc@5  82.50 ( 73.22)\n","==> Train Accuracy: Acc@1 41.362 || Acc@5 73.216\n","==> Test Accuracy:  Acc@1 47.750 || Acc@5 79.520\n","==> 70.32 seconds to train this epoch\n","\n","\n","----- epoch: 13, lr: 0.1 -----\n","Epoch: [13][  0/391]\tTime  0.265 ( 0.265)\tLoss 2.3214e+00 (2.3214e+00)\tAcc@1  39.84 ( 39.84)\tAcc@5  72.66 ( 72.66)\n","Epoch: [13][ 30/391]\tTime  0.170 ( 0.172)\tLoss 2.1857e+00 (2.1468e+00)\tAcc@1  40.62 ( 42.41)\tAcc@5  73.44 ( 74.80)\n","Epoch: [13][ 60/391]\tTime  0.170 ( 0.170)\tLoss 2.6531e+00 (2.1496e+00)\tAcc@1  33.59 ( 43.02)\tAcc@5  59.38 ( 74.67)\n","Epoch: [13][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.2889e+00 (2.1593e+00)\tAcc@1  41.41 ( 42.69)\tAcc@5  71.88 ( 74.49)\n","Epoch: [13][120/391]\tTime  0.170 ( 0.170)\tLoss 2.0298e+00 (2.1677e+00)\tAcc@1  43.75 ( 42.48)\tAcc@5  76.56 ( 74.29)\n","Epoch: [13][150/391]\tTime  0.168 ( 0.169)\tLoss 2.0378e+00 (2.1697e+00)\tAcc@1  42.19 ( 42.35)\tAcc@5  78.91 ( 74.44)\n","Epoch: [13][180/391]\tTime  0.169 ( 0.169)\tLoss 2.0384e+00 (2.1815e+00)\tAcc@1  45.31 ( 42.16)\tAcc@5  77.34 ( 74.20)\n","Epoch: [13][210/391]\tTime  0.166 ( 0.169)\tLoss 2.1284e+00 (2.1780e+00)\tAcc@1  40.62 ( 42.19)\tAcc@5  74.22 ( 74.24)\n","Epoch: [13][240/391]\tTime  0.170 ( 0.169)\tLoss 2.5474e+00 (2.1756e+00)\tAcc@1  35.94 ( 42.27)\tAcc@5  65.62 ( 74.24)\n","Epoch: [13][270/391]\tTime  0.168 ( 0.169)\tLoss 2.2674e+00 (2.1808e+00)\tAcc@1  37.50 ( 42.11)\tAcc@5  75.00 ( 74.10)\n","Epoch: [13][300/391]\tTime  0.170 ( 0.169)\tLoss 2.1530e+00 (2.1811e+00)\tAcc@1  44.53 ( 42.11)\tAcc@5  75.78 ( 74.10)\n","Epoch: [13][330/391]\tTime  0.172 ( 0.169)\tLoss 2.1907e+00 (2.1831e+00)\tAcc@1  35.94 ( 41.99)\tAcc@5  71.88 ( 74.09)\n","Epoch: [13][360/391]\tTime  0.170 ( 0.169)\tLoss 2.4492e+00 (2.1864e+00)\tAcc@1  35.16 ( 41.97)\tAcc@5  63.28 ( 74.01)\n","Epoch: [13][390/391]\tTime  0.152 ( 0.169)\tLoss 2.1775e+00 (2.1843e+00)\tAcc@1  46.25 ( 42.02)\tAcc@5  72.50 ( 73.96)\n","==> Train Accuracy: Acc@1 42.020 || Acc@5 73.958\n","==> Test Accuracy:  Acc@1 45.850 || Acc@5 76.590\n","==> 70.29 seconds to train this epoch\n","\n","\n","----- epoch: 14, lr: 0.1 -----\n","Epoch: [14][  0/391]\tTime  0.272 ( 0.272)\tLoss 2.1700e+00 (2.1700e+00)\tAcc@1  42.97 ( 42.97)\tAcc@5  77.34 ( 77.34)\n","Epoch: [14][ 30/391]\tTime  0.169 ( 0.172)\tLoss 1.9050e+00 (2.1448e+00)\tAcc@1  44.53 ( 43.15)\tAcc@5  80.47 ( 74.90)\n","Epoch: [14][ 60/391]\tTime  0.170 ( 0.170)\tLoss 2.1029e+00 (2.1509e+00)\tAcc@1  37.50 ( 42.64)\tAcc@5  75.78 ( 74.28)\n","Epoch: [14][ 90/391]\tTime  0.168 ( 0.170)\tLoss 2.0589e+00 (2.1413e+00)\tAcc@1  42.97 ( 42.82)\tAcc@5  77.34 ( 74.72)\n","Epoch: [14][120/391]\tTime  0.170 ( 0.170)\tLoss 2.2558e+00 (2.1448e+00)\tAcc@1  41.41 ( 42.72)\tAcc@5  73.44 ( 74.71)\n","Epoch: [14][150/391]\tTime  0.168 ( 0.169)\tLoss 2.2956e+00 (2.1338e+00)\tAcc@1  38.28 ( 42.76)\tAcc@5  71.09 ( 74.82)\n","Epoch: [14][180/391]\tTime  0.171 ( 0.169)\tLoss 2.0169e+00 (2.1376e+00)\tAcc@1  50.00 ( 42.87)\tAcc@5  80.47 ( 74.75)\n","Epoch: [14][210/391]\tTime  0.170 ( 0.169)\tLoss 2.1160e+00 (2.1424e+00)\tAcc@1  39.84 ( 42.68)\tAcc@5  79.69 ( 74.64)\n","Epoch: [14][240/391]\tTime  0.168 ( 0.169)\tLoss 2.1576e+00 (2.1419e+00)\tAcc@1  43.75 ( 42.76)\tAcc@5  75.00 ( 74.54)\n","Epoch: [14][270/391]\tTime  0.169 ( 0.169)\tLoss 2.0291e+00 (2.1431e+00)\tAcc@1  45.31 ( 42.81)\tAcc@5  75.00 ( 74.49)\n","Epoch: [14][300/391]\tTime  0.168 ( 0.169)\tLoss 2.4034e+00 (2.1433e+00)\tAcc@1  42.97 ( 42.93)\tAcc@5  68.75 ( 74.55)\n","Epoch: [14][330/391]\tTime  0.168 ( 0.169)\tLoss 2.4147e+00 (2.1421e+00)\tAcc@1  33.59 ( 43.06)\tAcc@5  70.31 ( 74.61)\n","Epoch: [14][360/391]\tTime  0.168 ( 0.169)\tLoss 2.2719e+00 (2.1434e+00)\tAcc@1  40.62 ( 42.98)\tAcc@5  79.69 ( 74.63)\n","Epoch: [14][390/391]\tTime  0.152 ( 0.169)\tLoss 2.2461e+00 (2.1451e+00)\tAcc@1  42.50 ( 42.97)\tAcc@5  75.00 ( 74.58)\n","==> Train Accuracy: Acc@1 42.970 || Acc@5 74.578\n","==> Test Accuracy:  Acc@1 47.770 || Acc@5 78.640\n","==> 70.22 seconds to train this epoch\n","\n","\n","----- epoch: 15, lr: 0.1 -----\n","Epoch: [15][  0/391]\tTime  0.249 ( 0.249)\tLoss 2.1753e+00 (2.1753e+00)\tAcc@1  42.97 ( 42.97)\tAcc@5  75.78 ( 75.78)\n","Epoch: [15][ 30/391]\tTime  0.170 ( 0.171)\tLoss 2.2066e+00 (2.0995e+00)\tAcc@1  42.97 ( 43.78)\tAcc@5  75.00 ( 75.45)\n","Epoch: [15][ 60/391]\tTime  0.170 ( 0.170)\tLoss 2.0697e+00 (2.0939e+00)\tAcc@1  40.62 ( 43.78)\tAcc@5  78.12 ( 75.37)\n","Epoch: [15][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.2220e+00 (2.0885e+00)\tAcc@1  43.75 ( 43.94)\tAcc@5  73.44 ( 75.65)\n","Epoch: [15][120/391]\tTime  0.171 ( 0.169)\tLoss 2.0313e+00 (2.0911e+00)\tAcc@1  35.16 ( 44.06)\tAcc@5  84.38 ( 75.78)\n","Epoch: [15][150/391]\tTime  0.168 ( 0.169)\tLoss 2.0223e+00 (2.0975e+00)\tAcc@1  42.97 ( 43.81)\tAcc@5  76.56 ( 75.61)\n","Epoch: [15][180/391]\tTime  0.170 ( 0.169)\tLoss 2.2219e+00 (2.0988e+00)\tAcc@1  44.53 ( 43.73)\tAcc@5  69.53 ( 75.58)\n","Epoch: [15][210/391]\tTime  0.168 ( 0.169)\tLoss 2.5323e+00 (2.1051e+00)\tAcc@1  32.81 ( 43.74)\tAcc@5  65.62 ( 75.39)\n","Epoch: [15][240/391]\tTime  0.168 ( 0.169)\tLoss 1.8665e+00 (2.1090e+00)\tAcc@1  53.12 ( 43.70)\tAcc@5  76.56 ( 75.43)\n","Epoch: [15][270/391]\tTime  0.168 ( 0.169)\tLoss 2.2465e+00 (2.1135e+00)\tAcc@1  45.31 ( 43.62)\tAcc@5  74.22 ( 75.39)\n","Epoch: [15][300/391]\tTime  0.169 ( 0.169)\tLoss 2.2055e+00 (2.1208e+00)\tAcc@1  43.75 ( 43.52)\tAcc@5  73.44 ( 75.32)\n","Epoch: [15][330/391]\tTime  0.169 ( 0.169)\tLoss 2.1857e+00 (2.1207e+00)\tAcc@1  45.31 ( 43.45)\tAcc@5  71.09 ( 75.38)\n","Epoch: [15][360/391]\tTime  0.170 ( 0.169)\tLoss 2.1423e+00 (2.1189e+00)\tAcc@1  42.19 ( 43.48)\tAcc@5  74.22 ( 75.40)\n","Epoch: [15][390/391]\tTime  0.153 ( 0.169)\tLoss 2.3484e+00 (2.1165e+00)\tAcc@1  43.75 ( 43.56)\tAcc@5  75.00 ( 75.44)\n","==> Train Accuracy: Acc@1 43.558 || Acc@5 75.438\n","==> Test Accuracy:  Acc@1 40.280 || Acc@5 72.970\n","==> 70.27 seconds to train this epoch\n","\n","\n","----- epoch: 16, lr: 0.1 -----\n","Epoch: [16][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.9046e+00 (1.9046e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  79.69 ( 79.69)\n","Epoch: [16][ 30/391]\tTime  0.172 ( 0.172)\tLoss 2.1829e+00 (2.0278e+00)\tAcc@1  43.75 ( 45.89)\tAcc@5  70.31 ( 77.49)\n","Epoch: [16][ 60/391]\tTime  0.170 ( 0.170)\tLoss 2.1428e+00 (2.0538e+00)\tAcc@1  39.06 ( 44.92)\tAcc@5  75.78 ( 76.86)\n","Epoch: [16][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.0680e+00 (2.0392e+00)\tAcc@1  49.22 ( 45.19)\tAcc@5  77.34 ( 77.25)\n","Epoch: [16][120/391]\tTime  0.169 ( 0.170)\tLoss 2.1086e+00 (2.0713e+00)\tAcc@1  46.09 ( 44.58)\tAcc@5  71.88 ( 76.51)\n","Epoch: [16][150/391]\tTime  0.168 ( 0.170)\tLoss 1.9200e+00 (2.0818e+00)\tAcc@1  50.00 ( 44.47)\tAcc@5  82.03 ( 76.20)\n","Epoch: [16][180/391]\tTime  0.170 ( 0.170)\tLoss 1.9677e+00 (2.0824e+00)\tAcc@1  45.31 ( 44.51)\tAcc@5  79.69 ( 76.18)\n","Epoch: [16][210/391]\tTime  0.168 ( 0.169)\tLoss 2.0905e+00 (2.0870e+00)\tAcc@1  45.31 ( 44.47)\tAcc@5  74.22 ( 75.99)\n","Epoch: [16][240/391]\tTime  0.169 ( 0.169)\tLoss 1.9308e+00 (2.0932e+00)\tAcc@1  47.66 ( 44.31)\tAcc@5  76.56 ( 75.95)\n","Epoch: [16][270/391]\tTime  0.170 ( 0.169)\tLoss 1.7001e+00 (2.0888e+00)\tAcc@1  51.56 ( 44.38)\tAcc@5  85.16 ( 76.04)\n","Epoch: [16][300/391]\tTime  0.170 ( 0.169)\tLoss 2.0571e+00 (2.0896e+00)\tAcc@1  42.97 ( 44.39)\tAcc@5  78.91 ( 75.92)\n","Epoch: [16][330/391]\tTime  0.167 ( 0.169)\tLoss 2.1534e+00 (2.0849e+00)\tAcc@1  44.53 ( 44.48)\tAcc@5  78.12 ( 76.02)\n","Epoch: [16][360/391]\tTime  0.169 ( 0.169)\tLoss 1.9643e+00 (2.0865e+00)\tAcc@1  48.44 ( 44.43)\tAcc@5  73.44 ( 75.98)\n","Epoch: [16][390/391]\tTime  0.150 ( 0.169)\tLoss 2.0192e+00 (2.0878e+00)\tAcc@1  41.25 ( 44.40)\tAcc@5  80.00 ( 75.95)\n","==> Train Accuracy: Acc@1 44.400 || Acc@5 75.954\n","==> Test Accuracy:  Acc@1 50.280 || Acc@5 81.210\n","==> 70.34 seconds to train this epoch\n","\n","\n","----- epoch: 17, lr: 0.1 -----\n","Epoch: [17][  0/391]\tTime  0.257 ( 0.257)\tLoss 2.1270e+00 (2.1270e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  74.22 ( 74.22)\n","Epoch: [17][ 30/391]\tTime  0.171 ( 0.172)\tLoss 2.0437e+00 (2.0332e+00)\tAcc@1  47.66 ( 45.39)\tAcc@5  78.12 ( 76.89)\n","Epoch: [17][ 60/391]\tTime  0.169 ( 0.170)\tLoss 2.0764e+00 (2.0481e+00)\tAcc@1  47.66 ( 45.36)\tAcc@5  72.66 ( 76.17)\n","Epoch: [17][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.8583e+00 (2.0517e+00)\tAcc@1  50.00 ( 45.12)\tAcc@5  78.12 ( 76.24)\n","Epoch: [17][120/391]\tTime  0.168 ( 0.170)\tLoss 1.9321e+00 (2.0375e+00)\tAcc@1  44.53 ( 45.37)\tAcc@5  80.47 ( 76.57)\n","Epoch: [17][150/391]\tTime  0.168 ( 0.170)\tLoss 2.0955e+00 (2.0537e+00)\tAcc@1  46.09 ( 45.00)\tAcc@5  76.56 ( 76.30)\n","Epoch: [17][180/391]\tTime  0.168 ( 0.169)\tLoss 2.0160e+00 (2.0605e+00)\tAcc@1  45.31 ( 44.94)\tAcc@5  77.34 ( 76.12)\n","Epoch: [17][210/391]\tTime  0.169 ( 0.169)\tLoss 2.0687e+00 (2.0600e+00)\tAcc@1  46.09 ( 45.00)\tAcc@5  76.56 ( 76.27)\n","Epoch: [17][240/391]\tTime  0.170 ( 0.169)\tLoss 2.1212e+00 (2.0573e+00)\tAcc@1  45.31 ( 45.12)\tAcc@5  76.56 ( 76.27)\n","Epoch: [17][270/391]\tTime  0.170 ( 0.169)\tLoss 2.2310e+00 (2.0573e+00)\tAcc@1  43.75 ( 45.13)\tAcc@5  76.56 ( 76.23)\n","Epoch: [17][300/391]\tTime  0.171 ( 0.169)\tLoss 1.7190e+00 (2.0551e+00)\tAcc@1  52.34 ( 45.15)\tAcc@5  82.03 ( 76.30)\n","Epoch: [17][330/391]\tTime  0.168 ( 0.169)\tLoss 1.9458e+00 (2.0544e+00)\tAcc@1  49.22 ( 45.17)\tAcc@5  76.56 ( 76.31)\n","Epoch: [17][360/391]\tTime  0.169 ( 0.169)\tLoss 2.2954e+00 (2.0525e+00)\tAcc@1  35.16 ( 45.18)\tAcc@5  73.44 ( 76.46)\n","Epoch: [17][390/391]\tTime  0.154 ( 0.169)\tLoss 2.1183e+00 (2.0560e+00)\tAcc@1  43.75 ( 45.02)\tAcc@5  73.75 ( 76.46)\n","==> Train Accuracy: Acc@1 45.020 || Acc@5 76.462\n","==> Test Accuracy:  Acc@1 45.700 || Acc@5 76.800\n","==> 70.36 seconds to train this epoch\n","\n","\n","----- epoch: 18, lr: 0.1 -----\n","Epoch: [18][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.9606e+00 (1.9606e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5  75.00 ( 75.00)\n","Epoch: [18][ 30/391]\tTime  0.170 ( 0.172)\tLoss 2.1562e+00 (2.0067e+00)\tAcc@1  45.31 ( 46.47)\tAcc@5  75.00 ( 77.17)\n","Epoch: [18][ 60/391]\tTime  0.170 ( 0.170)\tLoss 2.0108e+00 (2.0177e+00)\tAcc@1  43.75 ( 46.08)\tAcc@5  75.78 ( 77.23)\n","Epoch: [18][ 90/391]\tTime  0.167 ( 0.170)\tLoss 2.1229e+00 (2.0121e+00)\tAcc@1  47.66 ( 46.18)\tAcc@5  75.00 ( 77.18)\n","Epoch: [18][120/391]\tTime  0.168 ( 0.170)\tLoss 2.2335e+00 (2.0128e+00)\tAcc@1  38.28 ( 46.31)\tAcc@5  77.34 ( 77.17)\n","Epoch: [18][150/391]\tTime  0.169 ( 0.170)\tLoss 2.2625e+00 (2.0171e+00)\tAcc@1  39.84 ( 46.09)\tAcc@5  74.22 ( 77.10)\n","Epoch: [18][180/391]\tTime  0.169 ( 0.170)\tLoss 2.0848e+00 (2.0243e+00)\tAcc@1  47.66 ( 45.78)\tAcc@5  77.34 ( 76.98)\n","Epoch: [18][210/391]\tTime  0.171 ( 0.170)\tLoss 2.2265e+00 (2.0287e+00)\tAcc@1  42.19 ( 45.55)\tAcc@5  75.00 ( 76.85)\n","Epoch: [18][240/391]\tTime  0.170 ( 0.170)\tLoss 1.9611e+00 (2.0300e+00)\tAcc@1  45.31 ( 45.55)\tAcc@5  79.69 ( 76.76)\n","Epoch: [18][270/391]\tTime  0.170 ( 0.169)\tLoss 1.8313e+00 (2.0305e+00)\tAcc@1  49.22 ( 45.59)\tAcc@5  81.25 ( 76.68)\n","Epoch: [18][300/391]\tTime  0.169 ( 0.169)\tLoss 1.8448e+00 (2.0371e+00)\tAcc@1  50.00 ( 45.43)\tAcc@5  77.34 ( 76.60)\n","Epoch: [18][330/391]\tTime  0.171 ( 0.169)\tLoss 2.0525e+00 (2.0322e+00)\tAcc@1  42.19 ( 45.52)\tAcc@5  78.12 ( 76.64)\n","Epoch: [18][360/391]\tTime  0.169 ( 0.169)\tLoss 1.9322e+00 (2.0344e+00)\tAcc@1  42.97 ( 45.51)\tAcc@5  82.81 ( 76.63)\n","Epoch: [18][390/391]\tTime  0.151 ( 0.169)\tLoss 2.2984e+00 (2.0326e+00)\tAcc@1  32.50 ( 45.47)\tAcc@5  68.75 ( 76.63)\n","==> Train Accuracy: Acc@1 45.472 || Acc@5 76.632\n","==> Test Accuracy:  Acc@1 46.770 || Acc@5 78.810\n","==> 70.36 seconds to train this epoch\n","\n","\n","----- epoch: 19, lr: 0.1 -----\n","Epoch: [19][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.9581e+00 (1.9581e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  78.91 ( 78.91)\n","Epoch: [19][ 30/391]\tTime  0.169 ( 0.172)\tLoss 2.2009e+00 (1.9745e+00)\tAcc@1  49.22 ( 47.15)\tAcc@5  68.75 ( 78.43)\n","Epoch: [19][ 60/391]\tTime  0.170 ( 0.170)\tLoss 1.9493e+00 (1.9981e+00)\tAcc@1  46.09 ( 46.70)\tAcc@5  79.69 ( 77.72)\n","Epoch: [19][ 90/391]\tTime  0.171 ( 0.170)\tLoss 2.1803e+00 (2.0053e+00)\tAcc@1  44.53 ( 46.41)\tAcc@5  73.44 ( 77.28)\n","Epoch: [19][120/391]\tTime  0.170 ( 0.170)\tLoss 2.0299e+00 (2.0154e+00)\tAcc@1  42.19 ( 46.20)\tAcc@5  80.47 ( 77.00)\n","Epoch: [19][150/391]\tTime  0.170 ( 0.170)\tLoss 1.8913e+00 (2.0210e+00)\tAcc@1  52.34 ( 46.00)\tAcc@5  75.78 ( 77.01)\n","Epoch: [19][180/391]\tTime  0.168 ( 0.169)\tLoss 2.0251e+00 (2.0234e+00)\tAcc@1  47.66 ( 46.11)\tAcc@5  77.34 ( 76.98)\n","Epoch: [19][210/391]\tTime  0.169 ( 0.169)\tLoss 2.1131e+00 (2.0273e+00)\tAcc@1  39.84 ( 45.98)\tAcc@5  72.66 ( 76.88)\n","Epoch: [19][240/391]\tTime  0.170 ( 0.169)\tLoss 1.5507e+00 (2.0156e+00)\tAcc@1  57.03 ( 46.16)\tAcc@5  84.38 ( 77.08)\n","Epoch: [19][270/391]\tTime  0.169 ( 0.169)\tLoss 2.1441e+00 (2.0150e+00)\tAcc@1  41.41 ( 46.18)\tAcc@5  74.22 ( 77.05)\n","Epoch: [19][300/391]\tTime  0.168 ( 0.169)\tLoss 1.9580e+00 (2.0181e+00)\tAcc@1  41.41 ( 46.13)\tAcc@5  79.69 ( 76.98)\n","Epoch: [19][330/391]\tTime  0.168 ( 0.169)\tLoss 1.9475e+00 (2.0158e+00)\tAcc@1  46.88 ( 46.11)\tAcc@5  78.12 ( 77.06)\n","Epoch: [19][360/391]\tTime  0.167 ( 0.169)\tLoss 1.7800e+00 (2.0126e+00)\tAcc@1  47.66 ( 46.21)\tAcc@5  87.50 ( 77.14)\n","Epoch: [19][390/391]\tTime  0.152 ( 0.169)\tLoss 1.8781e+00 (2.0127e+00)\tAcc@1  46.25 ( 46.18)\tAcc@5  77.50 ( 77.12)\n","==> Train Accuracy: Acc@1 46.176 || Acc@5 77.116\n","==> Test Accuracy:  Acc@1 48.980 || Acc@5 80.300\n","==> 70.28 seconds to train this epoch\n","\n","\n","----- epoch: 20, lr: 0.1 -----\n","Epoch: [20][  0/391]\tTime  0.260 ( 0.260)\tLoss 1.8763e+00 (1.8763e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  77.34 ( 77.34)\n","Epoch: [20][ 30/391]\tTime  0.170 ( 0.171)\tLoss 1.9179e+00 (1.9457e+00)\tAcc@1  42.19 ( 47.25)\tAcc@5  79.69 ( 78.63)\n","Epoch: [20][ 60/391]\tTime  0.170 ( 0.170)\tLoss 2.0228e+00 (1.9596e+00)\tAcc@1  46.09 ( 47.50)\tAcc@5  78.12 ( 78.07)\n","Epoch: [20][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.7059e+00 (1.9642e+00)\tAcc@1  53.12 ( 47.15)\tAcc@5  83.59 ( 77.99)\n","Epoch: [20][120/391]\tTime  0.170 ( 0.169)\tLoss 1.9736e+00 (1.9665e+00)\tAcc@1  44.53 ( 47.22)\tAcc@5  77.34 ( 77.85)\n","Epoch: [20][150/391]\tTime  0.169 ( 0.169)\tLoss 1.8528e+00 (1.9721e+00)\tAcc@1  48.44 ( 46.86)\tAcc@5  83.59 ( 77.78)\n","Epoch: [20][180/391]\tTime  0.168 ( 0.169)\tLoss 2.0490e+00 (1.9719e+00)\tAcc@1  40.62 ( 46.86)\tAcc@5  77.34 ( 77.90)\n","Epoch: [20][210/391]\tTime  0.170 ( 0.169)\tLoss 1.9540e+00 (1.9769e+00)\tAcc@1  43.75 ( 46.79)\tAcc@5  81.25 ( 77.86)\n","Epoch: [20][240/391]\tTime  0.169 ( 0.169)\tLoss 2.1155e+00 (1.9818e+00)\tAcc@1  39.06 ( 46.69)\tAcc@5  78.12 ( 77.75)\n","Epoch: [20][270/391]\tTime  0.168 ( 0.169)\tLoss 2.1892e+00 (1.9817e+00)\tAcc@1  42.19 ( 46.80)\tAcc@5  74.22 ( 77.75)\n","Epoch: [20][300/391]\tTime  0.168 ( 0.169)\tLoss 2.1399e+00 (1.9783e+00)\tAcc@1  49.22 ( 46.83)\tAcc@5  71.88 ( 77.82)\n","Epoch: [20][330/391]\tTime  0.170 ( 0.169)\tLoss 2.3113e+00 (1.9794e+00)\tAcc@1  42.19 ( 46.72)\tAcc@5  71.88 ( 77.82)\n","Epoch: [20][360/391]\tTime  0.169 ( 0.169)\tLoss 1.9767e+00 (1.9823e+00)\tAcc@1  47.66 ( 46.63)\tAcc@5  80.47 ( 77.83)\n","Epoch: [20][390/391]\tTime  0.150 ( 0.169)\tLoss 2.0781e+00 (1.9850e+00)\tAcc@1  37.50 ( 46.62)\tAcc@5  73.75 ( 77.75)\n","==> Train Accuracy: Acc@1 46.624 || Acc@5 77.750\n","==> Test Accuracy:  Acc@1 43.960 || Acc@5 74.680\n","==> 70.27 seconds to train this epoch\n","\n","\n","----- epoch: 21, lr: 0.1 -----\n","Epoch: [21][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.9324e+00 (1.9324e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  75.00 ( 75.00)\n","Epoch: [21][ 30/391]\tTime  0.170 ( 0.171)\tLoss 1.8878e+00 (1.9343e+00)\tAcc@1  48.44 ( 47.58)\tAcc@5  78.91 ( 78.68)\n","Epoch: [21][ 60/391]\tTime  0.170 ( 0.170)\tLoss 1.9310e+00 (1.9472e+00)\tAcc@1  50.00 ( 47.43)\tAcc@5  79.69 ( 78.43)\n","Epoch: [21][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.8092e+00 (1.9355e+00)\tAcc@1  57.81 ( 47.80)\tAcc@5  79.69 ( 78.57)\n","Epoch: [21][120/391]\tTime  0.169 ( 0.169)\tLoss 1.9196e+00 (1.9468e+00)\tAcc@1  52.34 ( 47.80)\tAcc@5  82.03 ( 78.38)\n","Epoch: [21][150/391]\tTime  0.167 ( 0.169)\tLoss 1.9599e+00 (1.9576e+00)\tAcc@1  42.97 ( 47.53)\tAcc@5  75.78 ( 78.31)\n","Epoch: [21][180/391]\tTime  0.167 ( 0.169)\tLoss 2.1633e+00 (1.9698e+00)\tAcc@1  41.41 ( 47.14)\tAcc@5  77.34 ( 78.00)\n","Epoch: [21][210/391]\tTime  0.168 ( 0.169)\tLoss 1.9286e+00 (1.9638e+00)\tAcc@1  50.78 ( 47.21)\tAcc@5  81.25 ( 78.20)\n","Epoch: [21][240/391]\tTime  0.168 ( 0.169)\tLoss 1.7864e+00 (1.9584e+00)\tAcc@1  53.91 ( 47.31)\tAcc@5  75.78 ( 78.25)\n","Epoch: [21][270/391]\tTime  0.168 ( 0.169)\tLoss 1.9283e+00 (1.9632e+00)\tAcc@1  48.44 ( 47.18)\tAcc@5  75.00 ( 78.20)\n","Epoch: [21][300/391]\tTime  0.169 ( 0.169)\tLoss 2.0781e+00 (1.9671e+00)\tAcc@1  41.41 ( 47.09)\tAcc@5  75.78 ( 78.15)\n","Epoch: [21][330/391]\tTime  0.169 ( 0.169)\tLoss 2.0134e+00 (1.9646e+00)\tAcc@1  47.66 ( 47.13)\tAcc@5  74.22 ( 78.19)\n","Epoch: [21][360/391]\tTime  0.170 ( 0.169)\tLoss 1.9909e+00 (1.9652e+00)\tAcc@1  54.69 ( 47.02)\tAcc@5  80.47 ( 78.21)\n","Epoch: [21][390/391]\tTime  0.153 ( 0.169)\tLoss 1.9694e+00 (1.9677e+00)\tAcc@1  50.00 ( 46.92)\tAcc@5  76.25 ( 78.13)\n","==> Train Accuracy: Acc@1 46.924 || Acc@5 78.126\n","==> Test Accuracy:  Acc@1 51.110 || Acc@5 82.030\n","==> 70.19 seconds to train this epoch\n","\n","\n","----- epoch: 22, lr: 0.1 -----\n","Epoch: [22][  0/391]\tTime  0.253 ( 0.253)\tLoss 2.0708e+00 (2.0708e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  74.22 ( 74.22)\n","Epoch: [22][ 30/391]\tTime  0.170 ( 0.171)\tLoss 1.6640e+00 (1.9029e+00)\tAcc@1  50.00 ( 48.36)\tAcc@5  84.38 ( 78.65)\n","Epoch: [22][ 60/391]\tTime  0.169 ( 0.170)\tLoss 2.0380e+00 (1.9214e+00)\tAcc@1  46.88 ( 48.08)\tAcc@5  76.56 ( 78.66)\n","Epoch: [22][ 90/391]\tTime  0.167 ( 0.170)\tLoss 1.7464e+00 (1.9249e+00)\tAcc@1  53.91 ( 48.15)\tAcc@5  81.25 ( 78.61)\n","Epoch: [22][120/391]\tTime  0.169 ( 0.170)\tLoss 1.7306e+00 (1.9270e+00)\tAcc@1  48.44 ( 48.14)\tAcc@5  83.59 ( 78.49)\n","Epoch: [22][150/391]\tTime  0.171 ( 0.170)\tLoss 1.9334e+00 (1.9286e+00)\tAcc@1  48.44 ( 48.08)\tAcc@5  75.78 ( 78.35)\n","Epoch: [22][180/391]\tTime  0.170 ( 0.169)\tLoss 2.0243e+00 (1.9322e+00)\tAcc@1  47.66 ( 48.04)\tAcc@5  78.12 ( 78.38)\n","Epoch: [22][210/391]\tTime  0.171 ( 0.169)\tLoss 2.1446e+00 (1.9311e+00)\tAcc@1  41.41 ( 48.02)\tAcc@5  76.56 ( 78.50)\n","Epoch: [22][240/391]\tTime  0.168 ( 0.169)\tLoss 1.7616e+00 (1.9410e+00)\tAcc@1  53.12 ( 47.85)\tAcc@5  78.91 ( 78.21)\n","Epoch: [22][270/391]\tTime  0.170 ( 0.169)\tLoss 1.8064e+00 (1.9434e+00)\tAcc@1  46.88 ( 47.73)\tAcc@5  81.25 ( 78.25)\n","Epoch: [22][300/391]\tTime  0.168 ( 0.169)\tLoss 1.8400e+00 (1.9423e+00)\tAcc@1  54.69 ( 47.67)\tAcc@5  78.91 ( 78.36)\n","Epoch: [22][330/391]\tTime  0.169 ( 0.169)\tLoss 2.0935e+00 (1.9426e+00)\tAcc@1  46.88 ( 47.72)\tAcc@5  78.91 ( 78.33)\n","Epoch: [22][360/391]\tTime  0.167 ( 0.169)\tLoss 2.0442e+00 (1.9449e+00)\tAcc@1  46.88 ( 47.67)\tAcc@5  76.56 ( 78.29)\n","Epoch: [22][390/391]\tTime  0.151 ( 0.169)\tLoss 2.4440e+00 (1.9467e+00)\tAcc@1  38.75 ( 47.59)\tAcc@5  71.25 ( 78.24)\n","==> Train Accuracy: Acc@1 47.586 || Acc@5 78.244\n","==> Test Accuracy:  Acc@1 54.100 || Acc@5 83.350\n","==> 70.24 seconds to train this epoch\n","\n","\n","----- epoch: 23, lr: 0.1 -----\n","Epoch: [23][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.7932e+00 (1.7932e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  77.34 ( 77.34)\n","Epoch: [23][ 30/391]\tTime  0.170 ( 0.171)\tLoss 1.8731e+00 (1.9294e+00)\tAcc@1  50.00 ( 49.14)\tAcc@5  77.34 ( 78.88)\n","Epoch: [23][ 60/391]\tTime  0.170 ( 0.170)\tLoss 1.8320e+00 (1.9198e+00)\tAcc@1  53.12 ( 48.85)\tAcc@5  78.12 ( 78.86)\n","Epoch: [23][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.8267e+00 (1.9224e+00)\tAcc@1  52.34 ( 48.94)\tAcc@5  77.34 ( 78.76)\n","Epoch: [23][120/391]\tTime  0.168 ( 0.169)\tLoss 2.0631e+00 (1.9278e+00)\tAcc@1  46.09 ( 48.57)\tAcc@5  70.31 ( 78.51)\n","Epoch: [23][150/391]\tTime  0.168 ( 0.169)\tLoss 1.9671e+00 (1.9213e+00)\tAcc@1  45.31 ( 48.51)\tAcc@5  78.91 ( 78.81)\n","Epoch: [23][180/391]\tTime  0.169 ( 0.169)\tLoss 1.9594e+00 (1.9232e+00)\tAcc@1  49.22 ( 48.46)\tAcc@5  71.88 ( 78.72)\n","Epoch: [23][210/391]\tTime  0.169 ( 0.169)\tLoss 1.4278e+00 (1.9247e+00)\tAcc@1  64.84 ( 48.39)\tAcc@5  89.84 ( 78.67)\n","Epoch: [23][240/391]\tTime  0.168 ( 0.169)\tLoss 1.9238e+00 (1.9280e+00)\tAcc@1  45.31 ( 48.34)\tAcc@5  82.03 ( 78.60)\n","Epoch: [23][270/391]\tTime  0.167 ( 0.169)\tLoss 1.9104e+00 (1.9248e+00)\tAcc@1  47.66 ( 48.56)\tAcc@5  82.03 ( 78.69)\n","Epoch: [23][300/391]\tTime  0.170 ( 0.169)\tLoss 2.1997e+00 (1.9285e+00)\tAcc@1  40.62 ( 48.42)\tAcc@5  72.66 ( 78.62)\n","Epoch: [23][330/391]\tTime  0.169 ( 0.169)\tLoss 2.0667e+00 (1.9332e+00)\tAcc@1  42.19 ( 48.35)\tAcc@5  75.00 ( 78.56)\n","Epoch: [23][360/391]\tTime  0.169 ( 0.169)\tLoss 1.8385e+00 (1.9371e+00)\tAcc@1  47.66 ( 48.24)\tAcc@5  82.03 ( 78.50)\n","Epoch: [23][390/391]\tTime  0.151 ( 0.169)\tLoss 2.0620e+00 (1.9370e+00)\tAcc@1  43.75 ( 48.20)\tAcc@5  76.25 ( 78.53)\n","==> Train Accuracy: Acc@1 48.200 || Acc@5 78.530\n","==> Test Accuracy:  Acc@1 52.090 || Acc@5 81.720\n","==> 70.19 seconds to train this epoch\n","\n","\n","----- epoch: 24, lr: 0.1 -----\n","Epoch: [24][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.8044e+00 (1.8044e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  83.59 ( 83.59)\n","Epoch: [24][ 30/391]\tTime  0.170 ( 0.171)\tLoss 2.0250e+00 (1.8818e+00)\tAcc@1  43.75 ( 49.52)\tAcc@5  78.91 ( 79.36)\n","Epoch: [24][ 60/391]\tTime  0.171 ( 0.170)\tLoss 1.7267e+00 (1.8911e+00)\tAcc@1  53.12 ( 49.05)\tAcc@5  87.50 ( 79.29)\n","Epoch: [24][ 90/391]\tTime  0.167 ( 0.170)\tLoss 1.8307e+00 (1.8801e+00)\tAcc@1  45.31 ( 49.12)\tAcc@5  79.69 ( 79.63)\n","Epoch: [24][120/391]\tTime  0.169 ( 0.169)\tLoss 1.9412e+00 (1.8957e+00)\tAcc@1  49.22 ( 48.68)\tAcc@5  78.12 ( 79.51)\n","Epoch: [24][150/391]\tTime  0.169 ( 0.169)\tLoss 1.7646e+00 (1.9042e+00)\tAcc@1  57.03 ( 48.59)\tAcc@5  85.94 ( 79.38)\n","Epoch: [24][180/391]\tTime  0.169 ( 0.169)\tLoss 1.7941e+00 (1.9026e+00)\tAcc@1  46.09 ( 48.55)\tAcc@5  85.16 ( 79.36)\n","Epoch: [24][210/391]\tTime  0.169 ( 0.169)\tLoss 1.9518e+00 (1.9059e+00)\tAcc@1  50.78 ( 48.51)\tAcc@5  76.56 ( 79.25)\n","Epoch: [24][240/391]\tTime  0.170 ( 0.169)\tLoss 2.1551e+00 (1.9171e+00)\tAcc@1  43.75 ( 48.28)\tAcc@5  72.66 ( 79.02)\n","Epoch: [24][270/391]\tTime  0.169 ( 0.169)\tLoss 2.3080e+00 (1.9264e+00)\tAcc@1  46.88 ( 48.12)\tAcc@5  71.09 ( 78.87)\n","Epoch: [24][300/391]\tTime  0.168 ( 0.169)\tLoss 1.7971e+00 (1.9268e+00)\tAcc@1  52.34 ( 48.06)\tAcc@5  84.38 ( 78.84)\n","Epoch: [24][330/391]\tTime  0.170 ( 0.169)\tLoss 2.1566e+00 (1.9288e+00)\tAcc@1  45.31 ( 48.04)\tAcc@5  70.31 ( 78.76)\n","Epoch: [24][360/391]\tTime  0.168 ( 0.169)\tLoss 2.0141e+00 (1.9294e+00)\tAcc@1  46.09 ( 48.02)\tAcc@5  75.00 ( 78.72)\n","Epoch: [24][390/391]\tTime  0.150 ( 0.169)\tLoss 1.7376e+00 (1.9283e+00)\tAcc@1  46.25 ( 48.15)\tAcc@5  81.25 ( 78.78)\n","==> Train Accuracy: Acc@1 48.146 || Acc@5 78.782\n","==> Test Accuracy:  Acc@1 52.750 || Acc@5 81.840\n","==> 70.26 seconds to train this epoch\n","\n","\n","----- epoch: 25, lr: 0.1 -----\n","Epoch: [25][  0/391]\tTime  0.273 ( 0.273)\tLoss 2.1209e+00 (2.1209e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  78.91 ( 78.91)\n","Epoch: [25][ 30/391]\tTime  0.170 ( 0.172)\tLoss 1.8330e+00 (1.8329e+00)\tAcc@1  51.56 ( 50.66)\tAcc@5  77.34 ( 80.57)\n","Epoch: [25][ 60/391]\tTime  0.169 ( 0.170)\tLoss 1.9843e+00 (1.8399e+00)\tAcc@1  46.88 ( 50.40)\tAcc@5  78.12 ( 80.40)\n","Epoch: [25][ 90/391]\tTime  0.168 ( 0.170)\tLoss 2.0721e+00 (1.8717e+00)\tAcc@1  43.75 ( 49.48)\tAcc@5  75.78 ( 79.83)\n","Epoch: [25][120/391]\tTime  0.169 ( 0.170)\tLoss 1.9277e+00 (1.8856e+00)\tAcc@1  46.09 ( 49.08)\tAcc@5  73.44 ( 79.41)\n","Epoch: [25][150/391]\tTime  0.168 ( 0.169)\tLoss 1.7139e+00 (1.9027e+00)\tAcc@1  58.59 ( 48.55)\tAcc@5  82.81 ( 79.08)\n","Epoch: [25][180/391]\tTime  0.170 ( 0.169)\tLoss 1.8195e+00 (1.8967e+00)\tAcc@1  50.00 ( 48.85)\tAcc@5  82.81 ( 79.07)\n","Epoch: [25][210/391]\tTime  0.172 ( 0.169)\tLoss 1.8310e+00 (1.9009e+00)\tAcc@1  50.00 ( 48.64)\tAcc@5  77.34 ( 79.09)\n","Epoch: [25][240/391]\tTime  0.169 ( 0.169)\tLoss 1.9855e+00 (1.9075e+00)\tAcc@1  46.09 ( 48.58)\tAcc@5  78.91 ( 79.00)\n","Epoch: [25][270/391]\tTime  0.169 ( 0.169)\tLoss 1.9642e+00 (1.9034e+00)\tAcc@1  51.56 ( 48.71)\tAcc@5  77.34 ( 79.14)\n","Epoch: [25][300/391]\tTime  0.168 ( 0.169)\tLoss 1.9650e+00 (1.9050e+00)\tAcc@1  47.66 ( 48.67)\tAcc@5  74.22 ( 79.11)\n","Epoch: [25][330/391]\tTime  0.170 ( 0.169)\tLoss 1.7850e+00 (1.9055e+00)\tAcc@1  47.66 ( 48.65)\tAcc@5  84.38 ( 79.09)\n","Epoch: [25][360/391]\tTime  0.169 ( 0.169)\tLoss 1.8838e+00 (1.9060e+00)\tAcc@1  44.53 ( 48.64)\tAcc@5  78.12 ( 78.99)\n","Epoch: [25][390/391]\tTime  0.149 ( 0.169)\tLoss 1.8859e+00 (1.9084e+00)\tAcc@1  48.75 ( 48.52)\tAcc@5  82.50 ( 79.04)\n","==> Train Accuracy: Acc@1 48.516 || Acc@5 79.036\n","==> Test Accuracy:  Acc@1 52.950 || Acc@5 82.720\n","==> 70.25 seconds to train this epoch\n","\n","\n","----- epoch: 26, lr: 0.1 -----\n","Epoch: [26][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.8972e+00 (1.8972e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  79.69 ( 79.69)\n","Epoch: [26][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.8692e+00 (1.8978e+00)\tAcc@1  50.78 ( 49.14)\tAcc@5  79.69 ( 79.59)\n","Epoch: [26][ 60/391]\tTime  0.168 ( 0.170)\tLoss 2.2890e+00 (1.8660e+00)\tAcc@1  39.84 ( 49.62)\tAcc@5  71.09 ( 80.30)\n","Epoch: [26][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.9442e+00 (1.8755e+00)\tAcc@1  47.66 ( 49.18)\tAcc@5  78.12 ( 79.80)\n","Epoch: [26][120/391]\tTime  0.168 ( 0.169)\tLoss 2.0558e+00 (1.8800e+00)\tAcc@1  49.22 ( 49.17)\tAcc@5  76.56 ( 79.82)\n","Epoch: [26][150/391]\tTime  0.168 ( 0.169)\tLoss 1.8222e+00 (1.8830e+00)\tAcc@1  50.78 ( 49.20)\tAcc@5  82.03 ( 79.72)\n","Epoch: [26][180/391]\tTime  0.170 ( 0.169)\tLoss 1.8378e+00 (1.8864e+00)\tAcc@1  52.34 ( 49.23)\tAcc@5  83.59 ( 79.57)\n","Epoch: [26][210/391]\tTime  0.170 ( 0.169)\tLoss 1.8141e+00 (1.8917e+00)\tAcc@1  46.09 ( 48.92)\tAcc@5  85.16 ( 79.57)\n","Epoch: [26][240/391]\tTime  0.168 ( 0.169)\tLoss 1.7006e+00 (1.8979e+00)\tAcc@1  57.81 ( 48.74)\tAcc@5  83.59 ( 79.44)\n","Epoch: [26][270/391]\tTime  0.173 ( 0.169)\tLoss 1.8358e+00 (1.8983e+00)\tAcc@1  51.56 ( 48.75)\tAcc@5  82.03 ( 79.39)\n","Epoch: [26][300/391]\tTime  0.172 ( 0.169)\tLoss 1.9505e+00 (1.8961e+00)\tAcc@1  50.00 ( 48.77)\tAcc@5  78.12 ( 79.41)\n","Epoch: [26][330/391]\tTime  0.169 ( 0.169)\tLoss 1.9374e+00 (1.8996e+00)\tAcc@1  43.75 ( 48.69)\tAcc@5  79.69 ( 79.35)\n","Epoch: [26][360/391]\tTime  0.168 ( 0.169)\tLoss 2.0320e+00 (1.9014e+00)\tAcc@1  50.00 ( 48.67)\tAcc@5  76.56 ( 79.26)\n","Epoch: [26][390/391]\tTime  0.150 ( 0.169)\tLoss 1.6604e+00 (1.9012e+00)\tAcc@1  53.75 ( 48.71)\tAcc@5  86.25 ( 79.29)\n","==> Train Accuracy: Acc@1 48.714 || Acc@5 79.286\n","==> Test Accuracy:  Acc@1 51.200 || Acc@5 82.270\n","==> 70.24 seconds to train this epoch\n","\n","\n","----- epoch: 27, lr: 0.1 -----\n","Epoch: [27][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.9809e+00 (1.9809e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  78.91 ( 78.91)\n","Epoch: [27][ 30/391]\tTime  0.168 ( 0.172)\tLoss 1.9879e+00 (1.8525e+00)\tAcc@1  35.94 ( 49.80)\tAcc@5  79.69 ( 79.69)\n","Epoch: [27][ 60/391]\tTime  0.170 ( 0.170)\tLoss 2.0416e+00 (1.8575e+00)\tAcc@1  44.53 ( 49.60)\tAcc@5  77.34 ( 79.83)\n","Epoch: [27][ 90/391]\tTime  0.168 ( 0.170)\tLoss 2.1956e+00 (1.8704e+00)\tAcc@1  39.06 ( 49.35)\tAcc@5  75.00 ( 79.63)\n","Epoch: [27][120/391]\tTime  0.169 ( 0.170)\tLoss 1.9830e+00 (1.8624e+00)\tAcc@1  47.66 ( 49.50)\tAcc@5  77.34 ( 79.87)\n","Epoch: [27][150/391]\tTime  0.168 ( 0.170)\tLoss 2.2954e+00 (1.8695e+00)\tAcc@1  37.50 ( 49.29)\tAcc@5  71.09 ( 79.82)\n","Epoch: [27][180/391]\tTime  0.169 ( 0.169)\tLoss 1.7332e+00 (1.8672e+00)\tAcc@1  55.47 ( 49.42)\tAcc@5  80.47 ( 79.96)\n","Epoch: [27][210/391]\tTime  0.169 ( 0.169)\tLoss 1.4845e+00 (1.8721e+00)\tAcc@1  57.03 ( 49.40)\tAcc@5  83.59 ( 79.84)\n","Epoch: [27][240/391]\tTime  0.169 ( 0.169)\tLoss 2.1580e+00 (1.8722e+00)\tAcc@1  42.97 ( 49.44)\tAcc@5  69.53 ( 79.71)\n","Epoch: [27][270/391]\tTime  0.169 ( 0.169)\tLoss 1.9726e+00 (1.8735e+00)\tAcc@1  49.22 ( 49.38)\tAcc@5  75.78 ( 79.80)\n","Epoch: [27][300/391]\tTime  0.167 ( 0.169)\tLoss 2.0107e+00 (1.8795e+00)\tAcc@1  46.88 ( 49.23)\tAcc@5  78.91 ( 79.70)\n","Epoch: [27][330/391]\tTime  0.169 ( 0.169)\tLoss 1.9924e+00 (1.8814e+00)\tAcc@1  50.00 ( 49.20)\tAcc@5  76.56 ( 79.58)\n","Epoch: [27][360/391]\tTime  0.168 ( 0.169)\tLoss 1.8580e+00 (1.8814e+00)\tAcc@1  46.88 ( 49.16)\tAcc@5  80.47 ( 79.60)\n","Epoch: [27][390/391]\tTime  0.150 ( 0.169)\tLoss 1.9573e+00 (1.8805e+00)\tAcc@1  48.75 ( 49.21)\tAcc@5  76.25 ( 79.55)\n","==> Train Accuracy: Acc@1 49.206 || Acc@5 79.554\n","==> Test Accuracy:  Acc@1 49.870 || Acc@5 81.030\n","==> 70.24 seconds to train this epoch\n","\n","\n","----- epoch: 28, lr: 0.1 -----\n","Epoch: [28][  0/391]\tTime  0.252 ( 0.252)\tLoss 1.8691e+00 (1.8691e+00)\tAcc@1  45.31 ( 45.31)\tAcc@5  80.47 ( 80.47)\n","Epoch: [28][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.7503e+00 (1.8622e+00)\tAcc@1  48.44 ( 49.32)\tAcc@5  82.03 ( 79.94)\n","Epoch: [28][ 60/391]\tTime  0.171 ( 0.170)\tLoss 1.6992e+00 (1.8564e+00)\tAcc@1  53.91 ( 49.85)\tAcc@5  85.16 ( 80.06)\n","Epoch: [28][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.7043e+00 (1.8560e+00)\tAcc@1  53.12 ( 49.44)\tAcc@5  78.91 ( 79.77)\n","Epoch: [28][120/391]\tTime  0.170 ( 0.169)\tLoss 1.9202e+00 (1.8537e+00)\tAcc@1  46.09 ( 49.50)\tAcc@5  78.12 ( 80.00)\n","Epoch: [28][150/391]\tTime  0.169 ( 0.169)\tLoss 1.8304e+00 (1.8638e+00)\tAcc@1  53.12 ( 49.32)\tAcc@5  78.91 ( 79.82)\n","Epoch: [28][180/391]\tTime  0.169 ( 0.169)\tLoss 1.8587e+00 (1.8665e+00)\tAcc@1  50.00 ( 49.27)\tAcc@5  80.47 ( 79.81)\n","Epoch: [28][210/391]\tTime  0.168 ( 0.169)\tLoss 2.0788e+00 (1.8723e+00)\tAcc@1  47.66 ( 49.28)\tAcc@5  72.66 ( 79.71)\n","Epoch: [28][240/391]\tTime  0.168 ( 0.169)\tLoss 1.8818e+00 (1.8744e+00)\tAcc@1  52.34 ( 49.37)\tAcc@5  76.56 ( 79.54)\n","Epoch: [28][270/391]\tTime  0.170 ( 0.169)\tLoss 1.7472e+00 (1.8766e+00)\tAcc@1  53.91 ( 49.34)\tAcc@5  86.72 ( 79.58)\n","Epoch: [28][300/391]\tTime  0.170 ( 0.169)\tLoss 1.8599e+00 (1.8828e+00)\tAcc@1  53.91 ( 49.22)\tAcc@5  82.81 ( 79.48)\n","Epoch: [28][330/391]\tTime  0.170 ( 0.169)\tLoss 1.7130e+00 (1.8873e+00)\tAcc@1  50.78 ( 49.09)\tAcc@5  83.59 ( 79.39)\n","Epoch: [28][360/391]\tTime  0.169 ( 0.169)\tLoss 1.9199e+00 (1.8891e+00)\tAcc@1  49.22 ( 49.03)\tAcc@5  77.34 ( 79.42)\n","Epoch: [28][390/391]\tTime  0.154 ( 0.169)\tLoss 1.9614e+00 (1.8866e+00)\tAcc@1  45.00 ( 49.14)\tAcc@5  76.25 ( 79.45)\n","==> Train Accuracy: Acc@1 49.142 || Acc@5 79.446\n","==> Test Accuracy:  Acc@1 53.670 || Acc@5 83.640\n","==> 70.23 seconds to train this epoch\n","\n","\n","----- epoch: 29, lr: 0.1 -----\n","Epoch: [29][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.8102e+00 (1.8102e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  76.56 ( 76.56)\n","Epoch: [29][ 30/391]\tTime  0.169 ( 0.172)\tLoss 1.7063e+00 (1.8390e+00)\tAcc@1  55.47 ( 49.32)\tAcc@5  82.81 ( 80.12)\n","Epoch: [29][ 60/391]\tTime  0.170 ( 0.170)\tLoss 1.7252e+00 (1.8505e+00)\tAcc@1  57.81 ( 49.63)\tAcc@5  78.91 ( 79.82)\n","Epoch: [29][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.8808e+00 (1.8458e+00)\tAcc@1  56.25 ( 49.84)\tAcc@5  80.47 ( 80.24)\n","Epoch: [29][120/391]\tTime  0.169 ( 0.170)\tLoss 1.9733e+00 (1.8483e+00)\tAcc@1  43.75 ( 49.69)\tAcc@5  75.78 ( 80.21)\n","Epoch: [29][150/391]\tTime  0.168 ( 0.169)\tLoss 1.8878e+00 (1.8471e+00)\tAcc@1  48.44 ( 49.69)\tAcc@5  78.91 ( 80.31)\n","Epoch: [29][180/391]\tTime  0.168 ( 0.169)\tLoss 1.9598e+00 (1.8458e+00)\tAcc@1  44.53 ( 49.67)\tAcc@5  82.03 ( 80.39)\n","Epoch: [29][210/391]\tTime  0.168 ( 0.169)\tLoss 1.8060e+00 (1.8533e+00)\tAcc@1  53.91 ( 49.72)\tAcc@5  79.69 ( 80.17)\n","Epoch: [29][240/391]\tTime  0.169 ( 0.169)\tLoss 1.8236e+00 (1.8522e+00)\tAcc@1  50.78 ( 49.76)\tAcc@5  78.12 ( 80.07)\n","Epoch: [29][270/391]\tTime  0.169 ( 0.169)\tLoss 2.0523e+00 (1.8603e+00)\tAcc@1  46.88 ( 49.57)\tAcc@5  72.66 ( 79.87)\n","Epoch: [29][300/391]\tTime  0.169 ( 0.169)\tLoss 1.7476e+00 (1.8637e+00)\tAcc@1  53.91 ( 49.48)\tAcc@5  80.47 ( 79.85)\n","Epoch: [29][330/391]\tTime  0.169 ( 0.169)\tLoss 2.1504e+00 (1.8669e+00)\tAcc@1  48.44 ( 49.41)\tAcc@5  74.22 ( 79.76)\n","Epoch: [29][360/391]\tTime  0.169 ( 0.169)\tLoss 1.9411e+00 (1.8717e+00)\tAcc@1  45.31 ( 49.25)\tAcc@5  79.69 ( 79.67)\n","Epoch: [29][390/391]\tTime  0.151 ( 0.169)\tLoss 1.5092e+00 (1.8760e+00)\tAcc@1  55.00 ( 49.16)\tAcc@5  86.25 ( 79.59)\n","==> Train Accuracy: Acc@1 49.158 || Acc@5 79.590\n","==> Test Accuracy:  Acc@1 52.780 || Acc@5 82.970\n","==> 70.16 seconds to train this epoch\n","\n","\n","----- epoch: 30, lr: 0.1 -----\n","Epoch: [30][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.7551e+00 (1.7551e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  79.69 ( 79.69)\n","Epoch: [30][ 30/391]\tTime  0.170 ( 0.171)\tLoss 1.7266e+00 (1.8016e+00)\tAcc@1  53.91 ( 50.96)\tAcc@5  82.03 ( 80.80)\n","Epoch: [30][ 60/391]\tTime  0.169 ( 0.170)\tLoss 1.9133e+00 (1.8215e+00)\tAcc@1  47.66 ( 50.53)\tAcc@5  80.47 ( 80.66)\n","Epoch: [30][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.8322e+00 (1.8347e+00)\tAcc@1  53.12 ( 50.64)\tAcc@5  80.47 ( 80.29)\n","Epoch: [30][120/391]\tTime  0.170 ( 0.169)\tLoss 2.0301e+00 (1.8436e+00)\tAcc@1  49.22 ( 50.41)\tAcc@5  72.66 ( 80.20)\n","Epoch: [30][150/391]\tTime  0.168 ( 0.169)\tLoss 1.7892e+00 (1.8498e+00)\tAcc@1  43.75 ( 50.21)\tAcc@5  81.25 ( 80.16)\n","Epoch: [30][180/391]\tTime  0.169 ( 0.169)\tLoss 2.0240e+00 (1.8540e+00)\tAcc@1  42.19 ( 50.08)\tAcc@5  74.22 ( 80.11)\n","Epoch: [30][210/391]\tTime  0.168 ( 0.169)\tLoss 1.7395e+00 (1.8533e+00)\tAcc@1  51.56 ( 50.13)\tAcc@5  82.03 ( 80.23)\n","Epoch: [30][240/391]\tTime  0.168 ( 0.169)\tLoss 1.9085e+00 (1.8493e+00)\tAcc@1  51.56 ( 50.24)\tAcc@5  75.00 ( 80.29)\n","Epoch: [30][270/391]\tTime  0.170 ( 0.169)\tLoss 1.9380e+00 (1.8561e+00)\tAcc@1  53.91 ( 50.05)\tAcc@5  76.56 ( 80.20)\n","Epoch: [30][300/391]\tTime  0.169 ( 0.169)\tLoss 1.8006e+00 (1.8601e+00)\tAcc@1  54.69 ( 50.00)\tAcc@5  82.03 ( 80.13)\n","Epoch: [30][330/391]\tTime  0.167 ( 0.169)\tLoss 1.9429e+00 (1.8641e+00)\tAcc@1  48.44 ( 49.97)\tAcc@5  78.12 ( 80.05)\n","Epoch: [30][360/391]\tTime  0.168 ( 0.169)\tLoss 2.0204e+00 (1.8643e+00)\tAcc@1  43.75 ( 49.96)\tAcc@5  82.03 ( 80.06)\n","Epoch: [30][390/391]\tTime  0.151 ( 0.169)\tLoss 1.9739e+00 (1.8655e+00)\tAcc@1  51.25 ( 49.93)\tAcc@5  80.00 ( 80.02)\n","==> Train Accuracy: Acc@1 49.928 || Acc@5 80.020\n","==> Test Accuracy:  Acc@1 52.440 || Acc@5 82.850\n","==> 70.26 seconds to train this epoch\n","\n","\n","----- epoch: 31, lr: 0.1 -----\n","Epoch: [31][  0/391]\tTime  0.260 ( 0.260)\tLoss 1.7865e+00 (1.7865e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  81.25 ( 81.25)\n","Epoch: [31][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.8568e+00 (1.8179e+00)\tAcc@1  50.78 ( 50.00)\tAcc@5  78.12 ( 81.07)\n","Epoch: [31][ 60/391]\tTime  0.170 ( 0.170)\tLoss 1.7888e+00 (1.8272e+00)\tAcc@1  46.88 ( 49.82)\tAcc@5  78.12 ( 80.89)\n","Epoch: [31][ 90/391]\tTime  0.170 ( 0.170)\tLoss 2.0248e+00 (1.8387e+00)\tAcc@1  43.75 ( 49.60)\tAcc@5  75.00 ( 80.43)\n","Epoch: [31][120/391]\tTime  0.170 ( 0.169)\tLoss 2.0300e+00 (1.8513e+00)\tAcc@1  41.41 ( 49.32)\tAcc@5  78.91 ( 80.16)\n","Epoch: [31][150/391]\tTime  0.169 ( 0.169)\tLoss 1.8184e+00 (1.8458e+00)\tAcc@1  53.12 ( 49.71)\tAcc@5  82.81 ( 80.15)\n","Epoch: [31][180/391]\tTime  0.169 ( 0.169)\tLoss 1.8772e+00 (1.8514e+00)\tAcc@1  50.00 ( 49.53)\tAcc@5  79.69 ( 80.12)\n","Epoch: [31][210/391]\tTime  0.168 ( 0.169)\tLoss 1.7879e+00 (1.8446e+00)\tAcc@1  47.66 ( 49.88)\tAcc@5  83.59 ( 80.22)\n","Epoch: [31][240/391]\tTime  0.169 ( 0.169)\tLoss 1.8265e+00 (1.8518e+00)\tAcc@1  51.56 ( 49.56)\tAcc@5  80.47 ( 80.08)\n","Epoch: [31][270/391]\tTime  0.169 ( 0.169)\tLoss 1.7875e+00 (1.8550e+00)\tAcc@1  50.00 ( 49.53)\tAcc@5  82.81 ( 79.98)\n","Epoch: [31][300/391]\tTime  0.168 ( 0.169)\tLoss 1.6257e+00 (1.8520e+00)\tAcc@1  52.34 ( 49.66)\tAcc@5  81.25 ( 80.05)\n","Epoch: [31][330/391]\tTime  0.169 ( 0.169)\tLoss 1.8743e+00 (1.8599e+00)\tAcc@1  46.09 ( 49.47)\tAcc@5  79.69 ( 79.90)\n","Epoch: [31][360/391]\tTime  0.166 ( 0.169)\tLoss 2.1919e+00 (1.8627e+00)\tAcc@1  42.19 ( 49.44)\tAcc@5  74.22 ( 79.83)\n","Epoch: [31][390/391]\tTime  0.151 ( 0.169)\tLoss 2.0680e+00 (1.8634e+00)\tAcc@1  50.00 ( 49.42)\tAcc@5  77.50 ( 79.86)\n","==> Train Accuracy: Acc@1 49.422 || Acc@5 79.858\n","==> Test Accuracy:  Acc@1 52.980 || Acc@5 83.170\n","==> 70.11 seconds to train this epoch\n","\n","\n","----- epoch: 32, lr: 0.1 -----\n","Epoch: [32][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.6781e+00 (1.6781e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  83.59 ( 83.59)\n","Epoch: [32][ 30/391]\tTime  0.171 ( 0.172)\tLoss 2.0534e+00 (1.8401e+00)\tAcc@1  42.19 ( 50.35)\tAcc@5  76.56 ( 80.04)\n","Epoch: [32][ 60/391]\tTime  0.169 ( 0.170)\tLoss 2.0928e+00 (1.8420e+00)\tAcc@1  42.19 ( 50.26)\tAcc@5  77.34 ( 79.91)\n","Epoch: [32][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.8356e+00 (1.8340e+00)\tAcc@1  53.12 ( 50.09)\tAcc@5  82.81 ( 80.02)\n","Epoch: [32][120/391]\tTime  0.168 ( 0.170)\tLoss 1.8672e+00 (1.8303e+00)\tAcc@1  49.22 ( 50.20)\tAcc@5  76.56 ( 80.25)\n","Epoch: [32][150/391]\tTime  0.170 ( 0.170)\tLoss 1.7272e+00 (1.8241e+00)\tAcc@1  52.34 ( 50.31)\tAcc@5  82.03 ( 80.35)\n","Epoch: [32][180/391]\tTime  0.170 ( 0.170)\tLoss 2.1512e+00 (1.8284e+00)\tAcc@1  44.53 ( 50.23)\tAcc@5  73.44 ( 80.41)\n","Epoch: [32][210/391]\tTime  0.169 ( 0.170)\tLoss 1.7769e+00 (1.8330e+00)\tAcc@1  50.00 ( 50.25)\tAcc@5  86.72 ( 80.26)\n","Epoch: [32][240/391]\tTime  0.168 ( 0.169)\tLoss 1.8452e+00 (1.8318e+00)\tAcc@1  53.12 ( 50.40)\tAcc@5  80.47 ( 80.26)\n","Epoch: [32][270/391]\tTime  0.168 ( 0.169)\tLoss 1.9741e+00 (1.8372e+00)\tAcc@1  39.84 ( 50.14)\tAcc@5  80.47 ( 80.20)\n","Epoch: [32][300/391]\tTime  0.169 ( 0.169)\tLoss 1.7796e+00 (1.8398e+00)\tAcc@1  54.69 ( 50.12)\tAcc@5  84.38 ( 80.15)\n","Epoch: [32][330/391]\tTime  0.169 ( 0.169)\tLoss 2.0102e+00 (1.8409e+00)\tAcc@1  46.88 ( 50.14)\tAcc@5  78.12 ( 80.18)\n","Epoch: [32][360/391]\tTime  0.168 ( 0.169)\tLoss 2.1759e+00 (1.8450e+00)\tAcc@1  46.09 ( 50.04)\tAcc@5  73.44 ( 80.12)\n","Epoch: [32][390/391]\tTime  0.151 ( 0.169)\tLoss 2.1114e+00 (1.8468e+00)\tAcc@1  45.00 ( 50.01)\tAcc@5  77.50 ( 80.08)\n","==> Train Accuracy: Acc@1 50.006 || Acc@5 80.082\n","==> Test Accuracy:  Acc@1 52.160 || Acc@5 82.780\n","==> 70.28 seconds to train this epoch\n","\n","\n","----- epoch: 33, lr: 0.1 -----\n","Epoch: [33][  0/391]\tTime  0.246 ( 0.246)\tLoss 1.7084e+00 (1.7084e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  85.94 ( 85.94)\n","Epoch: [33][ 30/391]\tTime  0.170 ( 0.171)\tLoss 1.8636e+00 (1.8133e+00)\tAcc@1  47.66 ( 51.16)\tAcc@5  80.47 ( 81.10)\n","Epoch: [33][ 60/391]\tTime  0.170 ( 0.170)\tLoss 1.7840e+00 (1.8061e+00)\tAcc@1  54.69 ( 51.02)\tAcc@5  81.25 ( 81.28)\n","Epoch: [33][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.9952e+00 (1.8052e+00)\tAcc@1  46.88 ( 50.88)\tAcc@5  77.34 ( 81.13)\n","Epoch: [33][120/391]\tTime  0.168 ( 0.169)\tLoss 1.5764e+00 (1.8095e+00)\tAcc@1  57.81 ( 50.79)\tAcc@5  82.81 ( 81.15)\n","Epoch: [33][150/391]\tTime  0.170 ( 0.169)\tLoss 1.8702e+00 (1.8107e+00)\tAcc@1  50.78 ( 50.75)\tAcc@5  81.25 ( 81.03)\n","Epoch: [33][180/391]\tTime  0.169 ( 0.169)\tLoss 1.8455e+00 (1.8121e+00)\tAcc@1  55.47 ( 50.85)\tAcc@5  81.25 ( 80.89)\n","Epoch: [33][210/391]\tTime  0.169 ( 0.169)\tLoss 1.8201e+00 (1.8177e+00)\tAcc@1  46.09 ( 50.70)\tAcc@5  78.91 ( 80.75)\n","Epoch: [33][240/391]\tTime  0.169 ( 0.169)\tLoss 2.0753e+00 (1.8229e+00)\tAcc@1  45.31 ( 50.71)\tAcc@5  78.91 ( 80.58)\n","Epoch: [33][270/391]\tTime  0.169 ( 0.169)\tLoss 1.6314e+00 (1.8303e+00)\tAcc@1  54.69 ( 50.53)\tAcc@5  82.03 ( 80.47)\n","Epoch: [33][300/391]\tTime  0.168 ( 0.169)\tLoss 1.8710e+00 (1.8332e+00)\tAcc@1  50.78 ( 50.46)\tAcc@5  75.78 ( 80.43)\n","Epoch: [33][330/391]\tTime  0.168 ( 0.169)\tLoss 1.6379e+00 (1.8409e+00)\tAcc@1  53.12 ( 50.26)\tAcc@5  86.72 ( 80.32)\n","Epoch: [33][360/391]\tTime  0.168 ( 0.169)\tLoss 2.0338e+00 (1.8482e+00)\tAcc@1  46.88 ( 50.12)\tAcc@5  75.00 ( 80.17)\n","Epoch: [33][390/391]\tTime  0.151 ( 0.169)\tLoss 1.5283e+00 (1.8526e+00)\tAcc@1  62.50 ( 50.06)\tAcc@5  85.00 ( 80.09)\n","==> Train Accuracy: Acc@1 50.058 || Acc@5 80.086\n","==> Test Accuracy:  Acc@1 55.000 || Acc@5 84.640\n","==> 70.23 seconds to train this epoch\n","\n","\n","----- epoch: 34, lr: 0.1 -----\n","Epoch: [34][  0/391]\tTime  0.284 ( 0.284)\tLoss 2.1764e+00 (2.1764e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  74.22 ( 74.22)\n","Epoch: [34][ 30/391]\tTime  0.170 ( 0.172)\tLoss 1.8183e+00 (1.7996e+00)\tAcc@1  48.44 ( 50.43)\tAcc@5  81.25 ( 81.33)\n","Epoch: [34][ 60/391]\tTime  0.168 ( 0.170)\tLoss 1.7974e+00 (1.7937e+00)\tAcc@1  50.00 ( 50.61)\tAcc@5  82.03 ( 81.33)\n","Epoch: [34][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.9217e+00 (1.7920e+00)\tAcc@1  48.44 ( 51.04)\tAcc@5  75.00 ( 81.22)\n","Epoch: [34][120/391]\tTime  0.169 ( 0.169)\tLoss 1.7197e+00 (1.8019e+00)\tAcc@1  56.25 ( 50.76)\tAcc@5  83.59 ( 81.04)\n","Epoch: [34][150/391]\tTime  0.169 ( 0.169)\tLoss 1.7291e+00 (1.8004e+00)\tAcc@1  48.44 ( 50.98)\tAcc@5  81.25 ( 81.07)\n","Epoch: [34][180/391]\tTime  0.169 ( 0.169)\tLoss 1.9343e+00 (1.8119e+00)\tAcc@1  49.22 ( 50.73)\tAcc@5  78.91 ( 80.87)\n","Epoch: [34][210/391]\tTime  0.170 ( 0.169)\tLoss 2.0156e+00 (1.8114e+00)\tAcc@1  46.88 ( 50.78)\tAcc@5  75.78 ( 80.83)\n","Epoch: [34][240/391]\tTime  0.168 ( 0.169)\tLoss 1.7224e+00 (1.8173e+00)\tAcc@1  52.34 ( 50.67)\tAcc@5  82.03 ( 80.67)\n","Epoch: [34][270/391]\tTime  0.169 ( 0.169)\tLoss 1.8745e+00 (1.8205e+00)\tAcc@1  46.88 ( 50.59)\tAcc@5  78.12 ( 80.56)\n","Epoch: [34][300/391]\tTime  0.169 ( 0.169)\tLoss 1.7437e+00 (1.8184e+00)\tAcc@1  50.00 ( 50.66)\tAcc@5  82.81 ( 80.58)\n","Epoch: [34][330/391]\tTime  0.170 ( 0.169)\tLoss 1.8192e+00 (1.8203e+00)\tAcc@1  50.78 ( 50.57)\tAcc@5  81.25 ( 80.61)\n","Epoch: [34][360/391]\tTime  0.168 ( 0.169)\tLoss 1.7752e+00 (1.8242e+00)\tAcc@1  54.69 ( 50.50)\tAcc@5  77.34 ( 80.52)\n","Epoch: [34][390/391]\tTime  0.152 ( 0.169)\tLoss 1.7159e+00 (1.8241e+00)\tAcc@1  55.00 ( 50.48)\tAcc@5  83.75 ( 80.49)\n","==> Train Accuracy: Acc@1 50.482 || Acc@5 80.488\n","==> Test Accuracy:  Acc@1 53.390 || Acc@5 83.020\n","==> 70.17 seconds to train this epoch\n","\n","\n","----- epoch: 35, lr: 0.1 -----\n","Epoch: [35][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.6779e+00 (1.6779e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  84.38 ( 84.38)\n","Epoch: [35][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.5794e+00 (1.7674e+00)\tAcc@1  60.16 ( 51.92)\tAcc@5  85.94 ( 81.63)\n","Epoch: [35][ 60/391]\tTime  0.169 ( 0.170)\tLoss 1.7372e+00 (1.7690e+00)\tAcc@1  54.69 ( 52.09)\tAcc@5  84.38 ( 81.80)\n","Epoch: [35][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.9378e+00 (1.7833e+00)\tAcc@1  49.22 ( 51.67)\tAcc@5  73.44 ( 81.27)\n","Epoch: [35][120/391]\tTime  0.169 ( 0.169)\tLoss 1.8501e+00 (1.7913e+00)\tAcc@1  48.44 ( 51.45)\tAcc@5  78.12 ( 81.24)\n","Epoch: [35][150/391]\tTime  0.172 ( 0.169)\tLoss 2.1147e+00 (1.7928e+00)\tAcc@1  44.53 ( 51.41)\tAcc@5  74.22 ( 81.17)\n","Epoch: [35][180/391]\tTime  0.168 ( 0.169)\tLoss 1.5813e+00 (1.7980e+00)\tAcc@1  53.12 ( 51.28)\tAcc@5  84.38 ( 81.11)\n","Epoch: [35][210/391]\tTime  0.169 ( 0.169)\tLoss 1.9028e+00 (1.8006e+00)\tAcc@1  49.22 ( 51.18)\tAcc@5  78.12 ( 81.04)\n","Epoch: [35][240/391]\tTime  0.169 ( 0.169)\tLoss 1.6825e+00 (1.8056e+00)\tAcc@1  57.81 ( 51.12)\tAcc@5  80.47 ( 80.99)\n","Epoch: [35][270/391]\tTime  0.167 ( 0.169)\tLoss 1.9989e+00 (1.8069e+00)\tAcc@1  41.41 ( 51.08)\tAcc@5  73.44 ( 80.92)\n","Epoch: [35][300/391]\tTime  0.170 ( 0.169)\tLoss 1.7973e+00 (1.8178e+00)\tAcc@1  50.78 ( 50.74)\tAcc@5  84.38 ( 80.76)\n","Epoch: [35][330/391]\tTime  0.169 ( 0.169)\tLoss 1.8719e+00 (1.8238e+00)\tAcc@1  46.88 ( 50.64)\tAcc@5  82.03 ( 80.69)\n","Epoch: [35][360/391]\tTime  0.169 ( 0.169)\tLoss 1.6263e+00 (1.8271e+00)\tAcc@1  54.69 ( 50.56)\tAcc@5  83.59 ( 80.59)\n","Epoch: [35][390/391]\tTime  0.151 ( 0.169)\tLoss 2.0431e+00 (1.8330e+00)\tAcc@1  46.25 ( 50.40)\tAcc@5  76.25 ( 80.50)\n","==> Train Accuracy: Acc@1 50.404 || Acc@5 80.498\n","==> Test Accuracy:  Acc@1 51.280 || Acc@5 81.660\n","==> 70.26 seconds to train this epoch\n","\n","\n","----- epoch: 36, lr: 0.1 -----\n","Epoch: [36][  0/391]\tTime  0.279 ( 0.279)\tLoss 1.5882e+00 (1.5882e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  84.38 ( 84.38)\n","Epoch: [36][ 30/391]\tTime  0.168 ( 0.172)\tLoss 1.5806e+00 (1.7586e+00)\tAcc@1  54.69 ( 53.28)\tAcc@5  83.59 ( 82.33)\n","Epoch: [36][ 60/391]\tTime  0.169 ( 0.170)\tLoss 1.5287e+00 (1.7625e+00)\tAcc@1  57.81 ( 52.47)\tAcc@5  87.50 ( 82.24)\n","Epoch: [36][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.5434e+00 (1.7809e+00)\tAcc@1  53.91 ( 52.00)\tAcc@5  88.28 ( 81.82)\n","Epoch: [36][120/391]\tTime  0.169 ( 0.170)\tLoss 1.5750e+00 (1.7977e+00)\tAcc@1  60.94 ( 51.67)\tAcc@5  82.81 ( 81.26)\n","Epoch: [36][150/391]\tTime  0.169 ( 0.170)\tLoss 1.6924e+00 (1.7969e+00)\tAcc@1  52.34 ( 51.61)\tAcc@5  80.47 ( 81.22)\n","Epoch: [36][180/391]\tTime  0.168 ( 0.169)\tLoss 1.8537e+00 (1.8013e+00)\tAcc@1  53.12 ( 51.46)\tAcc@5  80.47 ( 81.09)\n","Epoch: [36][210/391]\tTime  0.168 ( 0.169)\tLoss 1.8223e+00 (1.8036e+00)\tAcc@1  50.78 ( 51.44)\tAcc@5  76.56 ( 81.04)\n","Epoch: [36][240/391]\tTime  0.168 ( 0.169)\tLoss 1.8086e+00 (1.8075e+00)\tAcc@1  47.66 ( 51.30)\tAcc@5  83.59 ( 81.00)\n","Epoch: [36][270/391]\tTime  0.168 ( 0.169)\tLoss 1.8815e+00 (1.8133e+00)\tAcc@1  47.66 ( 51.10)\tAcc@5  78.91 ( 80.93)\n","Epoch: [36][300/391]\tTime  0.168 ( 0.169)\tLoss 1.9562e+00 (1.8162e+00)\tAcc@1  45.31 ( 51.05)\tAcc@5  80.47 ( 80.82)\n","Epoch: [36][330/391]\tTime  0.169 ( 0.169)\tLoss 1.6917e+00 (1.8181e+00)\tAcc@1  54.69 ( 50.97)\tAcc@5  83.59 ( 80.72)\n","Epoch: [36][360/391]\tTime  0.170 ( 0.169)\tLoss 1.5308e+00 (1.8270e+00)\tAcc@1  53.12 ( 50.75)\tAcc@5  85.16 ( 80.56)\n","Epoch: [36][390/391]\tTime  0.153 ( 0.169)\tLoss 1.5478e+00 (1.8275e+00)\tAcc@1  62.50 ( 50.77)\tAcc@5  83.75 ( 80.53)\n","==> Train Accuracy: Acc@1 50.768 || Acc@5 80.528\n","==> Test Accuracy:  Acc@1 52.910 || Acc@5 82.480\n","==> 70.27 seconds to train this epoch\n","\n","\n","----- epoch: 37, lr: 0.1 -----\n","Epoch: [37][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.7944e+00 (1.7944e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  80.47 ( 80.47)\n","Epoch: [37][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.5830e+00 (1.7574e+00)\tAcc@1  59.38 ( 52.24)\tAcc@5  83.59 ( 81.17)\n","Epoch: [37][ 60/391]\tTime  0.167 ( 0.170)\tLoss 1.7604e+00 (1.7667e+00)\tAcc@1  50.00 ( 51.79)\tAcc@5  84.38 ( 81.29)\n","Epoch: [37][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.9498e+00 (1.7700e+00)\tAcc@1  43.75 ( 51.77)\tAcc@5  80.47 ( 81.34)\n","Epoch: [37][120/391]\tTime  0.170 ( 0.169)\tLoss 1.7344e+00 (1.7762e+00)\tAcc@1  53.12 ( 51.52)\tAcc@5  85.94 ( 81.31)\n","Epoch: [37][150/391]\tTime  0.169 ( 0.169)\tLoss 1.8138e+00 (1.7768e+00)\tAcc@1  51.56 ( 51.54)\tAcc@5  79.69 ( 81.34)\n","Epoch: [37][180/391]\tTime  0.168 ( 0.169)\tLoss 1.7541e+00 (1.7856e+00)\tAcc@1  53.91 ( 51.40)\tAcc@5  83.59 ( 81.22)\n","Epoch: [37][210/391]\tTime  0.168 ( 0.169)\tLoss 1.8035e+00 (1.7909e+00)\tAcc@1  51.56 ( 51.28)\tAcc@5  84.38 ( 81.21)\n","Epoch: [37][240/391]\tTime  0.169 ( 0.169)\tLoss 1.7231e+00 (1.7992e+00)\tAcc@1  52.34 ( 51.03)\tAcc@5  80.47 ( 81.05)\n","Epoch: [37][270/391]\tTime  0.169 ( 0.169)\tLoss 1.8606e+00 (1.7989e+00)\tAcc@1  48.44 ( 51.06)\tAcc@5  80.47 ( 81.09)\n","Epoch: [37][300/391]\tTime  0.169 ( 0.169)\tLoss 1.7333e+00 (1.8047e+00)\tAcc@1  54.69 ( 50.94)\tAcc@5  81.25 ( 80.96)\n","Epoch: [37][330/391]\tTime  0.169 ( 0.169)\tLoss 2.0192e+00 (1.8068e+00)\tAcc@1  44.53 ( 50.90)\tAcc@5  77.34 ( 80.92)\n","Epoch: [37][360/391]\tTime  0.171 ( 0.169)\tLoss 1.7444e+00 (1.8108e+00)\tAcc@1  52.34 ( 50.71)\tAcc@5  82.81 ( 80.87)\n","Epoch: [37][390/391]\tTime  0.152 ( 0.169)\tLoss 1.8175e+00 (1.8172e+00)\tAcc@1  56.25 ( 50.61)\tAcc@5  77.50 ( 80.71)\n","==> Train Accuracy: Acc@1 50.612 || Acc@5 80.714\n","==> Test Accuracy:  Acc@1 55.100 || Acc@5 84.250\n","==> 70.18 seconds to train this epoch\n","\n","\n","----- epoch: 38, lr: 0.1 -----\n","Epoch: [38][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.4811e+00 (1.4811e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  84.38 ( 84.38)\n","Epoch: [38][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.7540e+00 (1.7154e+00)\tAcc@1  50.00 ( 53.88)\tAcc@5  80.47 ( 82.31)\n","Epoch: [38][ 60/391]\tTime  0.170 ( 0.170)\tLoss 1.9195e+00 (1.7310e+00)\tAcc@1  45.31 ( 53.19)\tAcc@5  80.47 ( 82.30)\n","Epoch: [38][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.7185e+00 (1.7496e+00)\tAcc@1  53.91 ( 52.67)\tAcc@5  80.47 ( 82.11)\n","Epoch: [38][120/391]\tTime  0.168 ( 0.169)\tLoss 1.5578e+00 (1.7561e+00)\tAcc@1  57.03 ( 52.47)\tAcc@5  86.72 ( 82.02)\n","Epoch: [38][150/391]\tTime  0.168 ( 0.169)\tLoss 1.7839e+00 (1.7694e+00)\tAcc@1  49.22 ( 52.07)\tAcc@5  81.25 ( 81.71)\n","Epoch: [38][180/391]\tTime  0.170 ( 0.169)\tLoss 1.8073e+00 (1.7744e+00)\tAcc@1  51.56 ( 52.03)\tAcc@5  82.81 ( 81.60)\n","Epoch: [38][210/391]\tTime  0.170 ( 0.169)\tLoss 1.8341e+00 (1.7805e+00)\tAcc@1  47.66 ( 51.84)\tAcc@5  78.12 ( 81.52)\n","Epoch: [38][240/391]\tTime  0.167 ( 0.169)\tLoss 1.9771e+00 (1.7930e+00)\tAcc@1  39.84 ( 51.59)\tAcc@5  82.03 ( 81.16)\n","Epoch: [38][270/391]\tTime  0.169 ( 0.169)\tLoss 1.6934e+00 (1.7986e+00)\tAcc@1  53.91 ( 51.40)\tAcc@5  82.03 ( 81.06)\n","Epoch: [38][300/391]\tTime  0.169 ( 0.169)\tLoss 1.8754e+00 (1.8008e+00)\tAcc@1  48.44 ( 51.37)\tAcc@5  81.25 ( 81.00)\n","Epoch: [38][330/391]\tTime  0.169 ( 0.169)\tLoss 1.7608e+00 (1.8071e+00)\tAcc@1  53.12 ( 51.21)\tAcc@5  78.91 ( 80.89)\n","Epoch: [38][360/391]\tTime  0.168 ( 0.169)\tLoss 1.6470e+00 (1.8118e+00)\tAcc@1  54.69 ( 51.08)\tAcc@5  86.72 ( 80.83)\n","Epoch: [38][390/391]\tTime  0.148 ( 0.169)\tLoss 1.5688e+00 (1.8138e+00)\tAcc@1  58.75 ( 51.01)\tAcc@5  78.75 ( 80.79)\n","==> Train Accuracy: Acc@1 51.006 || Acc@5 80.788\n","==> Test Accuracy:  Acc@1 55.930 || Acc@5 85.590\n","==> 70.21 seconds to train this epoch\n","\n","\n","----- epoch: 39, lr: 0.1 -----\n","Epoch: [39][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.7167e+00 (1.7167e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  84.38 ( 84.38)\n","Epoch: [39][ 30/391]\tTime  0.171 ( 0.171)\tLoss 1.8116e+00 (1.7970e+00)\tAcc@1  48.44 ( 50.38)\tAcc@5  79.69 ( 80.90)\n","Epoch: [39][ 60/391]\tTime  0.166 ( 0.170)\tLoss 1.7352e+00 (1.7795e+00)\tAcc@1  51.56 ( 50.95)\tAcc@5  83.59 ( 81.29)\n","Epoch: [39][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.8901e+00 (1.7766e+00)\tAcc@1  47.66 ( 51.38)\tAcc@5  78.91 ( 81.15)\n","Epoch: [39][120/391]\tTime  0.169 ( 0.169)\tLoss 1.6288e+00 (1.7994e+00)\tAcc@1  57.03 ( 50.72)\tAcc@5  81.25 ( 80.61)\n","Epoch: [39][150/391]\tTime  0.169 ( 0.169)\tLoss 1.5525e+00 (1.7876e+00)\tAcc@1  57.81 ( 51.00)\tAcc@5  85.16 ( 80.90)\n","Epoch: [39][180/391]\tTime  0.168 ( 0.169)\tLoss 2.0028e+00 (1.8003e+00)\tAcc@1  42.97 ( 50.79)\tAcc@5  78.12 ( 80.80)\n","Epoch: [39][210/391]\tTime  0.169 ( 0.169)\tLoss 1.5066e+00 (1.8031e+00)\tAcc@1  59.38 ( 50.82)\tAcc@5  85.16 ( 80.82)\n","Epoch: [39][240/391]\tTime  0.168 ( 0.169)\tLoss 1.7270e+00 (1.8078e+00)\tAcc@1  50.78 ( 50.79)\tAcc@5  84.38 ( 80.76)\n","Epoch: [39][270/391]\tTime  0.169 ( 0.169)\tLoss 1.5463e+00 (1.8088e+00)\tAcc@1  59.38 ( 50.77)\tAcc@5  84.38 ( 80.75)\n","Epoch: [39][300/391]\tTime  0.169 ( 0.169)\tLoss 1.7050e+00 (1.8130e+00)\tAcc@1  54.69 ( 50.67)\tAcc@5  79.69 ( 80.65)\n","Epoch: [39][330/391]\tTime  0.163 ( 0.169)\tLoss 1.9561e+00 (1.8158e+00)\tAcc@1  49.22 ( 50.66)\tAcc@5  79.69 ( 80.64)\n","Epoch: [39][360/391]\tTime  0.169 ( 0.169)\tLoss 2.1026e+00 (1.8190e+00)\tAcc@1  43.75 ( 50.60)\tAcc@5  74.22 ( 80.60)\n","Epoch: [39][390/391]\tTime  0.152 ( 0.169)\tLoss 2.0986e+00 (1.8207e+00)\tAcc@1  46.25 ( 50.57)\tAcc@5  71.25 ( 80.64)\n","==> Train Accuracy: Acc@1 50.572 || Acc@5 80.638\n","==> Test Accuracy:  Acc@1 51.830 || Acc@5 81.600\n","==> 70.22 seconds to train this epoch\n","\n","\n","----- epoch: 40, lr: 0.1 -----\n","Epoch: [40][  0/391]\tTime  0.253 ( 0.253)\tLoss 1.8034e+00 (1.8034e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  82.81 ( 82.81)\n","Epoch: [40][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.4793e+00 (1.7541e+00)\tAcc@1  57.81 ( 52.32)\tAcc@5  87.50 ( 82.06)\n","Epoch: [40][ 60/391]\tTime  0.169 ( 0.170)\tLoss 1.7742e+00 (1.7606e+00)\tAcc@1  47.66 ( 51.78)\tAcc@5  85.94 ( 81.98)\n","Epoch: [40][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.7324e+00 (1.7669e+00)\tAcc@1  50.78 ( 51.97)\tAcc@5  84.38 ( 81.89)\n","Epoch: [40][120/391]\tTime  0.169 ( 0.169)\tLoss 1.7260e+00 (1.7757e+00)\tAcc@1  51.56 ( 51.72)\tAcc@5  84.38 ( 81.71)\n","Epoch: [40][150/391]\tTime  0.169 ( 0.169)\tLoss 1.7608e+00 (1.7829e+00)\tAcc@1  50.78 ( 51.56)\tAcc@5  80.47 ( 81.48)\n","Epoch: [40][180/391]\tTime  0.169 ( 0.169)\tLoss 2.0628e+00 (1.7835e+00)\tAcc@1  47.66 ( 51.61)\tAcc@5  71.09 ( 81.41)\n","Epoch: [40][210/391]\tTime  0.168 ( 0.169)\tLoss 1.9166e+00 (1.7870e+00)\tAcc@1  53.12 ( 51.46)\tAcc@5  79.69 ( 81.29)\n","Epoch: [40][240/391]\tTime  0.170 ( 0.169)\tLoss 1.7504e+00 (1.7875e+00)\tAcc@1  51.56 ( 51.41)\tAcc@5  82.03 ( 81.35)\n","Epoch: [40][270/391]\tTime  0.168 ( 0.169)\tLoss 1.9026e+00 (1.7901e+00)\tAcc@1  50.00 ( 51.44)\tAcc@5  82.81 ( 81.24)\n","Epoch: [40][300/391]\tTime  0.169 ( 0.169)\tLoss 1.6275e+00 (1.8000e+00)\tAcc@1  52.34 ( 51.22)\tAcc@5  85.94 ( 81.09)\n","Epoch: [40][330/391]\tTime  0.170 ( 0.169)\tLoss 1.7793e+00 (1.8039e+00)\tAcc@1  53.12 ( 51.08)\tAcc@5  84.38 ( 81.08)\n","Epoch: [40][360/391]\tTime  0.169 ( 0.169)\tLoss 1.7899e+00 (1.8063e+00)\tAcc@1  50.00 ( 50.99)\tAcc@5  86.72 ( 81.05)\n","Epoch: [40][390/391]\tTime  0.150 ( 0.169)\tLoss 1.7642e+00 (1.8090e+00)\tAcc@1  51.25 ( 50.96)\tAcc@5  81.25 ( 80.98)\n","==> Train Accuracy: Acc@1 50.956 || Acc@5 80.984\n","==> Test Accuracy:  Acc@1 54.700 || Acc@5 83.900\n","==> 70.19 seconds to train this epoch\n","\n","\n","----- epoch: 41, lr: 0.1 -----\n","Epoch: [41][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.7432e+00 (1.7432e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  84.38 ( 84.38)\n","Epoch: [41][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.9380e+00 (1.7858e+00)\tAcc@1  43.75 ( 51.36)\tAcc@5  82.03 ( 81.40)\n","Epoch: [41][ 60/391]\tTime  0.167 ( 0.170)\tLoss 1.6695e+00 (1.7673e+00)\tAcc@1  54.69 ( 51.90)\tAcc@5  84.38 ( 81.48)\n","Epoch: [41][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.7834e+00 (1.7552e+00)\tAcc@1  53.91 ( 52.52)\tAcc@5  79.69 ( 81.68)\n","Epoch: [41][120/391]\tTime  0.168 ( 0.170)\tLoss 1.8885e+00 (1.7659e+00)\tAcc@1  48.44 ( 52.20)\tAcc@5  78.12 ( 81.43)\n","Epoch: [41][150/391]\tTime  0.170 ( 0.169)\tLoss 1.5529e+00 (1.7799e+00)\tAcc@1  57.03 ( 52.02)\tAcc@5  90.62 ( 81.24)\n","Epoch: [41][180/391]\tTime  0.168 ( 0.169)\tLoss 1.7818e+00 (1.7788e+00)\tAcc@1  53.91 ( 52.02)\tAcc@5  82.03 ( 81.31)\n","Epoch: [41][210/391]\tTime  0.169 ( 0.169)\tLoss 1.7550e+00 (1.7749e+00)\tAcc@1  47.66 ( 51.99)\tAcc@5  83.59 ( 81.37)\n","Epoch: [41][240/391]\tTime  0.168 ( 0.169)\tLoss 1.9806e+00 (1.7799e+00)\tAcc@1  48.44 ( 51.92)\tAcc@5  82.03 ( 81.27)\n","Epoch: [41][270/391]\tTime  0.168 ( 0.169)\tLoss 1.8867e+00 (1.7905e+00)\tAcc@1  49.22 ( 51.71)\tAcc@5  78.12 ( 81.08)\n","Epoch: [41][300/391]\tTime  0.170 ( 0.169)\tLoss 2.0316e+00 (1.7941e+00)\tAcc@1  42.19 ( 51.50)\tAcc@5  80.47 ( 81.18)\n","Epoch: [41][330/391]\tTime  0.169 ( 0.169)\tLoss 1.9369e+00 (1.7968e+00)\tAcc@1  49.22 ( 51.43)\tAcc@5  75.78 ( 81.17)\n","Epoch: [41][360/391]\tTime  0.167 ( 0.169)\tLoss 2.0388e+00 (1.7996e+00)\tAcc@1  42.97 ( 51.37)\tAcc@5  81.25 ( 81.06)\n","Epoch: [41][390/391]\tTime  0.152 ( 0.169)\tLoss 1.5693e+00 (1.7988e+00)\tAcc@1  62.50 ( 51.38)\tAcc@5  80.00 ( 81.04)\n","==> Train Accuracy: Acc@1 51.378 || Acc@5 81.040\n","==> Test Accuracy:  Acc@1 52.560 || Acc@5 81.210\n","==> 70.24 seconds to train this epoch\n","\n","\n","----- epoch: 42, lr: 0.1 -----\n","Epoch: [42][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.9771e+00 (1.9771e+00)\tAcc@1  48.44 ( 48.44)\tAcc@5  76.56 ( 76.56)\n","Epoch: [42][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.8348e+00 (1.7729e+00)\tAcc@1  51.56 ( 52.67)\tAcc@5  78.12 ( 81.02)\n","Epoch: [42][ 60/391]\tTime  0.170 ( 0.170)\tLoss 1.6972e+00 (1.7750e+00)\tAcc@1  52.34 ( 52.42)\tAcc@5  83.59 ( 81.40)\n","Epoch: [42][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.9324e+00 (1.7671e+00)\tAcc@1  48.44 ( 52.53)\tAcc@5  82.81 ( 81.42)\n","Epoch: [42][120/391]\tTime  0.171 ( 0.169)\tLoss 1.6481e+00 (1.7850e+00)\tAcc@1  55.47 ( 52.02)\tAcc@5  84.38 ( 81.18)\n","Epoch: [42][150/391]\tTime  0.168 ( 0.169)\tLoss 1.9286e+00 (1.7893e+00)\tAcc@1  49.22 ( 51.87)\tAcc@5  78.91 ( 81.14)\n","Epoch: [42][180/391]\tTime  0.168 ( 0.169)\tLoss 1.8867e+00 (1.7987e+00)\tAcc@1  50.78 ( 51.59)\tAcc@5  77.34 ( 80.89)\n","Epoch: [42][210/391]\tTime  0.172 ( 0.169)\tLoss 1.9002e+00 (1.7996e+00)\tAcc@1  46.88 ( 51.41)\tAcc@5  79.69 ( 80.89)\n","Epoch: [42][240/391]\tTime  0.170 ( 0.169)\tLoss 1.7028e+00 (1.8043e+00)\tAcc@1  52.34 ( 51.24)\tAcc@5  84.38 ( 80.79)\n","Epoch: [42][270/391]\tTime  0.170 ( 0.169)\tLoss 1.9387e+00 (1.8033e+00)\tAcc@1  47.66 ( 51.27)\tAcc@5  80.47 ( 80.87)\n","Epoch: [42][300/391]\tTime  0.168 ( 0.169)\tLoss 2.0017e+00 (1.8052e+00)\tAcc@1  46.09 ( 51.25)\tAcc@5  78.12 ( 80.86)\n","Epoch: [42][330/391]\tTime  0.169 ( 0.169)\tLoss 1.9626e+00 (1.8089e+00)\tAcc@1  50.78 ( 51.25)\tAcc@5  78.91 ( 80.79)\n","Epoch: [42][360/391]\tTime  0.167 ( 0.169)\tLoss 1.8679e+00 (1.8102e+00)\tAcc@1  49.22 ( 51.17)\tAcc@5  80.47 ( 80.74)\n","Epoch: [42][390/391]\tTime  0.152 ( 0.169)\tLoss 2.0272e+00 (1.8072e+00)\tAcc@1  43.75 ( 51.31)\tAcc@5  80.00 ( 80.77)\n","==> Train Accuracy: Acc@1 51.310 || Acc@5 80.766\n","==> Test Accuracy:  Acc@1 54.630 || Acc@5 84.060\n","==> 70.18 seconds to train this epoch\n","\n","\n","----- epoch: 43, lr: 0.1 -----\n","Epoch: [43][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.6032e+00 (1.6032e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  84.38 ( 84.38)\n","Epoch: [43][ 30/391]\tTime  0.170 ( 0.171)\tLoss 1.6466e+00 (1.7580e+00)\tAcc@1  58.59 ( 52.42)\tAcc@5  80.47 ( 81.83)\n","Epoch: [43][ 60/391]\tTime  0.175 ( 0.170)\tLoss 1.5379e+00 (1.7490e+00)\tAcc@1  57.03 ( 52.65)\tAcc@5  83.59 ( 81.90)\n","Epoch: [43][ 90/391]\tTime  0.168 ( 0.170)\tLoss 2.0656e+00 (1.7532e+00)\tAcc@1  43.75 ( 52.42)\tAcc@5  74.22 ( 81.82)\n","Epoch: [43][120/391]\tTime  0.171 ( 0.169)\tLoss 1.6235e+00 (1.7597e+00)\tAcc@1  53.91 ( 52.25)\tAcc@5  85.16 ( 81.72)\n","Epoch: [43][150/391]\tTime  0.170 ( 0.169)\tLoss 1.8104e+00 (1.7620e+00)\tAcc@1  54.69 ( 52.27)\tAcc@5  81.25 ( 81.75)\n","Epoch: [43][180/391]\tTime  0.167 ( 0.169)\tLoss 1.8546e+00 (1.7663e+00)\tAcc@1  48.44 ( 52.17)\tAcc@5  82.81 ( 81.56)\n","Epoch: [43][210/391]\tTime  0.170 ( 0.169)\tLoss 1.6462e+00 (1.7676e+00)\tAcc@1  57.03 ( 52.07)\tAcc@5  80.47 ( 81.48)\n","Epoch: [43][240/391]\tTime  0.169 ( 0.169)\tLoss 1.7766e+00 (1.7729e+00)\tAcc@1  52.34 ( 51.85)\tAcc@5  79.69 ( 81.41)\n","Epoch: [43][270/391]\tTime  0.169 ( 0.169)\tLoss 1.9936e+00 (1.7853e+00)\tAcc@1  43.75 ( 51.50)\tAcc@5  76.56 ( 81.13)\n","Epoch: [43][300/391]\tTime  0.168 ( 0.169)\tLoss 1.8912e+00 (1.7862e+00)\tAcc@1  45.31 ( 51.54)\tAcc@5  76.56 ( 81.09)\n","Epoch: [43][330/391]\tTime  0.168 ( 0.169)\tLoss 1.9862e+00 (1.7890e+00)\tAcc@1  50.00 ( 51.52)\tAcc@5  74.22 ( 81.06)\n","Epoch: [43][360/391]\tTime  0.169 ( 0.169)\tLoss 1.9391e+00 (1.7913e+00)\tAcc@1  47.66 ( 51.43)\tAcc@5  80.47 ( 81.05)\n","Epoch: [43][390/391]\tTime  0.153 ( 0.169)\tLoss 1.9537e+00 (1.7912e+00)\tAcc@1  51.25 ( 51.41)\tAcc@5  76.25 ( 81.10)\n","==> Train Accuracy: Acc@1 51.406 || Acc@5 81.104\n","==> Test Accuracy:  Acc@1 56.460 || Acc@5 85.250\n","==> 70.16 seconds to train this epoch\n","\n","\n","----- epoch: 44, lr: 0.1 -----\n","Epoch: [44][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.7687e+00 (1.7687e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  78.91 ( 78.91)\n","Epoch: [44][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.5966e+00 (1.7741e+00)\tAcc@1  57.03 ( 51.94)\tAcc@5  85.16 ( 81.53)\n","Epoch: [44][ 60/391]\tTime  0.171 ( 0.170)\tLoss 1.8446e+00 (1.7649e+00)\tAcc@1  50.78 ( 52.28)\tAcc@5  80.47 ( 81.66)\n","Epoch: [44][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.6540e+00 (1.7566e+00)\tAcc@1  53.91 ( 52.22)\tAcc@5  85.16 ( 82.06)\n","Epoch: [44][120/391]\tTime  0.167 ( 0.169)\tLoss 1.7559e+00 (1.7587e+00)\tAcc@1  50.00 ( 52.09)\tAcc@5  85.16 ( 81.88)\n","Epoch: [44][150/391]\tTime  0.166 ( 0.169)\tLoss 1.9464e+00 (1.7651e+00)\tAcc@1  52.34 ( 51.88)\tAcc@5  76.56 ( 81.67)\n","Epoch: [44][180/391]\tTime  0.167 ( 0.169)\tLoss 1.8352e+00 (1.7693e+00)\tAcc@1  51.56 ( 51.93)\tAcc@5  79.69 ( 81.58)\n","Epoch: [44][210/391]\tTime  0.171 ( 0.169)\tLoss 1.8909e+00 (1.7739e+00)\tAcc@1  50.00 ( 51.79)\tAcc@5  82.03 ( 81.58)\n","Epoch: [44][240/391]\tTime  0.169 ( 0.169)\tLoss 1.9121e+00 (1.7744e+00)\tAcc@1  48.44 ( 51.71)\tAcc@5  78.12 ( 81.54)\n","Epoch: [44][270/391]\tTime  0.167 ( 0.169)\tLoss 2.0671e+00 (1.7750e+00)\tAcc@1  47.66 ( 51.77)\tAcc@5  75.78 ( 81.47)\n","Epoch: [44][300/391]\tTime  0.169 ( 0.169)\tLoss 1.7104e+00 (1.7790e+00)\tAcc@1  53.12 ( 51.73)\tAcc@5  79.69 ( 81.36)\n","Epoch: [44][330/391]\tTime  0.169 ( 0.169)\tLoss 1.8252e+00 (1.7803e+00)\tAcc@1  51.56 ( 51.73)\tAcc@5  78.91 ( 81.29)\n","Epoch: [44][360/391]\tTime  0.167 ( 0.169)\tLoss 1.8527e+00 (1.7839e+00)\tAcc@1  47.66 ( 51.70)\tAcc@5  82.81 ( 81.19)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RB3-eyvkZJGE"},"source":[""],"execution_count":null,"outputs":[]}]}